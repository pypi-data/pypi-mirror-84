Ploomber
========

.. image:: https://travis-ci.org/ploomber/ploomber.svg?branch=master
    :target: https://travis-ci.org/ploomber/ploomber.svg?branch=master

.. image:: https://readthedocs.org/projects/ploomber/badge/?version=latest
    :target: https://ploomber.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. image:: https://mybinder.org/badge_logo.svg
 :target: https://mybinder.org/v2/gh/ploomber/projects/master

.. image:: https://badge.fury.io/py/ploomber.svg
  :target: https://badge.fury.io/py/ploomber

.. image:: https://coveralls.io/repos/github/ploomber/ploomber/badge.svg?branch=master
  :target: https://coveralls.io/github/ploomber/ploomber?branch=master

Coding an entire analysis pipeline in a single notebook file allows you to
develop your code interactively, but it creates an unmaintainable monolith that
easily breaks. Ploomber allows you to modularize your analysis in smaller
tasks without losing the power of an interactive notebook.

Imagine you have a pipeline that gets (``get.ipynb``), cleans (``clean.ipynb``)
and plots (``plot.ipynb``) data. All you  have to do to turn this into a data
pipeline is to declare a special cell at the top of your notebook with
dependencies and output files:

.. code-block:: python

    # top cell in clean.ipynb

    # get.ipynb must run before clean.ipynb
    upstream = ['get']
    # output files generated by clean.ipynb
    product = {'data': 'output/clean.csv'}


That's it! Execute ``ploomber build`` and your pipeline tasks will execute in
the right order.

Main features
-------------

1. **Jupyter integration**. When you open your notebooks, Ploomber will
automatically inject a new cell with the location of your input files, as
inferred from your ``upstream`` variable. If you open a Python or R script, it
will be converted to a notebook on the fly.

2. **Incremental builds**. Speed up execution by skipping tasks whose source
code hasn't changed.

3. **Pipeline testing**. Run tests upon task execution to verify that the output
data has the right properties (e.g. values within expected range).

4. **Pipeline inspection**. Start an interactive session with
``ploomber interact`` to debug your pipeline. Call
``dag['task_name'].debug()`` to start a debugging session.


Try it out
----------

.. code-block:: shell

    # clone the sample projects
    git clone https://github.com/ploomber/projects

    # move to the machine learning pipeline example
    cd projects/ml-basic

    # install dependencies
    # 1) if you have conda installed
    conda env create -f environment.yml
    conda activate ml-basic
    # 2) if you don't have conda
    pip install ploomber pandas scikit-learn pyarrow sklearn-evaluation

    # create output folder
    mkdir output

    # run the pipeline
    ploomber build    


When execution finishes, you'll see the output in the ``output/`` folder.


Installation
------------

.. code-block:: shell

    pip install ploomber


Compatible with Python 3.6 and higher.


Resources
---------

* `Sample projects <https://github.com/ploomber/projects>`_
* `Documentation <https://ploomber.readthedocs.io/>`_
* `Blog <https://ploomber.io/>`_

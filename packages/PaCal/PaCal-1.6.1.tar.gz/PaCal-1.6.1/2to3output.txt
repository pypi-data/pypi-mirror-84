root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Skipping optional fixer: buffer
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Skipping optional fixer: idioms
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Skipping optional fixer: set_literal
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Skipping optional fixer: ws_comma
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Refactored ./__init__.py
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
root: Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt
RefactoringTool: Refactored ./distr.py
--- ./__init__.py	(original)
+++ ./__init__.py	(refactored)
@@ -5,60 +5,60 @@
 
 _np.seterr(all="ignore")
 
-from utils import Inf
+from .utils import Inf
 
-from distr import DiscreteDistr
-from distr import exp, log, atan, min, max, sqrt, sign, sin, cos, tan, tanh, sigmoid
+from .distr import DiscreteDistr
+from .distr import exp, log, atan, min, max, sqrt, sign, sin, cos, tan, tanh, sigmoid
 
-from standard_distr import FunDistr
-from standard_distr import NormalDistr
-from standard_distr import UniformDistr
-from standard_distr import TrapezoidalDistr
-from standard_distr import CauchyDistr
-from standard_distr import ChiSquareDistr
-from standard_distr import ExponentialDistr
-from standard_distr import GammaDistr
-from standard_distr import BetaDistr
-from standard_distr import ParetoDistr
-from standard_distr import LevyDistr
-from standard_distr import LaplaceDistr
-from standard_distr import StudentTDistr
-from standard_distr import SemicircleDistr
-from standard_distr import FDistr
-from standard_distr import WeibullDistr
-from standard_distr import GumbelDistr
-from standard_distr import FrechetDistr
-from standard_distr import MollifierDistr
+from .standard_distr import FunDistr
+from .standard_distr import NormalDistr
+from .standard_distr import UniformDistr
+from .standard_distr import TrapezoidalDistr
+from .standard_distr import CauchyDistr
+from .standard_distr import ChiSquareDistr
+from .standard_distr import ExponentialDistr
+from .standard_distr import GammaDistr
+from .standard_distr import BetaDistr
+from .standard_distr import ParetoDistr
+from .standard_distr import LevyDistr
+from .standard_distr import LaplaceDistr
+from .standard_distr import StudentTDistr
+from .standard_distr import SemicircleDistr
+from .standard_distr import FDistr
+from .standard_distr import WeibullDistr
+from .standard_distr import GumbelDistr
+from .standard_distr import FrechetDistr
+from .standard_distr import MollifierDistr
 
-from standard_distr import OneDistr
-from standard_distr import ZeroDistr
-from standard_distr import BinomialDistr
-from standard_distr import BernoulliDistr
-from standard_distr import PoissonDistr
-from standard_distr import MixDistr
-from distr import CondGtDistr
-from distr import CondLtDistr
-from distr import ConstDistr
-from distr import Gt
-from distr import Lt
-from distr import Between
+from .standard_distr import OneDistr
+from .standard_distr import ZeroDistr
+from .standard_distr import BinomialDistr
+from .standard_distr import BernoulliDistr
+from .standard_distr import PoissonDistr
+from .standard_distr import MixDistr
+from .distr import CondGtDistr
+from .distr import CondLtDistr
+from .distr import ConstDistr
+from .distr import Gt
+from .distr import Lt
+from .distr import Between
 
-from stats.noncentral_distr import NoncentralTDistr
-from stats.noncentral_distr import NoncentralChiSquareDistr
-from stats.noncentral_distr import NoncentralBetaDistr
-from stats.noncentral_distr import NoncentralFDistr
+from .stats.noncentral_distr import NoncentralTDistr
+from .stats.noncentral_distr import NoncentralChiSquareDistr
+from .stats.noncentral_distr import NoncentralBetaDistr
+from .stats.noncentral_distr import NoncentralFDistr
 
-from stats.iid_ops import iid_sum, iid_prod, iid_max, iid_min, iid_average, iid_average_geom
-from stats.iid_ops import iid_order_stat, iid_median
+from .stats.iid_ops import iid_sum, iid_prod, iid_max, iid_min, iid_average, iid_average_geom
+from .stats.iid_ops import iid_order_stat, iid_median
 
-from stats.distr_est import LoglikelihoodEstimator
+from .stats.distr_est import LoglikelihoodEstimator
 
 # dependent variables
-from depvars.copulas import PiCopula, FrankCopula, ClaytonCopula, GumbelCopula
-from depvars.nddistr import NDNormalDistr, IJthOrderStatsNDDistr
-from depvars.models import TwoVarsModel, Model
+from .depvars.copulas import PiCopula, FrankCopula, ClaytonCopula, GumbelCopula
+from .depvars.nddistr import NDNormalDistr, IJthOrderStatsNDDistr
+from .depvars.models import TwoVarsModel, Model
 
-import params
+from . import params
 
 #def _pickle_ufunc(ufunc):
 #    return ufunc.__name__
@@ -68,9 +68,9 @@
 
 #
 def _pickle_method(method):
-    obj = method.im_self
-    cls = method.im_class
-    func_name = method.im_func.__name__
+    obj = method.__self__
+    cls = method.__self__.__class__
+    func_name = method.__func__.__name__
     #print "pickle>>>", func_name, obj, cls 
     if func_name.startswith('__') and not func_name.endswith('__'):
         #deal with mangled names
@@ -98,12 +98,12 @@
     #    params.general.process_pool = multiprocessing.Pool(params.general.nprocs)
     # make ufuncs picklable
     import types
-    import copy_reg
+    import copyreg
     #copy_reg.pickle(_np.ufunc, _pickle_ufunc, _unpickle_ufunc)
-    copy_reg.pickle(types.MethodType, _pickle_method, _unpickle_method)
+    copyreg.pickle(types.MethodType, _pickle_method, _unpickle_method)
     # disable threading in openblas
     import os
     try:
         os.environ["OPENBLAS_NUM_THREADS"] = "1"
     except:
-        print "WARNING: could not disable openblas threading"
+        print("WARNING: could not disable openblas threading")
--- ./distr.py	(original)
+++ ./distr.py	(refactored)
@@ -20,7 +20,7 @@
 import time
 import traceback
 
-import params
+from . import params
 from pacal.indeparith import conv, convprod, convdiv, convmin, convmax
 from pacal.segments import PiecewiseFunction, PiecewiseDistribution, DiracSegment, ConstSegment
 from pacal.rv import *
@@ -66,7 +66,7 @@
 
                 panc = p.getAncestorIDs()
                 if panc & anc:
-                    print "Warning: arguments treated as independent"
+                    print("Warning: arguments treated as independent")
                     break
                 anc.update(panc)
     def getName(self):
@@ -264,26 +264,26 @@
             r['iqrange(0.025)'] = self.iqrange()
             r['medianad'] = self.medianad()  
             r['interval(0.95)'] = self.interval()       
-        except Exception, e:           
+        except Exception as e:           
             traceback.print_exc() 
         return r
     def summary(self, show_moments=False):
         """Summary statistics for a given distribution."""
-        print "============= summary ============="
+        print("============= summary =============")
         #print self.get_piecewise_pdf()
         #t0  = time.time()
         summ = self.summary_map()
-        print " ", self.getName()
+        print(" ", self.getName())
         for i in ['mean', 'var', 'skewness', 'kurtosis', 'entropy', 'median', 'mode', 'medianad', 'iqrange(0.025)', 'interval(0.95)',  'range',  'tailexp', 'int_err']:
-            if summ.has_key(i): 
-                print '{0:{align}20}'.format(i, align = '>'), " = ", repr(summ[i])       
-            else:
-                print "---", i
+            if i in summ: 
+                print('{0:{align}20}'.format(i, align = '>'), " = ", repr(summ[i]))       
+            else:
+                print("---", i)
         if show_moments:
-            print "      moments:"
+            print("      moments:")
             for i in range(11):
                 mi = self.moment(i,0)
-                print '{0:{align}20}'.format(i, align = '>'), " = ", repr(mi)
+                print('{0:{align}20}'.format(i, align = '>'), " = ", repr(mi))
         #print "=====", time.time() - t0, "sec."
     def rand_raw(self, n = None):
         """Generates random numbers without tracking dependencies.
@@ -1042,7 +1042,7 @@
     def __init__(self, xi=[0.0, 1.0], pi=[0.5, 0.5]):
         super(DiscreteDistr, self).__init__([])
         assert(len(xi) == len(pi))
-        px = zip(xi, pi)
+        px = list(zip(xi, pi))
         px.sort()
         self.px = px
         self.xi = [p[0] for p in px]
@@ -1056,9 +1056,9 @@
         return yy
     def init_piecewise_pdf(self):
         self.piecewise_pdf = PiecewiseDistribution([])        
-        for i in xrange(len(self.xi)):
+        for i in range(len(self.xi)):
             self.piecewise_pdf.addSegment(DiracSegment(self.xi[i], self.pi[i]))
-        for i in xrange(len(self.xi)-1):RefactoringTool: No changes to ./gamma.py
RefactoringTool: Refactored ./indeparith.py

+        for i in range(len(self.xi)-1):
             self.piecewise_pdf.addSegment(ConstSegment(self.xi[i], self.xi[i+1], 0))
     def rand_raw(self, n):
         u = uniform(0, 1, n)
@@ -1356,10 +1356,10 @@
                 r.plot(numberOfPoints = n_points, xmin = xmin, xmax = xmax, color='k')
                 ss = d.summary_map()
                 sd = theoretical.summary_map()
-                print "============= summary ============="
-                print " ", d.getName()
+                print("============= summary =============")
+                print(" ", d.getName())
                 for i in ['mean', 'std', 'var', 'median', 'entropy', 'medianad', 'iqrange(0.025)',  'ci(0.05)', 'range', 'int_err']:
-                    if ss.has_key(i): 
+                    if i in ss: 
                         try:
                             if i=='int_err':
                                 r = abs(ss[i]-0)
@@ -1367,8 +1367,8 @@
                                 r = abs(ss[i]-sd[i])
                             if not r==r:
                                 r = 0.0                           
-                            print '{0:{align}20}'.format(i, align = '>'), "=", '{0:{align}24}'.format(repr(ss[i]), align = '>'), " +/-", '%1.3g' % r    
-                        except Exception, e:  
+                            print('{0:{align}20}'.format(i, align = '>'), "=", '{0:{align}24}'.format(repr(ss[i]), align = '>'), " +/-", '%1.3g' % r)    
+                        except Exception as e:  
                             pass
             else:
                 pylab.plot(X, abse, color='k')
@@ -1383,6 +1383,6 @@
     if summary and not theoretical:
         d.summary()
     if summary and theoretical:
-        print "max. abs. error", maxabserr
-        print "max. rel. error", maxrelerr
+        print("max. abs. error", maxabserr)
+        print("max. rel. error", maxrelerr)
     #show()
--- ./indeparith.py	(original)
+++ ./indeparith.py	(refactored)
@@ -13,15 +13,15 @@
 
 from matplotlib.mlab import find
 
-import params
-
-from integration import *
-from interpolation import *
-from segments import DiracSegment
-from segments import Segment, SegmentWithPole, PInfSegment, MInfSegment
-from segments import PiecewiseDistribution, _segint
-from utils import epsunique, testPole
-from utils import get_parmap
+from . import params
+
+from .integration import *
+from .interpolation import *
+from .segments import DiracSegment
+from .segments import Segment, SegmentWithPole, PInfSegment, MInfSegment
+from .segments import PiecewiseDistribution, _segint
+from .utils import epsunique, testPole
+from .utils import get_parmap
 
 import multiprocessing
 import time 
@@ -120,7 +120,7 @@
         segint = seg.toInterpolatedSegment()
         fg.addSegment(segint)
         breaks = breaks[:-1]
-    for i in xrange(len(breaks)-1):
+    for i in range(len(breaks)-1):
         segList = _findSegListAdd(f, g, (breaks[i][0] + breaks[i+1][0])/2)
         fun = Convxrunner(segList, params.integration_finite).convx
         seg = Segment(breaks[i][0], breaks[i+1][0], fun)
@@ -130,30 +130,30 @@
             NoL = True
             left_pole = testPole(fun, breaks[i][0])
             if left_pole and params.segments.debug_info:
-                print "probably pole", estimateDegreeOfPole(fun, breaks[i][0])
+                print("probably pole", estimateDegreeOfPole(fun, breaks[i][0]))
             elif params.segments.debug_info:   
-                print "probably no pole", estimateDegreeOfPole(fun, breaks[i][0])
+                print("probably no pole", estimateDegreeOfPole(fun, breaks[i][0]))
         if breaks[i][4]: # potential singularity on the left
             NoL = True
             left_pole = testPole(fun, breaks[i][0], deriv = True)
             if left_pole and params.segments.debug_info:
-                print "probably deriv pole", estimateDegreeOfPole(fun, breaks[i][0], deriv = True)
+                print("probably deriv pole", estimateDegreeOfPole(fun, breaks[i][0], deriv = True))
             elif params.segments.debug_info:   
-                print "probably no deriv pole", estimateDegreeOfPole(fun, breaks[i][0], deriv = True)
+                print("probably no deriv pole", estimateDegreeOfPole(fun, breaks[i][0], deriv = True))
         if breaks[i+1][1]: # potential singularity on the right
             NoR = True
             right_pole = testPole(fun, breaks[i+1][0], pos = False)
             if right_pole and params.segments.debug_info:
-                print "probably pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False)
+                print("probably pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False))
             elif params.segments.debug_info:
-                print "probably no pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False)
+                print("probably no pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False))
         if breaks[i+1][3]: # potential singularity on the right
             NoR = True
             right_pole = testPole(fun, breaks[i+1][0], pos = False, deriv = True)
             if right_pole and params.segments.debug_info:
-                print "probably deriv pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False, deriv = True)
+                print("probably deriv pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False, deriv = True))
             elif params.segments.debug_info:
-                print "probably no deriv pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False, deriv = True)
+                print("probably no deriv pole", estimateDegreeOfPole(fun, breaks[i+1][0], pos = False, deriv = True))
         segint = seg.toInterpolatedSegment(left_pole, NoL, right_pole, NoR)
         fg.addSegment(segint)
     # Discrete parts of distributions
@@ -348,7 +348,7 @@
                     #    print ix, iy, log(ix) - log(x**-1.5), log(iy) - log(x**-1.5)
                     #    print
                 else:
-                    print "Should not be here!!!"
+                    print("Should not be here!!!")
                     assert(False)
             #if 3.26 < log(-x+1) < 3.27:
             #    print "x", x, log(-x+1), segi, segj, repr(Lx), repr(Ux), ix
@@ -953,27 +953,27 @@
             if pole_at_zero or testPole(fun, ub[i], pos = True):
                 #segint = InterpolatedSegmentWithPole(ub[i],ub[i+1], fun, left_pole = True)
                 if params.segments.debug_info:
-                    print "probably pole at 0 left prod", fun(0.0)
+                    print("probably pole at 0 left prod", fun(0.0))
                 seg = SegmentWithPole(ub[i],ub[i+1], fun, left_pole = True)  
             else:
                 if params.segments.debug_info:
-                    print "probably no pole at 0 left prod", fun(0.0)
+                    print("probably no pole at 0 left prod", fun(0.0))
                 seg = Segment(ub[i],ub[i+1], fun)
                 _NoL = True
         elif (ub[i+1] == 0): # TODO add proper condition
             #segint = InterpolatedSegmentWithPole(ub[i],ub[i+1], fun, left_pole = False)
             if pole_at_zero or testPole(fun, ub[i+1], pos = False):
                 if params.segments.debug_info:
-                    print "probably pole at 0 right prod", fun(0.0)
+                    print("probably pole at 0 right prod", fun(0.0))
                 seg = SegmentWithPole(ub[i],ub[i+1], fun, left_pole = False)                 
             else:
                 if params.segments.debug_info:
-                    print "probably no pole at 0 right prod", fun(0.0)
+                    print("probably no pole at 0 right prod", fun(0.0))
                 seg = Segment(ub[i],ub[i+1], fun)
                 _NoR = True
         else:
             if params.segments.debug_info:
-                print "probably no pole prod"
+                print("probably no pole prod")
             seg = Segment(ub[i],ub[i+1], fun)
         segint = seg.toInterpolatedSegment(NoL = _NoL, NoR = _NoR)
         #segint = seg.toInterpolatedSegment()
@@ -1144,7 +1144,7 @@
         segint = seg.toInterpolatedSegment()
         fg.addSegment(segint)RefactoringTool: Refactored ./integration.py

         ub=ub[0:-1]
-    for i in xrange(len(ub)-1) :
+    for i in range(len(ub)-1) :
         segList = _findSegListDiv(f, g, (ub[i] + ub[i+1])/2)
         #fun = partial(fun_div, segList)
         fun = Convxrunner(segList, params.integration_infinite).fun_div
@@ -1154,27 +1154,27 @@
             if testPole(fun, ub[i], pos = True):
                 #segint = InterpolatedSegmentWithPole(ub[i],ub[i+1], fun, left_pole = True)
                 if params.segments.debug_info:
-                    print "probably pole at 0 left div", fun(0.0)
+                    print("probably pole at 0 left div", fun(0.0))
                 seg = SegmentWithPole(ub[i], ub[i+1], fun, left_pole = True)     
             else:
                 if params.segments.debug_info:
-                    print "probably no pole at 0 left div", fun(0.0)
+                    print("probably no pole at 0 left div", fun(0.0))
                 seg = Segment(ub[i], ub[i+1], fun)
                 _NoL = True
         elif (ub[i+1] == 0): # TODO add proper condition
             #segint = InterpolatedSegmentWithPole(ub[i],ub[i+1], fun, left_pole = False)
             if testPole(fun, ub[i+1], pos = False):
                 if params.segments.debug_info:
-                    print "probably pole at 0 right div", fun(0.0)
+                    print("probably pole at 0 right div", fun(0.0))
                 seg = SegmentWithPole(ub[i], ub[i+1], fun, left_pole = False)                 
             else:
                 if params.segments.debug_info:
-                    print "probably no pole at 0 right div", fun(0.0)
+                    print("probably no pole at 0 right div", fun(0.0))
                 seg = Segment(ub[i], ub[i+1], fun)
                 _NoR = True
         else:
             if params.segments.debug_info:
-                print "probably no pole div",  fun(0.0)
+                print("probably no pole div",  fun(0.0))
             seg = Segment(ub[i], ub[i+1], fun)
         segint = seg.toInterpolatedSegment(NoL = _NoL, NoR = _NoR)
         fg.addSegment(segint)
@@ -1382,7 +1382,7 @@
     elif L<U:
         i, e = integrate_fejer2_pminf(fun, debug_info = debug_info, debug_plot = debug_plot)
     else:
-        print "errors in convdiv: x, segi, segj, L, U =", L, U
+        print("errors in convdiv: x, segi, segj, L, U =", L, U)
     return i,e
 
 
@@ -1394,11 +1394,11 @@
     for fi in f.getDiracs():
         for gi in g.getDiracs():
             key = fun(fi.a, gi.a)            
-            if wyn.has_key(key):
+            if key in wyn:
                 wyn[key] = wyn.get(key) + fi.f * gi.f
             else:  
                 wyn[key] = fi.f * gi.f
-    for key in wyn.keys():
+    for key in list(wyn.keys()):
         fg.addSegment(DiracSegment(key, wyn.get(key)))
     return fg
 def _probDiracAtZeroInProd(f, g):
@@ -1459,7 +1459,7 @@
     i=0
     for item in segList:
         i=i+1
-        print i, " ", item[0], ", ", item[1]    
+        print(i, " ", item[0], ", ", item[1])    
 
 
 
@@ -1467,7 +1467,7 @@
     def fun1(x):
         return 1-x**2
     
-    from segments import *
+    from .segments import *
     from pacal import *
     import pickle
     params.general.parallel=False
@@ -1479,9 +1479,9 @@
     #k.addSegment(Segment(0.2,1.0,lambda x: 1.0+0.0*x))
     #k = k.toInterpolated()
     #h.addSegment(ConstSegment(-1,0,0.5))
-    print k, k.range()
+    print(k, k.range())
     p = conv(k,h)
-    print "============================="
+    print("=============================")
     #print pickle.dumps(p.segments[0].f.interp_at)
     #params.general.parallel=False
     p = conv(k,p)
--- ./integration.py	(original)
+++ ./integration.py	(refactored)
@@ -20,20 +20,20 @@
 from numpy import finfo, double, isinf
 from numpy import ceil,log10, logspace
 
-from utils import cheb_nodes, incremental_cheb_nodes
-from utils import combine_interpolation_nodes_fast
-from utils import convergence_monitor
-from utils import debug_plot
-
-from vartransforms import VarTransformAlgebraic_PMInf
-from vartransforms import VarTransformAlgebraic_PInf
-from vartransforms import VarTransformAlgebraic_MInf
-from vartransforms import VarTransformReciprocal_PMInf
-from vartransforms import VarTransformReciprocal_PInf
-from vartransforms import VarTransformReciprocal_MInf
+from .utils import cheb_nodes, incremental_cheb_nodes
+from .utils import combine_interpolation_nodes_fast
+from .utils import convergence_monitor
+from .utils import debug_plot
+
+from .vartransforms import VarTransformAlgebraic_PMInf
+from .vartransforms import VarTransformAlgebraic_PInf
+from .vartransforms import VarTransformAlgebraic_MInf
+from .vartransforms import VarTransformReciprocal_PMInf
+from .vartransforms import VarTransformReciprocal_PInf
+from .vartransforms import VarTransformReciprocal_MInf
 
 from pacal.interpolation import ChebyshevInterpolator1
-import params
+from . import params
 
 # cache for Clenshaw quadrature coefficients
 _clenshaw_cache = {}
@@ -109,7 +109,7 @@
         prevI = I
         n = 2 * n - 1
     if debug_info:
-        print "===="
+        print("====")
     if debug_plot and n >= maxn: # problems with integration
         debug_plot(a, b, nodes, fs, coeffs)
     return I, err
@@ -142,14 +142,14 @@
         if prevI is not None:
             err = abs(I - prevI)
             if debug_info:
-                print repr(I), err, n, I + err == I, err <= abs(I) * tol, min(nodes), max(nodes), min(fs), max(fs)
+                print(repr(I), err, n, I + err == I, err <= abs(I) * tol, min(nodes), max(nodes), min(fs), max(fs))
             cm.add(err, I)
             if cm.test_convergence()[0]:
                 break
         prevI = I
         n = 2 * n - 1
     if debug_info:
-        print "===="
+        print("====")
     if debug_plot and n >= maxn: # problems with integration
         debug_plot(a, b, nodes, fs, coeffs)
     # return currently best result
@@ -290,7 +290,7 @@
         else:
             z = zeros_like(x)
             for i in range(len(x)):
-                print ";;;", i, len(x)
+                print(";;;", i, len(x))
                 z[i], err = integrate_fejer2(lambda y : f(x[i], y), a2, b2)
         return z
     cheb  = ChebyshevInterpolator1(fun1, a1,b1) 
@@ -314,11 +314,11 @@
     def test_clenshaw(f, a, b, exact):
         """Test clenshaw integration"""
         I, err = integrate_clenshaw(f, a, b)
-        print I - exact, err
+        print(I - exact, err)
     def test_fejer2(f, a, b, exact):
         """Test fejer 2nd rule integration"""
         I, err = integrate_fejer2(f, a, b)
-        print I - exact, err
+        print(I - exact, err)
     from numpy import sin, cos, pi, exp, sqrt
     test_clenshaw(cos, 0, pi/2, 1)
     test_clenshaw(cos, 0, 2, sin(2))
@@ -333,7 +333,7 @@
     def normpdf(x):
         return 1.0/sqrt(2*pi)*exp(-x*x/2)
     I, err = integrate_clenshaw(cauchy, 0, 100)
-    print I, err
+    print(I, err)
     # those don't work well with clenshaw because of endpoints:
     #I, err = integrate_clenshaw_pminf(cauchy)
     #print I, err
@@ -342,44 +342,44 @@
     #I, err = integrate_clenshaw_minf(cauchy, 0)
     #print I, err
     I, err = integrate_clenshaw_pminf(normpdf)
-    print I, err
+    print(I, err)
     I, err = integrate_clenshaw_pinf(normpdf, 0)
-    print I, err
+    print(I, err)
     I, err = integrate_clenshaw_minf(normpdf, 0)
-    print I, err
+    print(I, err)
 
     ## Current variable transform won't work for Cauchy on infinite
     ## integral.  Will work fine on half infinite integrals though
     #I, err = integrate_fejer2_pminf(cauchy)
     #print I, err
     I, err = integrate_fejer2_pinf(cauchy, 0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_minf(cauchy, 0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_pminf(normpdf)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_pinf(normpdf, 0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_minf(normpdf, 0)
-    print I, err
+    print(I, err)
     from testPiecewise import *
     I, err = integrate_fejer2_Xn_transformP(lambda x: -log(x), 0.0, 0.1, N=4.0)
-    print "log:", I, errRefactoringTool: Refactored ./interpolation.py

+    print("log:", I, err)
     I, err = integrate_fejer2_Xn_transformP(lambda x: -log(x)/x**0.5, 0.0, 1.0, N=4.0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_Xn_transformP(lambda x: chisqr(x), 0.0, 10, N=4.0)
-    print "chisqr1=",I, err
+    print("chisqr1=",I, err)
     def prodcauchy(x):
         return 1.0/(pi*pi*(x*x-1))*log(x*x)
     from numpy import log1p
     def prodcauchy_uni(x):
         return 1.0/(2*pi)*log1p((1.0/(x*x)))
     I, err = integrate_fejer2_Xn_transform(lambda x: prodcauchy_uni(x), 0.0, 2, N=3.0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_Xn_transformP(lambda x: prodcauchy_uni(x), 0.0, 2.0, N=3.0)
-    print I, err
+    print(I, err)
     I, err = integrate_fejer2_Xn_transformN(lambda x: prodcauchy_uni(x), -2.0, 0.0, N=3.0)
-    print I, err
+    print(I, err)
     #I1, err = integrate_fejer2(lambda x: 1/x, 1e-16, 1e-8)
     #print I1, err
     #I, err = integrate_fejer2(lambda x: 1/x, 1e-8, 1)
@@ -392,15 +392,15 @@
     #I1, err = integrate_fejer2_Xn_transformP(lambda x: 0.25/x**0.5/(1.0-x)**0.5, 0.0, 0.5, N=4.0, debug_info = True, debug_plot = True)
     #I2, err = integrate_fejer2_Xn_transformN(lambda x: 0.25/x**0.5/(1.0-x)**0.5, 0.5, 1.0, N=8, debug_info = True, debug_plot = True)
     I1, err = integrate_fejer2_Xn_transformP(ff, 0.0, 0.5, N=4.0, debug_info = True, debug_plot = True)
-    print "log:", I1, err
+    print("log:", I1, err)
     I2, err = integrate_fejer2_Xn_transformN(ff, 0.5, 1.0, N=4, debug_info = True, debug_plot = True)
-    print "log:", I2, err, I1+I2 - pi/4
+    print("log:", I2, err, I1+I2 - pi/4)
     
     def pc(x,t=1e10):
         #print x
         return 1/(1+(t*x)**2) * 1/(1+t**2)*t
     I, err = integrate_fejer2_pinf(pc, a=1e-10, debug_info = True, debug_plot = True)
     
-    print "pcauchy:", I, err, 
+    print("pcauchy:", I, err, end=' ') 
     
     
--- ./interpolation.py	(original)
+++ ./interpolation.py	(refactored)
@@ -28,16 +28,16 @@
 from numpy import cumsum, flipud, real, imag, linspace
 from numpy.linalg import eigvals
 #from numpy.polynomial.chebyshev import chebroots
-import params
-
-from utils import cheb_nodes_log, incremental_cheb_nodes_log
-from utils import cheb_nodes, incremental_cheb_nodes, cheb_nodes1, incremental_cheb_nodes1
-from utils import combine_interpolation_nodes, combine_interpolation_nodes_fast
-from utils import convergence_monitor, chebspace, chebspace1, estimateDegreeOfPole
-from utils import debug_plot
-from utils import chebt2, ichebt2, chebt1, ichebt1, chebroots
-
-from vartransforms import *
+from . import params
+
+from .utils import cheb_nodes_log, incremental_cheb_nodes_log
+from .utils import cheb_nodes, incremental_cheb_nodes, cheb_nodes1, incremental_cheb_nodes1
+from .utils import combine_interpolation_nodes, combine_interpolation_nodes_fast
+from .utils import convergence_monitor, chebspace, chebspace1, estimateDegreeOfPole
+from .utils import debug_plot
+from .utils import chebt2, ichebt2, chebt1, ichebt1, chebroots
+
+from .vartransforms import *
 
 
 # import faster Cython versions if possible
@@ -45,9 +45,9 @@
     #import pyximport; pyximport.install()
     from bary_interp import bary_interp
     have_Cython = True
-    print "Using compiled interpolation routine"
+    print("Using compiled interpolation routine")
 except:
-    print "Compiled interpolation routine not available"
+    print("Compiled interpolation routine not available")
     have_Cython = False
 
 
@@ -210,7 +210,7 @@
             err = self.test_accuracy(new_Xs, new_Ys)
             maxy = max(abs(new_Ys).max(), abs(self.Ys).max())
             if par.debug_info:
-                print "interp. err", err, old_err, new_n
+                print("interp. err", err, old_err, new_n)
             cm.add(err, maxy)
             if cm.test_convergence()[0]:
                 break
@@ -221,7 +221,7 @@
         if par.debug_plot and n >= maxn:
             debug_plot(self.a, self.b, self.Xs, self.Ys, None)
         if par.debug_info:
-            print "interp. err = ", err, "nodes=", n
+            print("interp. err = ", err, "nodes=", n)
         self.err = err
     def test_accuracy(self, new_Xs, new_Ys):
         """Test accuracy by compa true and interpolated values at
@@ -354,7 +354,7 @@
             err = self.test_accuracy(new_Xs, new_Ys)
             maxy = max(abs(new_Ys).max(), abs(self.Ys).max())
             if par.debug_info:
-                print "interp. err1", err, maxy, old_err, "nodes=", n, maxn      
+                print("interp. err1", err, maxy, old_err, "nodes=", n, maxn)      
             cm.add(err, maxy)
             if cm.test_convergence()[0]:
                 break
@@ -365,7 +365,7 @@
         if par.debug_plot and n >= maxn:
             debug_plot(self.a, self.b, self.Xs, self.Ys, None)
         if par.debug_info:
-            print "interp. err1 = ", err, "nodes=", n
+            print("interp. err1 = ", err, "nodes=", n)
         self.err = err
     def test_accuracy(self, new_Xs, new_Ys):
         """Test accuracy by comparing true and interpolated values at
@@ -424,7 +424,7 @@
     return interp.spec_f(x)
 def _wrap_f(f):
     if params.general.parallel:
-        return partial(_call_f, f.im_self)
+        return partial(_call_f, f.__self__)
     return f
 
 class ValTransformInterpolator(ChebyshevInterpolator1):
@@ -471,7 +471,7 @@
         self.a = a
         self.b = b
         if par.debug_info:
-            print "exponent=", self.exponent         
+            print("exponent=", self.exponent)         
         super(ChebyshevInterpolatorNoL2, self).__init__(lambda x: f(x) / x ** self.exponent, a, b,
                                                         par=params.interpolation,
                                                         *args, **kwargs)
@@ -489,7 +489,7 @@
         self.a = a
         self.b = b
         if par.debug_info:
-            print "exponent=", self.exponent         
+            print("exponent=", self.exponent)         
         super(ChebyshevInterpolatorNoR2, self).__init__(lambda x: f(x) / abs(x) ** self.exponent, a, b,
                                                        par=params.interpolation,
                                                        *args, **kwargs)
@@ -513,7 +513,7 @@
         if b is None:
             b = _find_zero(f, a)
             if par.debug_info:
-                print "found", b, f(b)
+                print("found", b, f(b))
         self.orig_a = a
         self.orig_b = b
         self.offset = offset - 1
@@ -692,7 +692,7 @@
         first_interp = True
         while True:
             Ltmp = Utmp * minx
-            print "[", Ltmp, Utmp, "]"
+            print("[", Ltmp, Utmp, "]")
             if first_interp:
                 I = interp_class(f, Ltmp, Utmp)
                 first_interp = False
@@ -709,7 +709,7 @@
         for I in self.interps:
             Xs += list(I.Xs)
             Ys += list(I.Ys)
-        XYs = zip(Xs, Ys)
+        XYs = list(zip(Xs, Ys))
         XYs.sort()
         self.Xs = array([t[0] for t in XYs])
         self.Ys = array([t[1] for t in XYs])
@@ -830,8 +830,8 @@
         if params.interpolation_asymp.debug_info:
             #print "vb.minmax", L, Ut
             if self.vl is not None:
-                print "vl.minmax", self.vl.orig_a, self.vl.orig_b
-            print "self.x_vb_max", self.x_vb_max, #self.f(self.x_vb_max)
+                print("vl.minmax", self.vl.orig_a, self.vl.orig_b)
+            print("self.x_vb_max", self.x_vb_max, end=' ') #self.f(self.x_vb_max)
     def interp_at(self, x):
         if isscalar(x):
             if self.x_vb_max is None or x <= self.x_vb_max:
@@ -905,17 +905,17 @@
     B = PiecewiseFunction(fun=lambda x:sin(3*x), breakPoints=[-1,0,1])
     
     B = B.toInterpolated()
-    print B.segments[0].f.__class__
+    print(B.segments[0].f.__class__)
     #B = B.trimInterpolators(abstol=1e-15)
-    print B.segments[0].f.Ys, B.segments[0].f.__class__
+    print(B.segments[0].f.Ys, B.segments[0].f.__class__)
     D = B.diff()
     D2 = D.diff()
     D3 = D2.diff()
     D4 = D3.diff()
     D5 = D4.diff()
-    print D.segments[0].f.Ys, D.segments[0].f.__class__ RefactoringTool: Refactored ./params.py
RefactoringTool: Refactored ./rv.py
RefactoringTool: Refactored ./segments.py

-    print D2.segments[0].f.Ys
-    print D.roots()
+    print(D.segments[0].f.Ys, D.segments[0].f.__class__) 
+    print(D2.segments[0].f.Ys)
+    print(D.roots())
     figure()
     B.plot()
     D.plot()
@@ -1017,7 +1017,7 @@
     #print ci.err, len(ci.Xs)
 
     for pdf in [chisqr, lambda x:-log(x)]:#, cauchy, lambda x: 1.0/(1+x**1.5), prodcauchy]:#, prodcauchy, prodcauchy_uni, chisqr, lambda x: sin(3*x)]:
-        print "======================================="
+        print("=======================================")
         x1 = 0.0
         x2 = 0.1
         #x1, x2 = 2.01029912342, 2.82968863313
@@ -1027,16 +1027,16 @@
         #normpdf = lambda x:chisqr(x,1)
         #ci = ChebyshevInterpolatorNoR2(pdf, x1, x2)
         #cii = ChebyshevInterpolatorNoL2(pdf, x1, x2)
-        print "1=============="
+        print("1==============")
         #cii = PInfInterpolator(pdf, 2)
         #mii = MInfInterpolator(pdf, -x1)
         from numpy import log, exp
         cii = LogXChebyshevInterpolator(lambda x: log(pdf(x)), 1e-50, x2)
-        print "2=============="
+        print("2==============")
         dii = ChebyshevInterpolator(lambda x: log(pdf(exp(x))), -50, -1)
         #dii = ChebyshevInterpolatorNoL2(pdf, x1, x2)
         #dii = ChebyshevInterpolator(pdf, 2, 10)
-        print "3=============="
+        print("3==============")
         #ci = LogXChebyshevInterpolator(pdf, 10, 10000)
         ci = PoleInterpolatorP(pdf, x1, x2)
         #dii = cii
@@ -1088,9 +1088,9 @@
         plot(X, abs(Y4 - Y2) / Y4, 'r')    
         plot(X, abs(Y4 - Y3) / Y4, 'b')    
 
-        from integration import *
+        from .integration import *
         #print integrate_fejer2_Xn_transformP(cii, x1, 3, N=4) + integrate_fejer2_pinf(cii, 3, x2)
-        print integrate_fejer2_Xn_transformP(pdf, 0, 3, N=4, debug_info=False)[0] + integrate_fejer2_pinf(cii, 3, debug_info=False)[0]
+        print(integrate_fejer2_Xn_transformP(pdf, 0, 3, N=4, debug_info=False)[0] + integrate_fejer2_pinf(cii, 3, debug_info=False)[0])
         #print integrate_fejer2_Xn_transformP(dii, x1, x2, N=3)
         #print integrate_fejer2_pinf(cii, x1, x2)
         #print integrate_fejer2_pinf(dii, x1, x2)
@@ -1101,11 +1101,11 @@
         #print ci.Xs
         #print cii.Xs
 
-        from integration import *
+        from .integration import *
         #print integrate_fejer2_Xn_transformP(cii, x1, 3, N=4) + integrate_fejer2_pinf(cii, 3, x2)
         #print integrate_fejer2_Xn_transformP(normpdf, 0, 1, N=4)[0] + integrate_fejer2_pinf(cii, 1, x2)[0]
-        print "1:", integrate_fejer2_Xn_transformP(normpdf, x1, x2, N=4)
-        print "2:", integrate_fejer2_Xn_transformP(dii, x1, x2, N=4)
+        print("1:", integrate_fejer2_Xn_transformP(normpdf, x1, x2, N=4))
+        print("2:", integrate_fejer2_Xn_transformP(dii, x1, x2, N=4))
         #print "3:", integrate_fejer2_Xn_transformN(funneg, -x2, -x1, N=4)
         #print "4:", integrate_fejer2_Xn_transformN(eii, -x2, -x1, N=4)
         #print integrate_fejer2_pinf(cii, x1, x2)
--- ./params.py	(original)
+++ ./params.py	(refactored)
@@ -15,7 +15,7 @@
     return slist
 def str_params(p = None):
     if p is None:
-        import params
+        from . import params
         p = params
     slist = _str_params_list(p)
     return "\n".join(slist)
@@ -156,11 +156,11 @@
     debug_plot = False
     
 if __name__ == "__main__":
-    print "integration.convergence.reltol=", integration.convergence.reltol
-    print str_params()
-    print
-    print str_params(integration)
-    print segments.integration.maxn
-    print interpolation_finite.maxn
-    print interpolation_asymp.maxn
+    print("integration.convergence.reltol=", integration.convergence.reltol)
+    print(str_params())
+    print()
+    print(str_params(integration))
+    print(segments.integration.maxn)
+    print(interpolation_finite.maxn)
+    print(interpolation_asymp.maxn)
 
--- ./rv.py	(original)
+++ ./rv.py	(refactored)
@@ -10,8 +10,8 @@
 import sympy
 from sympy import var
 
-import params
-from sympy_utils import sympy_min, sympy_max, sympy_abs
+from . import params
+from .sympy_utils import sympy_min, sympy_max, sympy_abs
 
 class RV(object):
     def __init__(self, parents = [], sym = None, a=0.0, b=1.0):
@@ -19,7 +19,7 @@
         self.a = a
         self.b = b
         if sym is not None:         # ====set symbolic name of r.v
-            if isinstance(sym, basestring):
+            if isinstance(sym, str):
                 self.sym = sympy.Symbol(sym)
             else:
                 self.sym = sym      # user defined symbolic name of r.v.
@@ -552,17 +552,17 @@
     y = RV(sym="y")
     z = RV(sym="z")
     u = x + y
-    print ">>", u.getParentsAll()
-    print ">>", u.getParentsFree()
+    print(">>", u.getParentsAll())
+    print(">>", u.getParentsFree())
     u.setSym("u")
-    print u.getEquations()
+    print(u.getEquations())
     v = u + z
     v.setSym("v")
 
-    print v.getEquations()
-
-    print u.getSym()
-    print v.getSym()
+    print(v.getEquations())
+
+    print(u.getSym())
+    print(v.getSym())
 
 
 #    print d;
--- ./segments.py	(original)
+++ ./segments.py	(refactored)
@@ -5,11 +5,11 @@
 import operator
 from functools import partial
 
-from integration import *
-from interpolation import *
-from utils import epsunique, estimateDegreeOfPole, testPole, findinv, estimateTailExponent, is_instance_method
-
-import params
+from .integration import *
+from .interpolation import *
+from .utils import epsunique, estimateDegreeOfPole, testPole, findinv, estimateTailExponent, is_instance_method
+
+from . import params
 
 from numpy import asfarray
 from numpy import linspace, multiply, add, divide, size
@@ -99,7 +99,7 @@
 def wrap_f(f):
     if params.general.parallel:
         if is_instance_method(f):
-            return partial(_call_f, f.im_self)
+            return partial(_call_f, f.__self__)
         return f
     return f
 def _safe_fun_on_f_call(seg, fun, x):
@@ -1164,7 +1164,7 @@
     def maximum(self):
         """Mode, using scipy's function fminbound, may be inaccurate """
         if not have_Scipy_optimize:
-            print "Warning: scipy's fminbound not found"      
+            print("Warning: scipy's fminbound not found")      
             return None
         m = 0
         x = None
@@ -1186,7 +1186,7 @@
     def minimum(self):
         """Mode, using scipy's function fminbound, may be inaccurate """
         if not have_Scipy_optimize:
-            print "Warning: scipy's fminbound not found"      
+            print("Warning: scipy's fminbound not found")      
             return None
         m = 0
         x = None
@@ -1238,7 +1238,7 @@
                         h1 = float(seg.f((seg.a + seg.b)/2))
                     else:
                         h1 = float(seg.f(xi+1e-10))
-            except Exception, e:           
+            except Exception as e:           
                 h1 = 0.0
                 h0 = 0.0
             seg.plot(xmin = xmin,
@@ -1253,7 +1253,7 @@
                     h0 = float(seg.f((seg.a + seg.b)/2))
                 else:
                     h0 = float(seg.f(seg.b-1e-10))
-            except Exception, e:           
+            except Exception as e:           
                 h0 = 0.0
             # plot right dashed line if next segment further off
             if i < len(self.segments) - 1 and self.segments[i+1].a > seg.b + params.segments.unique_eps:
@@ -1490,7 +1490,7 @@
             row = '{0} & {1} & {2} & {3}  & {4}  \\\\ \\hline \n'.format(i, seg.__class__.__name__, seg.a, seg.b, ni)
             str+=row
         str += "\\end{tabular}"
-        print str
+        print(str)
     
     def add_diracs(self, other):
         """Pointwise sum of discrete part of two piecewise functions """
@@ -1755,8 +1755,8 @@
                 ind = where((vals[i][1]<=y) & (y<=vals[i+1][0]))   
                 x[ind] = breaks[i+1]                 
         if (x is None): # It means
-            print "ASSERT x is None y=", y, self.__str__()
-            print "ASSERT x is None vals=", vals
+            print("ASSERT x is None y=", y, self.__str__())
+            print("ASSERT x is None vals=", vals)RefactoringTool: Refactored ./standard_distr.py
RefactoringTool: Refactored ./sympy_utils.py
RefactoringTool: Refactored ./utils.py

             #assert(False)
             x = NaN
         return x #findinv(self, a = self.breaks[0], b = self.breaks[-1]-1e-10, c = level, rtol = params.segments.rtol)
@@ -1872,7 +1872,7 @@
     def mode(self):
         """Mode, using scipy's function fminbound, may be inaccurate """
         if not have_Scipy_optimize:
-            print "Warning: scipy's fminbound not found"      
+            print("Warning: scipy's fminbound not found")      
             return None
         m = 0
         x = None
@@ -2019,7 +2019,7 @@
     #print params.integration_infinite.exponent
     if L > U:
         if params.segments.debug_info:
-            print "Warning: reversed integration interval, returning 0"
+            print("Warning: reversed integration interval, returning 0")
         return 0, 0
     if L == U:
         return 0, 0
@@ -2050,7 +2050,7 @@
     elif L<U:
         i, e = integrate_fejer2_pminf(fun, debug_info = debug_info, debug_plot = debug_plot, exponent = params.integration_infinite.exponent,)
     else:
-        print "errors in _conv_div: x, segi, segj, L, U =", L, U
+        print("errors in _conv_div: x, segi, segj, L, U =", L, U)
     #print "========"
     #if e>1e-10:
     #    print "error L=", L, "U=", U, fun(array([U])), force_minf , force_pinf , force_poleL, force_poleU
@@ -2066,11 +2066,11 @@
     for fi in f.getDiracs():
         for gi in g.getDiracs():
             key = fun(fi.a, gi.a)            
-            if wyn.has_key(key):
+            if key in wyn:
                 wyn[key] = wyn.get(key) + fi.f * gi.f
             else:  
                 wyn[key] = fi.f * gi.f
-    for key in wyn.keys():
+    for key in list(wyn.keys()):
         fg.addSegment(DiracSegment(key, wyn.get(key)))
     return fg
 
--- ./standard_distr.py	(original)
+++ ./standard_distr.py	(refactored)
@@ -11,11 +11,11 @@
 from functools import partial
 _MAX_EXP_ARG = log(finfo(double).max)
 
-import params
-from utils import lgamma, wrap_pdf
-from distr import Distr, DiscreteDistr, ConstDistr
-from segments import PiecewiseFunction, PiecewiseDistribution, Segment
-from segments import ConstSegment, PInfSegment, MInfSegment, SegmentWithPole
+from . import params
+from .utils import lgamma, wrap_pdf
+from .distr import Distr, DiscreteDistr, ConstDistr
+from .segments import PiecewiseFunction, PiecewiseDistribution, Segment
+from .segments import ConstSegment, PInfSegment, MInfSegment, SegmentWithPole
 
 try:
     from numpy import Inf
@@ -29,7 +29,7 @@
         super(FunDistr, self).__init__(**kwargs)
         self.fun = fun
         self.breakPoints = breakPoints
-        if kwargs.has_key("sym"):
+        if "sym" in kwargs:
             kwargs.pop("sym")
         self.kwargs = kwargs
         self.interpolated = interpolated  
@@ -279,7 +279,7 @@
                                                         lpoles=[True, False, False, False])
             
         else:
-            print "unexeepted df=", self.df            
+            print("unexeepted df=", self.df)            
         #if self.df == 1 or self.df == 3:
         #    self.piecewise_pdf.addSegment(SegmentWithPole(0, 1, self.pdf, left_pole = True))
         #else:
@@ -886,7 +886,7 @@
         xi = [0]
         pi = [P]
         pq = self.p / self.q
-        for i in xrange(n):
+        for i in range(n):
             P *= n - i
             P /= i + 1
             P *= pq
@@ -909,7 +909,7 @@
 
 if __name__ == "__main__":
     from pylab import figure, show
-    from distr import demo_distr, log, exp, max, min, sqrt
+    from .distr import demo_distr, log, exp, max, min, sqrt
 
     import numpy
     from numpy import ceil, log1p
--- ./sympy_utils.py	(original)
+++ ./sympy_utils.py	(refactored)
@@ -8,7 +8,7 @@
 import sympy
 import sympy.printing.lambdarepr
 
-import params
+from . import params
 
 # sympy defines max, min and abs differently in different versions
 try:
@@ -63,7 +63,7 @@
 _numpy_funcs = [("sqrt", np.sqrt), ("log", np.log), ("exp", np.exp)]
 def _my_lambdify_helper(expr_str, argnames, *argvals):
     #print expr_str, argnames, argvals, dict(_numpy_funcs + zip(argnames, argvals))
-    return eval(expr_str, globals(), dict(_numpy_funcs + zip(argnames, argvals)))
+    return eval(expr_str, globals(), dict(_numpy_funcs + list(zip(argnames, argvals))))
 def my_lambdify(args, expr, modules=None, printer=None, use_imps=True):
     """Lambdify sympy expressions without using lambda functions."""
     if params.general.parallel:
--- ./utils.py	(original)
+++ ./utils.py	(refactored)
@@ -33,7 +33,7 @@
 #from scipy.fftpack.basic import fft
 from scipy.optimize import fmin_cg,fmin, fmin_tnc
 
-import params
+from . import params
 
 # safe infinity
 try:
@@ -49,7 +49,7 @@
     return obj.pdf(x)
 def wrap_pdf(pdf):
     if params.general.parallel:
-        return partial(_call_pdf, pdf.im_self)
+        return partial(_call_pdf, pdf.__self__)
     return pdf
 
 
@@ -182,15 +182,15 @@
     #TODO
     """inverse chebyshev transformation, see chebfun"""
     n = len(c)
-    print "tam===", n
+    print("tam===", n)
     oncircle = concatenate((c[-1::-1], c[1:-1]));
-    print "v=", oncircle, n
+    print("v=", oncircle, n)
     v = real(ifft(oncircle));
-    print v
-    print v[-2:n:-1]
-    print "|", v[1:-1]
+    print(v)
+    print(v[-2:n:-1])
+    print("|", v[1:-1])
     f = (n-1)*concatenate(([2*v(1)], v[-2:n:-1]+v[1:-1], 2*v[-1]));
-    print "|", f
+    print("|", f)
     return f
 
 def cheb1companion(c):
@@ -234,7 +234,7 @@
     ri = yi[0:-1] - yi[1:]
     di = abs(xi[1:]-xi[0:-1])
     if debug_plot:
-        print xi,yi, f(xi)
+        print(xi,yi, f(xi))
         loglog(xi,yi)
     if len(yi) > 1:
         return ri[-1]/di[-1]
@@ -260,7 +260,7 @@
     ri = yi[0:-1] - yi[1:]
     di = abs(xi[1:]-xi[0:-1])
     if debug_plot:
-        print xi,yi, f(xi)
+        print(xi,yi, f(xi))
         loglog(xi,yi)
     if len(yi) > 1:
         return ri[-1]/di[-1]
@@ -287,7 +287,7 @@
         else:
             pole = True
     if debug_info:
-        print "x={0}, deg={1}, pole={2} check_deriv={3}".format(x, deg, pole, deriv)
+        print("x={0}, deg={1}, pole={2} check_deriv={3}".format(x, deg, pole, deriv))
     return pole
 
 class convergence_monitor(object):
@@ -345,7 +345,7 @@
         else:
             best_re = best_ae / abs(best_y)
         best_e = self.e_list[0]
-        for i in xrange(1, len(self.ae_list)):
+        for i in range(1, len(self.ae_list)):
             y = self.y_list[i]
             ae = self.ae_list[i]
             if y == 0:
@@ -397,7 +397,7 @@
     if fb == 0: return xb
 
     dm = xb - xa
-    for i in xrange(maxiter):
+    for i in range(maxiter):
         dm /= 2
         xm = xa + dm
         fm = f(xm, *args)
@@ -405,7 +405,7 @@
             xa = xm
         if fm == 0 or abs(dm) < tol:
             return xm
-    print "WARNING: zero fidning did not converge"
+    print("WARNING: zero fidning did not converge")
     return xm
 
 def estimateTailExponent(f, fromTo = None, N =300, deriv = False, debug_plot = False, pos = True):
@@ -425,7 +425,7 @@
     ri = yi[1:] - yi[0:-1]
     di = abs(xi[1:]-xi[0:-1])
     if debug_plot:
-        print ri, di
+        print(ri, di)
         plot(xi,yi)
     if len(yi) > 1:
         ex = ri[-1]/di[-1]
@@ -468,13 +468,13 @@
 try:
     from math import lgamma
 except:
-    from gamma import lgamma
+    from .gamma import lgamma
 
 def binomial_coeff(n, k):
     if k > n - k: # take advantage of symmetry
         k = n - k
     c = 1
-    for i in xrange(k):
+    for i in range(k):
         c = c * (n - i)
         c = c / (i + 1)
     return c
@@ -484,7 +484,7 @@
     c = 1
     j=0
     for k in ki:
-        for i in xrange(k):
+        for i in range(k):
             c = c * (n - j)
             c = c / (i + 1)
             j += 1
@@ -492,7 +492,7 @@
 
 def taylor_coeff(fun, N):
     """From L. Trefethen, Ten digits algorithms """
-    zz = exp(2j*pi*(array(range(N)))/N)
+    zz = exp(2j*pi*(array(list(range(N))))/N)
     c = fft(fun(zz))/N
     return real(c)
 
@@ -544,9 +544,9 @@
     """Checks if an object is a bound method on an instance."""
     if not isinstance(obj, types.MethodType):
         return False # Not a methodRefactoringTool: Refactored ./vartransforms.py
RefactoringTool: Refactored ./bindings/PacalServer.py
RefactoringTool: Refactored ./depvars/copulas.py

-    if obj.im_self is None:
+    if obj.__self__ is None:
         return False # Method is not bound
-    if issubclass(obj.im_class, type) or obj.im_class is types.ClassType:
+    if issubclass(obj.__self__.__class__, type) or obj.__self__.__class__ is type:
         return False # Method is a classmethod
     return True
 
@@ -574,10 +574,10 @@
     import numpy.polynomial.chebyshev as ch
     c = array([1, 2, 3, 1])
     CT =cheb1companion(array([1, 2, 3, 1]))
-    print CT
-    print chebroots(c)
-    print ch.chebroots(c)
-    print chebroots(c) - ch.chebroots(c)
+    print(CT)
+    print(chebroots(c))
+    print(ch.chebroots(c))
+    print(chebroots(c) - ch.chebroots(c))
     0/0
     #print taylor_coeff(lambda x:exp(x), 30)
     N = NormalDistr()
@@ -585,7 +585,7 @@
     #fun.plot()
     t0  = time.time()
     t_i =  taylor_coeff(fun, 100)
-    print time.time()-t0
+    print(time.time()-t0)
     sil=1
 
     t0  = time.time()
@@ -595,23 +595,23 @@
         else:
             sil *= i
         mi = N.moment(i, 0.0)
-        print i, repr(mi),  repr(t_i[i])*sil*2,  repr(mi/sil/2), repr(t_i[i]), repr(mi/sil/2-t_i[i]);
-    print time.time()-t0
-
-
-    print N.summary()
+        print(i, repr(mi),  repr(t_i[i])*sil*2,  repr(mi/sil/2), repr(t_i[i]), repr(mi/sil/2-t_i[i]));
+    print(time.time()-t0)
+
+
+    print(N.summary())
     show()
     0/0
-    print binomial_coeff(10, 7)
-    print multinomial_coeff(10, [3, 3, 4])
-    print multinomial_coeff(13, [7, 2, 4])
-    print multinomial_coeff(21, [9, 8, 4])
+    print(binomial_coeff(10, 7))
+    print(multinomial_coeff(10, [3, 3, 4]))
+    print(multinomial_coeff(13, [7, 2, 4]))
+    print(multinomial_coeff(21, [9, 8, 4]))
     0/0
 
-    from standard_distr import *
+    from .standard_distr import *
     from pylab import *
 
-    print estimateTailExponent(LevyDistr(), pos = True)
+    print(estimateTailExponent(LevyDistr(), pos = True))
     L = LevyDistr()
     L.summary()
 
@@ -626,7 +626,7 @@
         S = S + S
         subplot(211)
         (S/(2**(i))).plot(xmin=0,xmax=50)
-        print i,
+        print(i, end=' ')
         (S/(2**(i))).summary()
         subplot(212)
         r = S.get_piecewise_pdf() - S_1.get_piecewise_pdf()
@@ -670,19 +670,19 @@
     from numpy import ones_like, zeros_like
     def _pole_test(f, x, pos = True, deriv = False):
         return str(testPole(f, x, pos, deriv = deriv)) + "   " + str(estimateDegreeOfPole(f, x, pos)) + "   " + str(estimateDegreeOfPole(f, x, pos, deriv = True))
-    print "0,", _pole_test(lambda x: ones_like(x), 0)
-    print "0',", _pole_test(lambda x: ones_like(x), 0, deriv = True)
-    print "1,", _pole_test(lambda x: zeros_like(x), 0)
-    print "x,", _pole_test(lambda x: x, 0)
-    print "x',", _pole_test(lambda x: x, 0, deriv = True)
-    print "x**1.5,", _pole_test(lambda x: x**1.5, 0)
-    print "x**0.5,", _pole_test(lambda x: x**0.5, 0)
-    print "-log(x),", _pole_test(lambda x: -log(x), 0)
-    print "-log(sqrt(x)),", _pole_test(lambda x: -log(sqrt(x)), 0)
-    print "-log(-x),", _pole_test(lambda x: -log(-x), 0, pos = False)
-    print "1+x**0.5,", _pole_test(lambda x: 1+x**0.5, 0)
-    print "(1+x**0.5)',", _pole_test(lambda x: 1+x**0.5, 0, deriv = True)
-    print "x*log(x),", _pole_test(lambda x: x*log(x), 0)
-    print _pole_test(lambda x: 1+(1*x+7)*x**-2.5, 0)
-    print testPole(lambda x: 1.0/abs(2*x-1), 0.5, pos= False)
-    print testPole(lambda x: 9.0*abs(2*x-1), 0.5, pos= True)
+    print("0,", _pole_test(lambda x: ones_like(x), 0))
+    print("0',", _pole_test(lambda x: ones_like(x), 0, deriv = True))
+    print("1,", _pole_test(lambda x: zeros_like(x), 0))
+    print("x,", _pole_test(lambda x: x, 0))
+    print("x',", _pole_test(lambda x: x, 0, deriv = True))
+    print("x**1.5,", _pole_test(lambda x: x**1.5, 0))
+    print("x**0.5,", _pole_test(lambda x: x**0.5, 0))
+    print("-log(x),", _pole_test(lambda x: -log(x), 0))
+    print("-log(sqrt(x)),", _pole_test(lambda x: -log(sqrt(x)), 0))
+    print("-log(-x),", _pole_test(lambda x: -log(-x), 0, pos = False))
+    print("1+x**0.5,", _pole_test(lambda x: 1+x**0.5, 0))
+    print("(1+x**0.5)',", _pole_test(lambda x: 1+x**0.5, 0, deriv = True))
+    print("x*log(x),", _pole_test(lambda x: x*log(x), 0))
+    print(_pole_test(lambda x: 1+(1*x+7)*x**-2.5, 0))
+    print(testPole(lambda x: 1.0/abs(2*x-1), 0.5, pos= False))
+    print(testPole(lambda x: 9.0*abs(2*x-1), 0.5, pos= True))
--- ./vartransforms.py	(original)
+++ ./vartransforms.py	(refactored)
@@ -198,9 +198,9 @@
     def var_change(self, x):
         #assert all(x >= self.L)
         if ~all(x >= self.L):
-            print "assert all(x >= self.L)"
-            print x
-            print x < self.L
+            print("assert all(x >= self.L)")
+            print(x)
+            print(x < self.L)
         t = (x - self.L - self.c) / (x - self.L + self.c)
         return t
     def inv_var_change(self, t):
@@ -222,9 +222,9 @@
         #assert all(x <= self.U)
         
         if ~all(x <= self.U):
-            print "assert all(x >= self.L)"
-            print x
-            print x < self.U
+            print("assert all(x >= self.L)")
+            print(x)
+            print(x < self.U)
         t = (-(x - self.U) - self.c) / (-(x - self.U) + self.c)
         return t
     def inv_var_change(self, t):
@@ -264,11 +264,11 @@
 
 if __name__ == "__main__":
     vt = VarTransformAlgebraic_PMInf()
-    print vt.inv_var_change_with_mask(array([-1,0,1]))
-    print vt.inv_var_change_with_mask(-1)
-    print vt.apply_with_inv_transform(lambda x: x+1, array([-1,0,1]))
-    print vt.apply_with_inv_transform(lambda x: x+1, 0)
-    print vt.apply_with_inv_transform(lambda x: x+1, -1)
+    print(vt.inv_var_change_with_mask(array([-1,0,1])))
+    print(vt.inv_var_change_with_mask(-1))
+    print(vt.apply_with_inv_transform(lambda x: x+1, array([-1,0,1])))
+    print(vt.apply_with_inv_transform(lambda x: x+1, 0))
+    print(vt.apply_with_inv_transform(lambda x: x+1, -1))
 
     from numpy import exp
     from pylab import show
--- ./bindings/PacalServer.py	(original)
+++ ./bindings/PacalServer.py	(refactored)
@@ -9,7 +9,7 @@
             summ = self.ans.summary_map()
             str = " " + self.ans.getName() +"\n"
             for i in ['mean', 'std', 'var', 'tailexp', 'median', 'medianad', 'iqrange(0.025)',  'range', 'ci(0.05)', 'int_err']:
-                if summ.has_key(i): 
+                if i in summ: 
                     str += '{0:{align}20}'.format(i, align = '>') + " = " + "{0}".format(repr(summ[i]))+ "\n"     
             return str
         else:
@@ -17,7 +17,7 @@
         
     def summary(self):
         if isinstance(self.ans, distr.Distr):
-            return [self.ans.summary_map().keys(), self.ans.summary_map().values()]
+            return [list(self.ans.summary_map().keys()), list(self.ans.summary_map().values())]
         else:
             return None  
         
@@ -41,11 +41,11 @@
         else: 
             return self.ans    
     def execpacal(self, cmd):
-        exec cmd
+        exec(cmd)
         return
 
 if __name__=='__main__':
-    print "Registering COM server..."
+    print("Registering COM server...")
     import win32com.server.register
 #    p = PacalServer()
 #    print p.summary()
--- ./depvars/copulas.py	(original)
+++ ./depvars/copulas.py	(refactored)
@@ -156,7 +156,7 @@
         #print params.integration_infinite.exponent
         if L > U:
             if params.segments.debug_info:
-                print "Warning: reversed integration interval, returning 0"
+                print("Warning: reversed integration interval, returning 0")
             return 0, 0
         if L == U:
             return 0, 0
@@ -187,7 +187,7 @@
         elif L<U:
             i, e = integrate_fejer2_pminf(fun, debug_info = debug_info, debug_plot = debug_plot, exponent = params.integration_infinite.exponent,)
         else:
-            print "errors in _conv_div: x, segi, segj, L, U =", L, U
+            print("errors in _conv_div: x, segi, segj, L, U =", L, U)
         return i,e
  
     def cov(self, i=None, j=None):
@@ -199,7 +199,7 @@
             gmean = g.mean()           RefactoringTool: Refactored ./depvars/models.py

             f0, f1 = f.get_piecewise_pdf().range()
             g0, g1 = g.get_piecewise_pdf().range() 
-            print fmean, gmean, var, c_var, f0, f1, g0, g1
+            print(fmean, gmean, var, c_var, f0, f1, g0, g1)
             if i == j:
                 c, e = c, e = integrate_fejer2(lambda x: (x - fmean) ** 2 * f.pdf(x), f0, f1)                  
             else:
@@ -426,12 +426,12 @@
         pi = 1;
         for i in range(self.d):
             pi *= self.fi_deriv(vars[i])
-        print "si=\n", pprint(si)
-        print "pi=\n", pprint(pi)
-        print "C=\n", pprint(self.fi_inv(si))
+        print("si=\n", pprint(si))
+        print("pi=\n", pprint(pi))
+        print("C=\n", pprint(self.fi_inv(si)))
         #print "C=\n", pprint(self.ccdf(*tuple(vars)))
         #print "c=\n", pprint(sympy.simplify(self.fi_inv_nth_deriv(si) * pi))
-        print "c=\n", pprint(self.fi_inv_nth_deriv(si) * pi)
+        print("c=\n", pprint(self.fi_inv_nth_deriv(si) * pi))
         #print "c=\n", pprint(self.cpdf(*tuple(vars)))
     def tau_c(self):
         return 1 + 4 * integrate_fejer2(lambda t : self.fi(t) / self.fi_deriv(t), 0, 1)[0]
@@ -574,16 +574,16 @@
         return NDFun(self.d, self.Vars, fun_)
     def debug_info(self):
         #self.fi_inv_defiv = simplify(sympy.diff(self.sym_fi_inv(self.s, self.theta), self.s))
-        print "theta=", self.theta
-        print "fi(theta)=", self.fi_(self.t, sympy.Symbol("theta"))
-        print "fi=\n", pprint(self.sym_fi) 
-        print "fi_deriv=\n", pprint(self.sym_fi_deriv) 
-        print "fi_inv=\n", self.sym_fi_inv, ",\n", pprint(self.sym_fi_inv) 
-        print "fi_inv_nth_deriv=\n", pprint(self.sym_fi_inv_nth_deriv) 
-        print "fi=\n", sympy.latex(self.sym_fi) 
-        print "fi_deriv=\n", sympy.latex(self.sym_fi_deriv) 
-        print "fi_inv=\n", self.sym_fi_inv, ",\n", sympy.latex(self.sym_fi_inv) 
-        print "fi_inv_nth_deriv=\n", sympy.latex(self.sym_fi_inv_nth_deriv) 
+        print("theta=", self.theta)
+        print("fi(theta)=", self.fi_(self.t, sympy.Symbol("theta")))
+        print("fi=\n", pprint(self.sym_fi)) 
+        print("fi_deriv=\n", pprint(self.sym_fi_deriv)) 
+        print("fi_inv=\n", self.sym_fi_inv, ",\n", pprint(self.sym_fi_inv)) 
+        print("fi_inv_nth_deriv=\n", pprint(self.sym_fi_inv_nth_deriv)) 
+        print("fi=\n", sympy.latex(self.sym_fi)) 
+        print("fi_deriv=\n", sympy.latex(self.sym_fi_deriv)) 
+        print("fi_inv=\n", self.sym_fi_inv, ",\n", sympy.latex(self.sym_fi_inv)) 
+        print("fi_inv_nth_deriv=\n", sympy.latex(self.sym_fi_inv_nth_deriv)) 
     def rand2d_invcdf(self, n):
         u = self.marginals[0].rand_invcdf(n)
         t = UniformDistr().rand(n)
@@ -755,7 +755,7 @@
     """
     f = F.get_piecewise_pdf()
     g = G.get_piecewise_pdf()
-    if  p + q <> 1.0 :
+    if  p + q != 1.0 :
         p1 = abs(p) / (abs(p) + abs(q))
         q = abs(q) / (abs(p) + abs(q))
         p = p1;
@@ -834,7 +834,7 @@
     return wyn
 if __name__ == "__main__":
     from pylab import *
-    from nddistr import plot_2d_distr
+    from .nddistr import plot_2d_distr
 #    # ========= ArchimedeanCopulas tests ============================
 #    A = ArchimedeanSymbolicCopula(fi=lambda t, theta : 1 / theta * (t ** (-theta) - 1),
 #                          #fi_inv=lambda s, theta : (1+ theta*s) ** (-1/theta),
--- ./depvars/models.py	(original)
+++ ./depvars/models.py	(refactored)
@@ -66,7 +66,7 @@
             s += "   " + str(rv.getSymname()) + " ~ " + str(rv.getName()) + "\n"
         s += "dep vars:  " + ", ".join(str(rv.getSymname()) for rv in self.dep_rvs) + "\n"
         s += "Equations:\n"
-        for rv, eq in self.rv_to_equation.iteritems():
+        for rv, eq in self.rv_to_equation.items():
             s += str(rv.getSymname()) + " = " + str(eq) + "(" + str(self.eval_var(rv)) + ")\n"
         s += str(self.nddistr)
         s += "\n"
@@ -74,7 +74,7 @@
         return s
 
     def prepare_var(self, var):
-        if isinstance(var, basestring):
+        if isinstance(var, str):
             var = self.sym_to_rv[sympy.Symbol(var)]
         elif isinstance(var, sympy.Symbol):
             var = self.sym_to_rv[var]
@@ -83,7 +83,7 @@
         """Children of a variable."""
         ch = []
         vsym = var.getSymname()
-        for rv, eq in self.rv_to_equation.iteritems():
+        for rv, eq in self.rv_to_equation.items():
             if vsym in set(eq.atoms(sympy.Symbol)):
                 ch.append(rv)
         return ch
@@ -95,7 +95,7 @@
         free_var = self.prepare_var(free_var)
         dep_var = self.prepare_var(dep_var)
         if params.models.debug_info:
-            print "exchange free variable: ", free_var.getSymname(), "with dependent variable", dep_var.getSymname()
+            print("exchange free variable: ", free_var.getSymname(), "with dependent variable", dep_var.getSymname())
         if not self.is_free(free_var):
             raise RuntimeError("First exchanged variable must be free")
         if not self.is_dependent(dep_var):
@@ -108,9 +108,9 @@
                 raise RuntimeError("Dependent variable has a nonfree parent")
         var_changes, equation = self.var_change_helper(free_var, dep_var)
         if len(var_changes) != 1:
-            print "Equation:", equation, "has multiple solutions"
+            print("Equation:", equation, "has multiple solutions")
             for vc in var_changes:
-                print vc[0]
+                print(vc[0])
             raise RuntimeError("Equations with multiple solutions are not supported")
             #var_changes = var_changes[:1]
 
@@ -120,7 +120,7 @@
         self.dep_rvs.append(free_var)
         self.dep_rvs.remove(dep_var)
         del self.rv_to_equation[dep_var]
-        for rv, eq in self.rv_to_equation.iteritems():
+        for rv, eq in self.rv_to_equation.items():
             if free_var.getSymname() in set(eq.atoms(sympy.Symbol)):
                 self.rv_to_equation[rv] = eq.subs(free_var.getSymname(), inv_transf)
         self.rv_to_equation[free_var] = inv_transf
@@ -152,13 +152,13 @@
             if params.models.debug_info:
                 #print "vars to change: ", free_var.getSymname(), " <- ", dep_var.getSymname(), "=", self.rv_to_equation[dep_var]
                 #print "equation: ", dep_var.getSymname(), "=", self.rv_to_equation[dep_var]
-                print "substitution: ", free_var.getSymname(), "=", uj,
+                print("substitution: ", free_var.getSymname(), "=", uj, end=' ')
                 #print "variables: ", uj_symbols, inv_transf_vars
 
             # Jacobian
             #J = sympy.Abs(sympy.diff(uj, dep_var.getSymname()))
             J = sympy.diff(uj, dep_var.getSymname())
-            print J.atoms()
+            print(J.atoms())
             J_symbols = list(sorted(J.atoms(sympy.Symbol), key = str))
             if len(J_symbols) > 0:
                 jacobian_vars = [self.sym_to_rv[s] for s in J_symbols]
@@ -169,7 +169,7 @@
                 jacobian_vars = []
 
             if params.models.debug_info:
-                print ";  Jacobian=", J
+                print(";  Jacobian=", J)
             #print "variables: ", J_symbols, jacobian_vars
 
             var_changes.append((uj, inv_transf, inv_transf_vars, jacobian))
@@ -177,18 +177,18 @@
 
     def subst_for_rv_in_children(self, var, Xsym):
         """Substitute Xsym for occurrences of var in its children"""
-        for rv, eq in self.rv_to_equation.iteritems():
+        for rv, eq in self.rv_to_equation.items():
             if var.getSymname() in set(eq.atoms(sympy.Symbol)):
                 self.rv_to_equation[rv] = eq.subs(var.getSymname(), Xsym)
 
     def eliminate(self, var):
         var = self.prepare_var(var)
         if params.models.debug_info:
-            print "eliminate variable: ", var.getSymname(),
+            print("eliminate variable: ", var.getSymname(), end=' ')
         if var in self.free_rvs:
             if params.models.debug_info:
-                print " eliminate free via integration"
-            for rv, eq in self.rv_to_equation.iteritems():
+                print(" eliminate free via integration")
+            for rv, eq in self.rv_to_equation.items():
                 if var.getSymname() in set(eq.atoms(sympy.Symbol)):
                     raise RuntimeError("Cannot eliminate free variable on which other variables depend")
             self.nddistr = self.nddistr.eliminate(var)
@@ -196,7 +196,7 @@
             self.all_vars.remove(var)
         elif var in self.dep_rvs:
             if params.models.debug_info:
-                print " eliminate dependent via substitution"
+                print(" eliminate dependent via substitution")
             subs_eq = self.rv_to_equation[var]
             del self.rv_to_equation[var]
             self.subst_for_rv_in_children(var, subs_eq)
@@ -211,22 +211,22 @@
             self.eliminate(var)
     def unchain(self, vars, excluded=[]):
         vars_to_unchain = set(vars) - set(self.free_rvs)
-        print "unchain variables: ", ", ".join(str(rv.getSymname()) for rv in vars_to_unchain)
-        print "unchain variables: ",self.are_free(vars)
-        print "unchain variables: ",self.are_free(vars_to_unchain)
-        print ": ", vars_to_unchain
+        print("unchain variables: ", ", ".join(str(rv.getSymname()) for rv in vars_to_unchain))
+        print("unchain variables: ",self.are_free(vars))
+        print("unchain variables: ",self.are_free(vars_to_unchain))
+        print(": ", vars_to_unchain)
         for i in range(len(vars_to_unchain)):
             for var in vars_to_unchain:
                 #print ">>>>>>.", var.getSymname(), self.rv_to_equation[var]
                 #print ">>", self.rv_to_equation[var].atoms
                 if self.is_dependent(var) and self.are_free(self.rv_to_equation[var].atoms()):
                     for a in self.rv_to_equation[var].atoms():
-                        print ">", a
+                        print(">", a)
                         av = self.prepare_var(a)
-                        print ">=", av
-                        print self.__str__()
+                        print(">=", av)
+                        print(self.__str__())
                         if self.is_free(av) and not av in set(excluded):
-                            print "varschangeL:", av.getSymname(), var.getSymname()
+                            print("varschangeL:", av.getSymname(), var.getSymname())
                             self.varschange(av, var)
                             break
 
@@ -249,7 +249,7 @@
             cond[v] = x
         ii=0
         while wanted_rvs != set(M.all_vars):
-            print "OUTER LOOP| wanted:", [tmp_rv.getSymname() for tmp_rv in wanted_rvs], "all:", [tmp_rv.getSymname() for tmp_rv in M.all_vars], "dep:", [tmp_rv.getSymname() for tmp_rv in M.dep_rvs]
+            print("OUTER LOOP| wanted:", [tmp_rv.getSymname() for tmp_rv in wanted_rvs], "all:", [tmp_rv.getSymname() for tmp_rv in M.all_vars], "dep:", [tmp_rv.getSymname() for tmp_rv in M.dep_rvs])
             # eliminate all dangling variables
             to_remove = []
             for v in M.dep_rvs:
@@ -273,16 +273,16 @@
             exchanged_vars = set()
 
             while wanted_rvs | exchanged_vars != set(M.all_vars):
-                print "INNER LOOP| wanted:", [tmp_rv.getSymname() for tmp_rv in wanted_rvs], "exchanged:", [tmp_rv.getSymname() for tmp_rv in exchanged_vars], "all:", [tmp_rv.getSymname() for tmp_rv in M.all_vars]
+                print("INNER LOOP| wanted:", [tmp_rv.getSymname() for tmp_rv in wanted_rvs], "exchanged:", [tmp_rv.getSymname() for tmp_rv in exchanged_vars], "all:", [tmp_rv.getSymname() for tmp_rv in M.all_vars])
                 #print M.nddistr
                 # find a free var to eliminate
                 ii += 1
                 if params.models.debug_info:
-                    print "---------------step:", ii
+                    print("---------------step:", ii)
                     M.toGraphwiz(f =open("file"+str(ii)+".dot","w+"))
-                    print M
-                    print "---", ii, " ---> #free_vars:", len(M.free_rvs), "#dep_vars:", len(M.dep_rvs), "#eqns=", len(M.rv_to_equation.keys()), "sum=", (len(M.free_rvs) + len(M.dep_rvs)+len(M.rv_to_equation.keys()))
-                    print "------> #free_vars:", len(wanted_rvs), "#dep_vars:", len(exchanged_vars)
+                    print(M)
+                    print("---", ii, " ---> #free_vars:", len(M.free_rvs), "#dep_vars:", len(M.dep_rvs), "#eqns=", len(list(M.rv_to_equation.keys())), "sum=", (len(M.free_rvs) + len(M.dep_rvs)+len(list(M.rv_to_equation.keys()))))
+                    print("------> #free_vars:", len(wanted_rvs), "#dep_vars:", len(exchanged_vars))
                     if have_pgv:
                         G = pgv.AGraph("file"+str(ii)+".dot")
                         G.layout("dot")
@@ -320,7 +320,7 @@
                         key = (1*(fv in wanted_rvs), (nparents-1)*(nchildren-1)) # heuristic for deciding which vars to exchange
                         #key = ((nparents-1 + nterms)*(nchildren-1), 1*(fv in wanted_rvs)) # heuristic for deciding which vars to exchange
                         pairs.append((key, fv, dv))
-                print [(key, fv.getSymname(), dv.getSymname()) for key, fv, dv in sorted(pairs)]
+                print([(key, fv.getSymname(), dv.getSymname()) for key, fv, dv in sorted(pairs)])
                 if len(pairs) > 0:
                     pairs.sort()
                     _key, fv, dv = pairs[0]
@@ -334,11 +334,11 @@
                     break
         if params.models.debug_info:
             ii += 1
-            print "---===-=-=-===-=--=", ii
-            print "==",M.toGraphwiz(f =open("file"+str(ii)+".dot","w+"))
-            print M
-            print "---", ii, " ---> #free_vars:", len(M.free_rvs), "#dep_vars:", len(M.dep_rvs), "#eqns=", len(M.rv_to_equation.keys()), "sum=", (len(M.free_rvs) + len(M.dep_rvs)+len(M.rv_to_equation.keys()))
-            print "------> #free_vars:", len(wanted_rvs), "#dep_vars:", len(exchanged_vars)
+            print("---===-=-=-===-=--=", ii)
+            print("==",M.toGraphwiz(f =open("file"+str(ii)+".dot","w+")))
+            print(M)
+            print("---", ii, " ---> #free_vars:", len(M.free_rvs), "#dep_vars:", len(M.dep_rvs), "#eqns=", len(list(M.rv_to_equation.keys())), "sum=", (len(M.free_rvs) + len(M.dep_rvs)+len(list(M.rv_to_equation.keys()))))
+            print("------> #free_vars:", len(wanted_rvs), "#dep_vars:", len(exchanged_vars))
             if have_pgv:
                 G = pgv.AGraph("file"+str(ii)+".dot")
                 G.layout("dot")
@@ -371,7 +371,7 @@
                 else:
                     note += 1000
         else:
-            for rv, eq in self.rv_to_equation.iteritems():
+            for rv, eq in self.rv_to_equation.items():
                 if var.getSymname() in set(eq.atoms(sympy.Symbol)):
                     note += 1
         return note
@@ -379,7 +379,7 @@
     def condition(self, var, X, **kwargs):
         var = self.prepare_var(var)
         if params.models.debug_info:
-            print "condition on variable: ",  var.getSymname(), "=" ,X
+            print("condition on variable: ",  var.getSymname(), "=" ,X)
         if not self.is_free(var):
             raise RuntimeError("You can only condition on free variables")
         self.subst_for_rv_in_children(var, sympy.S(X))
@@ -434,15 +434,15 @@
         return var in self.dep_rvs
 
     def toGraphwiz(self, f = sys.stdout):
-        print >>f, "digraph G {rankdir = BT"
+        print("digraph G {rankdir = BT", file=f)
         for key in self.free_rvs:
-            print >>f, "\"{0}\"".format(key.getSymname()), " [label=\"{0}\"]".format(key.getSymname())
+            print("\"{0}\"".format(key.getSymname()), " [label=\"{0}\"]".format(key.getSymname()), file=f)
         for key in self.dep_rvs:
-            print >>f, "\"{0}\"".format(key.getSymname()), " [label=\"{0}={1}\"]".format(key.getSymname(),self.rv_to_equation[key])
-        for rv, eq in self.rv_to_equation.iteritems():
+            print("\"{0}\"".format(key.getSymname()), " [label=\"{0}={1}\"]".format(key.getSymname(),self.rv_to_equation[key]), file=f)
+        for rv, eq in self.rv_to_equation.items():
             for a in eq.atoms(sympy.Symbol):RefactoringTool: Refactored ./depvars/nddistr.py

-                print >>f, "\"{0}\" -> \"{1}\"".format(str(a), str(rv.getSymname()))
-        print >>f, "}"
+                print("\"{0}\" -> \"{1}\"".format(str(a), str(rv.getSymname())), file=f)
+        print("}", file=f)
 
 class TwoVarsModel(Model):
     """Two dimensional model with one equation"""
@@ -724,14 +724,14 @@
     S = X + Y; S.setSym("S")
     #P = NDProductDistr([X, Y])
     M = Model([X, Y], [S])
-    print M
+    print(M)
     #M2 = M.inference(wanted_rvs = [X])
     #M2 = M.inference(wanted_rvs = [X], cond_rvs = [Y], cond_X = [1.5])
     #M2 = M.inference(wanted_rvs = [S])
     #M2 = M.inference(wanted_rvs = [S], cond_rvs = [Y], cond_X = [1.5]) #! NaN moments!
     #M2 = M.inference(wanted_rvs = [X], cond_rvs = [S], cond_X = [2.5])
     M2 = M.inference(wanted_rvs = [X, Y], cond_rvs = [S], cond_X = [2.5]).plot()
-    print "===", M2
+    print("===", M2)
 
     #M.plot()
     show()
@@ -743,13 +743,13 @@
     R = N / D; R.setSym("R")
     P = NDProductDistr([X, Y])
     M = Model(P, [N, D, R])
-    print M
+    print(M)
     M2 = M.inference(wanted_rvs = [R])
     M2.plot()
     0/0
     M.varschange(X, N)
     M.eliminate(X)
-    print M
+    print(M)
     M.plot()
     show()
     0/0
@@ -843,7 +843,7 @@
 
     V=X2-X1
 
-    print "p=", V.parents[1].getSym()
+    print("p=", V.parents[1].getSym())
     mR = TwoVarsModel(cij, V)
     funR = mR.eval()
     funR.summary()
--- ./depvars/nddistr.py	(original)
+++ ./depvars/nddistr.py	(refactored)
@@ -53,7 +53,7 @@
         i=0
         if Vars is None:
             i+=-1
-            Vars = [RV(sym=LETTERS[i]) for i in xrange(d)]
+            Vars = [RV(sym=LETTERS[i]) for i in range(d)]
         self.Vars = Vars
         var_ids = [v.id() for v in self.Vars]
         self.id_to_idx = dict((id, idx) for idx, id in enumerate(var_ids))
@@ -68,7 +68,7 @@
             self.fun = fun
     def dump_symVars(self):
         for sv in self.Vars:
-            print '{0}={1}'.format(sv.getSymname(), sv.getSym())
+            print('{0}={1}'.format(sv.getSymname(), sv.getSym()))
     def fun(self, *X):
         pass
     def __call__(self, *X):
@@ -76,7 +76,7 @@
             y = self.fun(*X)
         elif isscalar(X[0]):
             mask = (X[0] >= self.a[0]) and (X[0] <= self.b[0])
-            for i in xrange(1, len(X)):
+            for i in range(1, len(X)):
                 mask = mask or ((X[i] >= self.a[i]) and (X[i] <= self.b[i]))
             if mask:
                 y = self.fun(*X)
@@ -84,7 +84,7 @@
                 y = 0
         else:
             mask = (X[0] >= self.a[0]) & (X[0] <= self.b[0])
-            for i in xrange(1, len(X)):
+            for i in range(1, len(X)):
                 mask &= ((X[i] >= self.a[i]) & (X[i] <= self.b[i]))
             y = zeros_like(X[0])
             y[mask] = self.fun(*[xi[mask] for xi in X])
@@ -255,7 +255,7 @@
                 y = integrate_fejer2(partial(self.integ_f, X), ndfun.a[v1], ndfun.b[v1])
             return y[0]
         y = asfarray(zeros_like(X[0]))
-        for i in xrange(len(X[0])):
+        for i in range(len(X[0])):
             # TODO: fix integration bounds!!!!
             if hasattr(self.ndfun, "f"):
                 y[i] = integrate_fejer2(partial(self.integ_f, [x[i] for x in X]), ndfun.f.a[v1], ndfun.f.b[v1])[0]
@@ -297,7 +297,7 @@
         unnormalized = NDInterpolatedDistr(len(c_var), partial(_cond_f, self, arg, c_var, var, X), [self.Vars[i] for i in c_var])
         normalize = kwargs.get("normalize", True)
         if normalize:
-            nrm = unnormalized.eliminate(range(unnormalized.d))
+            nrm = unnormalized.eliminate(list(range(unnormalized.d)))
             if isinstance(nrm, NDConstFactor):
                 nrm = nrm.c
             elif isinstance(nrm, NDProductDistr):
@@ -333,7 +333,7 @@
             else:
                 y =  zeros_like(x)
                 for i in range(len(x)):
-                    print i, "|||", _fun(x[i])
+                    print(i, "|||", _fun(x[i]))
                     y[i] = _fun(x[i])
                 return y
             #distr = FunDistr(fun=self.condition([c_var], x).distr_pdf, breakPoints=var.get_piecewise_pdf().getBreaks())
@@ -412,7 +412,7 @@
         #print params.integration_infinite.exponent
         if L > U:
             if params.segments.debug_info:
-                print "Warning: reversed integration interval, returning 0"
+                print("Warning: reversed integration interval, returning 0")
             return 0, 0
         if L == U:
             return 0, 0
@@ -443,7 +443,7 @@
         elif L<U:
             i, e = integrate_fejer2_pminf(fun, debug_info = debug_info, debug_plot = debug_plot, exponent = params.integration_infinite.exponent,)
         else:
-            print "errors in _conv_div: x, segi, segj, L, U =", L, U
+            print("errors in _conv_div: x, segi, segj, L, U =", L, U)
         #print "========"
         #if e>1e-10:
         #    print "error L=", L, "U=", U, fun(array([U])), force_minf , force_pinf , force_poleL, force_poleU
@@ -513,7 +513,7 @@
         assert len(Sigma.shape) == 2
         assert Sigma.shape[0] == Sigma.shape[1] == d
         if Vars is None:
-            Vars = [NormalDistr(mu[i], Sigma[i,i], sym = LETTERS[i]) for i in xrange(d)]
+            Vars = [NormalDistr(mu[i], Sigma[i,i], sym = LETTERS[i]) for i in range(d)]
         super(NDNormalDistr, self).__init__(d, Vars)
         self.marginals = self.Vars
         self.a = [m-5 for m in mu] # FIX THIS!!!
@@ -528,7 +528,7 @@
             return self.nrm * exp(-0.5 * dot(X, dot(self.invSigma, X).T))
         else:
             Xa = asfarray(X)
-            Xa = Xa.transpose(range(1, len(X[0].shape) + 1) + [0])
+            Xa = Xa.transpose(list(range(1, len(X[0].shape) + 1)) + [0])
             Xa -= self.mu
             Z = (dot(Xa, self.invSigma) * Xa).sum(axis= -1)
             return self.nrm * exp(-0.5 * Z)
@@ -565,7 +565,7 @@
         Vars = marginals
         self.marginals = marginals
         if Vars is None:
-            Vars = [NormalDistr(mu[i], Sigma[i,i], sym = LETTERS[i]) for i in xrange(d)]
+            Vars = [NormalDistr(mu[i], Sigma[i,i], sym = LETTERS[i]) for i in range(d)]
         super(NDNormalDistr, self).__init__(d, Vars)
         self.marginals = self.Vars
         self.a = [m-5 for m in mu] # FIX THIS!!!
@@ -579,12 +579,12 @@
             X = asfarray(X) - self.mu
             return self.nrm * exp(-0.5 * dot(X, dot(self.invSigma, X).T))
         else:
-            print X
+            print(X)
             X = [self.marginals[i].get_piecewise_cdfinv_interp()(X[i]) for i in range(len(X))]
             Xa = asfarray(X)
-            print Xa
-
-            Xa = Xa.transpose(range(1, len(X[0].shape) + 1) + [0])
+            print(Xa)
+
+            Xa = Xa.transpose(list(range(1, len(X[0].shape) + 1)) + [0])
             Xa -= self.mu
             Z = (dot(Xa, self.invSigma) * Xa).sum(axis= -1)
             return self.nrm * exp(-0.5 * Z)
@@ -771,7 +771,7 @@
             #print cf, cf.Vars[0].getSymname(), cf.condition(cV, cX, normalize=False)
             new_cond_factors.append(cf.condition(cV, cX, normalize=False))
         cfp = NDProductDistr(kept_factors + new_cond_factors)
-        nrm = cfp.eliminate(range(cfp.d))
+        nrm = cfp.eliminate(list(range(cfp.d)))
         nrm = nrm.as_constant()
         if nrm == 0:
             nrm = 1
@@ -830,7 +830,7 @@
         #print params.integration_infinite.exponent
         if L > U:
             if params.segments.debug_info:
-                print "Warning: reversed integration interval, returning 0"
+                print("Warning: reversed integration interval, returning 0")
             return 0, 0
         if L == U:
             return 0, 0
@@ -861,7 +861,7 @@
         elif L<U:
             i, e = integrate_fejer2_pminf(fun, debug_info = debug_info, debug_plot = debug_plot, exponent = params.integration_infinite.exponent,)
         else:
-            print "errors in _conv_div: x, segi, segj, L, U =", L, U
+            print("errors in _conv_div: x, segi, segj, L, U =", L, U)
         #print "========"
         #if e>1e-10:
         #    print "error L=", L, "U=", U, fun(array([U])), force_minf , force_pinf , force_poleL, force_poleURefactoringTool: Refactored ./depvars/sparse_grids.py
RefactoringTool: No changes to ./examples/Hill_estimator.py
RefactoringTool: Refactored ./examples/central_limit_demo.py

@@ -1031,12 +1031,12 @@
     X = BetaDistr(3,3, sym = "X")
     Y = BetaDistr(3,4, sym = "Y")
     noise = BetaDistr(5,5)*2 - 1
-    print X, Y, noise
+    print(X, Y, noise)
     nf = NDNoisyFun(lambda x, y: x + y, [X, Y], noise, value_sym = "Z")
     #nf = NDNoisyFun(lambda x, y: x * y, [X, Y], noise, value_sym = "Z")
-    print nf.a, nf.b
+    print(nf.a, nf.b)
     pr = NDProductDistr([X, Y, nf])
-    print pr.a, pr.b
+    print(pr.a, pr.b)
     zd = pr.eliminate([X])
     plot_2d_distr(zd)
     figure()
@@ -1085,7 +1085,7 @@
     #c = ClaytonCopula(theta = 0.5, marginals=[UniformDistr(), UniformDistr()])
 
     d = IJthOrderStatsNDDistr(BetaDistr(2,2), 10, 1, 10)
-    print d.symVars
+    print(d.symVars)
     plot_2d_distr(d)
     show()
     from pylab import figure, plot, linspace, show, legend
@@ -1100,37 +1100,37 @@
     mu = [1, 2]
     Sigma = [[2, 0.5], [0.5, 1]]
     ndn = NDNormalDistr(mu, Sigma)
-    print ndn(0, 0)
-    print ndn.Vars
+    print(ndn(0, 0))
+    print(ndn.Vars)
 
     ndn_sub = NDDistrWithVarSubst(ndn, ndn.Vars[0], lambda x,y: x+y, [ndn.Vars[0], ndn.Vars[1]])
-    print ndn(1, 1), ndn_sub(0,1)
+    print(ndn(1, 1), ndn_sub(0,1))
 
     plot_2d_distr(ndn)
 
     ndn_marg = ndn.eliminate(1)
     ndn_marg = ndn.eliminate(ndn.Vars[1])
-    print ndn_marg.Vars
+    print(ndn_marg.Vars)
     figure()
 
     plot(X, [ndn_marg(x) for x in X])
 
     ndn_cond = ndn.condition(ndn.Vars[1], 0.5)
-    print ndn_cond.Vars
+    print(ndn_cond.Vars)
     figure()
     plot(X, [ndn_cond(x) for x in X])
 
 
     ndi = NDInterpolatedDistr(ndn.d, ndn)
-    print ndi.Vars
+    print(ndi.Vars)
 
     plot_2d_distr(ndi)
 
     ndi_int = ndi.eliminate([0, 1])
-    print ndi_int
+    print(ndi_int)
 
     ndi_marg = ndi.eliminate(ndi.Vars[1])
-    print ndi_marg.Vars
+    print(ndi_marg.Vars)
     figure()
     plot(X, [ndi_marg(x) for x in X])
     plot(X, [ndn_marg(x) for x in X])
@@ -1158,9 +1158,9 @@
     ndn1c = ConditionalDistr(ndn1, [0])
     ndn2c = ConditionalDistr(ndn2, [0])
     gmrf = NDProductDistr([ndn1c, ndn2c, ndn1.eliminate(1)])
-    print gmrf(0, 0, 0)
-
-    print ndn1.eliminate([0, 1])
+    print(gmrf(0, 0, 0))
+
+    print(ndn1.eliminate([0, 1]))
 
     plot_2d_distr(ndn1)
     plot_2d_distr(ndn2)
@@ -1179,7 +1179,7 @@
     plot(X, gmmarg4(X))
 
     gmmarg5 = gmrf.eliminate([0, 1, 2])
-    print gmmarg5.as_constant()
+    print(gmmarg5.as_constant())
 
     gmrfc1 = gmrf.condition(ndn1.Vars[0], 1)
     plot_2d_distr(gmrfc1)  # [1, 2] are conditionally independent given [0]
--- ./depvars/sparse_grids.py	(original)
+++ ./depvars/sparse_grids.py	(refactored)
@@ -14,9 +14,9 @@
     #import pyximport; pyximport.install()
     from pacal.bary_interp import c_dense_grid_interp
     have_Cython = True
-    print "Using compiled sparse grid routine"
+    print("Using compiled sparse grid routine")
 except:
-    print "Compiled sparse grid routine not available"
+    print("Compiled sparse grid routine not available")
     have_Cython = False
 
 
@@ -25,7 +25,7 @@
     if nd == 1:
         return [(d,)]
     part = []
-    for x in xrange(1,d):
+    for x in range(1,d):
         new_part = [(x,)+p for p in gen_partitions(nd - 1, d-x)]
         part.extend(new_part)
     return part
@@ -37,7 +37,7 @@
     Q corresponds to P in the paper of Wasilkowski and Wozniakowski."""
     assert q >= d
     Q = []
-    for i in xrange(q-d+1, q+1):
+    for i in range(q-d+1, q+1):
         Q.extend(gen_partitions(d, i))
     return Q
 
@@ -69,11 +69,11 @@
         ni = self.init_ni
         self.exps = [None]
         self.cheb_weights_cache = [None]
-        self.xroot_cache = [list([None]) for j in xrange(self.d)] # cache for X coords of roots
-        for i in xrange(self.q - self.d + 1 + 1):  # maximum degree is q - d + 1 by definition of Q
+        self.xroot_cache = [list([None]) for j in range(self.d)] # cache for X coords of roots
+        for i in range(self.q - self.d + 1 + 1):  # maximum degree is q - d + 1 by definition of Q
             self.exps.append(ni)
             self.cheb_weights_cache.append(cheb_weights(ni))
-            for j in xrange(self.d):
+            for j in range(self.d):
                 self.xroot_cache[j].append(cheb_nodes(ni, self.a[j], self.b[j]))
             if ni == 1:
                 ni = 3
@@ -82,7 +82,7 @@
         self.ni = ni
 
         self.nodes, self.subgrid_map = self.get_nodes(self.q)
-        Xs = [array([self.xroot_cache[j][self.q - self.d + 1][n[j]] for n in self.nodes]) for j in xrange(self.d)]
+        Xs = [array([self.xroot_cache[j][self.q - self.d + 1][n[j]] for n in self.nodes]) for j in range(self.d)]
         self.Ys = atleast_1d(squeeze(self.f(*Xs)))
 
     def adaptive_interp(self, par = None):
@@ -98,7 +98,7 @@
         while q <= maxq:
             self.exps.append(ni)
             self.cheb_weights_cache.append(cheb_weights(ni))
-            for j in xrange(self.d):
+            for j in range(self.d):
                 self.xroot_cache[j].append(cheb_nodes(ni, self.a[j], self.b[j]))
             if ni == 1:
                 ni = 3
@@ -111,12 +111,12 @@
             inc_nodes = list(set(new_nodes) - set(old_nodes))
             inc_nodes.sort()
             max_q = q-self.d+1
-            inc_Xs = [array([self.xroot_cache[j][max_q][n[j]] for n in inc_nodes]) for j in xrange(self.d)]
+            inc_Xs = [array([self.xroot_cache[j][max_q][n[j]] for n in inc_nodes]) for j in range(self.d)]
             inc_Ys = atleast_1d(squeeze(self.f(*inc_Xs)))
             err = self.test_accuracy(inc_Xs, inc_Ys)
             maxy = max(abs(inc_Ys).max(), abs(self.Ys).max())
             if par.debug_info:
-                print "interp. err", err, old_err, q
+                print("interp. err", err, old_err, q)
             cm.add(err, maxy)
             if cm.test_convergence()[0]:
                 break
@@ -168,9 +168,9 @@
             max_q = q-self.d+1
             max_d = self.exps[max_q]
             if self.init_ni == 1:
-                new_nodes = itertools.product(*[range(0, max_d, 1 << (max_q - e)) if e > 1 else [max_d/2] for e in p])
-            else:
-                new_nodes = itertools.product(*[range(0, max_d, 1 << (max_q - e)) for e in p])
+                new_nodes = itertools.product(*[list(range(0, max_d, 1 << (max_q - e))) if e > 1 else [max_d/2] for e in p])
+            else:
+                new_nodes = itertools.product(*[list(range(0, max_d, 1 << (max_q - e))) for e in p])
 
             # node indices for this subgrid
             subgrid_indices = []
@@ -187,8 +187,8 @@
             c = (-1)**(q-si) * binomial_coeff(self.d - 1, q-si)
             subgrid_map[p] = (c, array(subgrid_indices))
         if params.interpolation_nd.debug_info:
-            print len(subgrid_map), "rect. subgrids,", sum(len(subgrid_map[k]) for k in subgrid_map), "ops per X,", len(nodes), "nodes,",
-            print "full grid size", self.exps[q-self.d+1]**self.d, "dim", self.d
+            print(len(subgrid_map), "rect. subgrids,", sum(len(subgrid_map[k]) for k in subgrid_map), "ops per X,", len(nodes), "nodes,", end=' ')
+            print("full grid size", self.exps[q-self.d+1]**self.d, "dim", self.d)
         return nodes, subgrid_map
 
     def interp_at(self, *X):
@@ -203,7 +203,7 @@
                 return array([])
         y = 0
         full_grid_cache = {}
-        for p, subgrid in self.subgrid_map.iteritems():
+        for p, subgrid in self.subgrid_map.items():
             c, ni = subgrid
             #yi = self.full_grid_interp(p, self.Ys[ni], X, full_grid_cache)
             yi = self.full_grid_interp_new(p, self.Ys[ni], X, full_grid_cache)
@@ -318,11 +318,11 @@
     ai = AdaptiveSparseGridInterpolator(f, d)#, a = a)
     yi = ai.interp_at(*X)
     yt = f(*X)
-    print yi, yt, yi - yt
+    print(yi, yt, yi - yt)
     debug = True
     X = [array([0.1, 0.2, 1.0]), array([0.2, 0.1, 0.5]), array([0.2, 0.1, 0.1])][0:d]
     X = [array([0.1, 0.2, 1.0]), array([0.2, 0.1, 0.5]), array([0.2, 0.1, 0.1])][0:d]
     yi = ai.interp_at(*X)
     yt = f(*X)
-    print yi, yt, yi - yt
+    print(yi, yt, yi - yt)
     
--- ./examples/central_limit_demo.py	(original)
+++ ./examples/central_limit_demo.py	(refactored)RefactoringTool: No changes to ./examples/discrete.py
RefactoringTool: No changes to ./examples/extreme_value_demo.py
RefactoringTool: Refactored ./examples/functions.py
RefactoringTool: Refactored ./examples/measurements.py
RefactoringTool: Refactored ./examples/noncentral.py
RefactoringTool: Refactored ./examples/order_stats.py
RefactoringTool: Refactored ./examples/singularities.py
RefactoringTool: Refactored ./examples/dependent/depvars_demo.py
RefactoringTool: Refactored ./examples/dependent/diffeq_noise.py
RefactoringTool: Refactored ./examples/dependent/kalman.py

@@ -19,9 +19,9 @@
         title("Limit of averages of " + X.getName())
         X.plot(linewidth = 4, color = "c", **args)
         Y = X
-        print "Limit of averages of " + X.getName() + ": ",
-        for i in xrange(N-1):
-            print i+2,
+        print("Limit of averages of " + X.getName() + ": ", end=' ')
+        for i in range(N-1):
+            print(i+2, end=' ')
             sys.stdout.flush()
             Y += X
             (Y/(i+2)).plot(color = colors[i%len(colors)], **args)
@@ -32,8 +32,8 @@
         ylim(ymin = 0)
         if ymax is not None:
             ylim(ymax = ymax)
-        print
-        print "time===", time.time()-tic
+        print()
+        print("time===", time.time()-tic)
         #show()
     
     #!----------------------
--- ./examples/functions.py	(original)
+++ ./examples/functions.py	(refactored)
@@ -47,7 +47,7 @@
 
 try:
     l = log(NormalDistr(0, 1))
-    print "Error: log of negative distribution not reported!!!!"
+    print("Error: log of negative distribution not reported!!!!")
 except ValueError:
     pass
 
--- ./examples/measurements.py	(original)
+++ ./examples/measurements.py	(refactored)
@@ -32,7 +32,7 @@
     try:
         from scipy.optimize.optimize import fminbound
     except ImportError:
-        print "Scipy not available, exiting..."
+        print("Scipy not available, exiting...")
         import sys
         sys.exit(10)
     
@@ -57,35 +57,35 @@
         """Error of a geometric combination of measurements."""
         return exp(log(E1)*alpha +  log(E2)*(1-alpha))
     
-    print
-    print "Combining measurements for optimal variance"
+    print()
+    print("Combining measurements for optimal variance")
     alphaOptVar = fminbound(lambda alpha: E(alpha).var(), 0, 1, xtol = 1e-16)
-    print "alpha for optimal variance = ", alphaOptVar 
+    print("alpha for optimal variance = ", alphaOptVar) 
     dopt = E(alphaOptVar)
     dopt.summary()
     
-    print
-    print "Combining measurements for optimal Median Absolute Deviance"
+    print()
+    print("Combining measurements for optimal Median Absolute Deviance")
     alphaOptMad = fminbound(lambda alpha: E(alpha).medianad(), 0, 1, xtol = 1e-16)
-    print "alpha for optimal MAD = ", alphaOptMad 
+    print("alpha for optimal MAD = ", alphaOptMad) 
     dopt = E(alphaOptMad)
     dopt.summary()
     
-    print
-    print "Combining measurements for optimal 95% confidence interval"
+    print()
+    print("Combining measurements for optimal 95% confidence interval")
     alphaOptIQrange = fminbound(lambda alpha: E(alpha).iqrange(0.025), 0, 1, xtol = 1e-16)
-    print "alpha for optimal 95% c.i. = ", alphaOptIQrange 
+    print("alpha for optimal 95% c.i. = ", alphaOptIQrange) 
     dopt = E(alphaOptIQrange)
     dopt.summary()
     
-    print
-    print "Combining measurements for optimal entropy"
+    print()
+    print("Combining measurements for optimal entropy")
     alphaOptEntropy = fminbound(lambda alpha: E(alpha).entropy(), 0, 1, xtol = 1e-16)
-    print "alpha for optimal entropy = ", alphaOptEntropy 
+    print("alpha for optimal entropy = ", alphaOptEntropy) 
     dopt = E(alphaOptEntropy)
     dopt.summary()
     
-    print "-----------------------"
+    print("-----------------------")
     figure()
     #E1.plot(color='k')
     #E2.plot(color='k')
--- ./examples/noncentral.py	(original)
+++ ./examples/noncentral.py	(refactored)
@@ -10,13 +10,13 @@
 
 def plot_nonc(d, titl = "", lim = None):
     figure()
-    print "----------------------------------------------------------------"
+    print("----------------------------------------------------------------")
     for i, nc in enumerate([0, 1, 2, 5, 10]):
         ncd = d(nc)
-        print ncd
+        print(ncd)
         ncd.summary(show_moments=True)
         ncd.plot(label = "nonc=" + str(nc), color = colors[i%len(colors)])
-        print 
+        print() 
         
     if lim is not None:
         xlim(lim[0], lim[1])
@@ -54,5 +54,5 @@
     #!
     plot_nonc(lambda nc: NoncentralFDistr(1, 1, nc), titl = "NoncentralF(1, 1, nonc)", lim = [-0.1, 3, 0, 0.9])
     plot_nonc(lambda nc: NoncentralFDistr(10, 20, nc), titl = "NoncentralF(10, 20, nonc)")
-    print "toc=", time.time() - tic 
+    print("toc=", time.time() - tic) 
     show()
--- ./examples/order_stats.py	(original)
+++ ./examples/order_stats.py	(refactored)
@@ -8,7 +8,7 @@
     colors = "kbgrcmy"
     
     c = 0
-    for i in xrange(1, 50, 5):
+    for i in range(1, 50, 5):
         os = iid_order_stat(BetaDistr(3, 2), 50, i)
         os.summary()
         os.plot(label = str(i) + "-" + ordinal_ending(i) + " ord. stat.", color = colors[c%len(colors)])
--- ./examples/singularities.py	(original)
+++ ./examples/singularities.py	(refactored)
@@ -65,7 +65,7 @@
     #!-------------------------------------------
     def prod_uni_pdf(n, x):
         pdf = (-log(x)) ** (n-1)
-        for i in xrange(2, n):
+        for i in range(2, n):
             pdf /= i
         return pdf
     figure()
--- ./examples/dependent/depvars_demo.py	(original)
+++ ./examples/dependent/depvars_demo.py	(refactored)
@@ -5,7 +5,7 @@
 #!
 
 import sys; 
-print('%s %s' % (sys.executable or sys.platform, sys.version))
+print(('%s %s' % (sys.executable or sys.platform, sys.version)))
 
 from functools import partial
 
@@ -34,8 +34,8 @@
 R_total.hist()
 R_total.summary()
 
-print R_total.cdf(3.0 / 4.0)
-print R_total.median()
+print(R_total.cdf(3.0 / 4.0))
+print(R_total.median())
 
 ylim(ymin=0)
 #axis((0.3, 1.0, 0.0, 3.0))
@@ -65,8 +65,8 @@
 figure()
 plot_2d_distr(CIJ)
 show()
-print X7.mean() - X2.mean()
-print repr(R.mean())
+print(X7.mean() - X2.mean())
+print(repr(R.mean()))
 
 
 #! Sample range distribution
@@ -88,8 +88,8 @@
 plot_2d_distr(CIJ)
 show()
 #! Compare it with SAS/QC manual, functions: d2, d3
-print repr(R.mean())
-print repr(R.var()), repr(R.std())
+print(repr(R.mean()))
+print(repr(R.var()), repr(R.std()))
 R.summary()
 
 #! ----------------------------------
@@ -105,8 +105,8 @@
     C = FrankCopula2d(theta=theta, marginals=[X, Y])
     M = TwoVarsModel(C, B)
     B_ = M.varchange_and_eliminate()
-    print "---------------------------------------" 
-    print i, ", theta=", theta, ", tau=", C.tau(0, 1), ", rho=", C.rho_s(0, 1), ", corrcoef=",C.corrcoef(0, 1) 
+    print("---------------------------------------") 
+    print(i, ", theta=", theta, ", tau=", C.tau(0, 1), ", rho=", C.rho_s(0, 1), ", corrcoef=",C.corrcoef(0, 1)) 
     figure(8)
     subplot(2, 2, i, projection='3d')
     C.plot(n=20, colors="k", labels=False)
--- ./examples/dependent/diffeq_noise.py	(original)
+++ ./examples/dependent/diffeq_noise.py	(refactored)
@@ -42,7 +42,7 @@
 K = (1 + h * A)
 K.setSym("K") 
 Y, O, E, U  = [], [], [], []           # lists of states, observations and errors
-for i in xrange(n):
+for i in range(n):
     #Y.append(Y[i] * K)
     #Y[i + 1].setSym("Y" + str(i + 1))  
     U.append(UniformDistr(-0.1,0.1, sym="U{0}".format(i)))
@@ -62,9 +62,9 @@
 #! -----
 P = NDProductDistr([A, Y0] + E + U)
 M = Model(P, O)
-print M
+print(M)
 M.eliminate_other(E + Y + O + [A, Y0] + U)
-print M
+print(M)
 M.toGraphwiz(f=open('bn.dot', mode="w+"))
 
 #!
@@ -81,7 +81,7 @@
     title("O_{0}={1}".format(n, yend))
     M2.plot()
     ay0.append(M2.nddistr.mode())           # "most probable" state
-    print "yend=", yend, ",  MAP  est. of A, Y0 =", ay0[i]
+    print("yend=", yend, ",  MAP  est. of A, Y0 =", ay0[i])
     i += 1
 show()
 #!
@@ -97,11 +97,11 @@
         ymean.append(Myi.mean())
         ystd.append(Myi.std())
         Myi.boxplot(pos=i+1, useci=0.05, showMean=False)
-    plot(range(1, n+1, 1), ymean, 'k', linestyle=styles[j], label="A, Y[0] = {0:.3f},{1:.3f}".format(*ay0[j]))
+    plot(list(range(1, n+1, 1)), ymean, 'k', linestyle=styles[j], label="A, Y[0] = {0:.3f},{1:.3f}".format(*ay0[j]))
     ylabel("O[i]")
     xlabel("i")
 legend(loc='upper left')
 show()
-print "computation time=", time.time() - t0
+print("computation time=", time.time() - t0)
 
 
--- ./examples/dependent/kalman.py	(original)
+++ ./examples/dependent/kalman.py	(refactored)
@@ -42,7 +42,7 @@
 K = 0.7
 Y = []                          # list of statesRefactoringTool: Refactored ./examples/dependent/linreg.py
RefactoringTool: Refactored ./examples/dependent/sums.py
RefactoringTool: Refactored ./examples/dependent/two_variables/order_stats.py
RefactoringTool: Refactored ./examples/dependent/two_variables/regression.py
RefactoringTool: No changes to ./examples/dependent/two_variables/resistors.py
RefactoringTool: Refactored ./examples/dependent/two_variables/sum_dependent.py
RefactoringTool: Refactored ./examples/springer_book/Chapter3_sums.py

 O, E, U = [], [], []            # lists of observations and errors
-for i in xrange(n):
+for i in range(n):
     U.append(UniformDistr(-0.2, 0.2, sym="U{0}".format(i)))
     if i == 0:
         Y.append(Y0 * K + U[i])
@@ -56,7 +56,7 @@
     O[-1].setSym("O{0}".format(i))
     #print O[-1].range(), O[-1].range_()
 M = Model(U + [Y0] + E, Y + O)
-print M
+print(M)
 M.toGraphwiz(f=open('bn.dot', mode="w+"))
 #!
 #! Simulation with signal filtering
@@ -94,8 +94,8 @@
 
 #! Error of estimation using median 
 #! --------------------------------
-print "mse=", sqrt(mean((Yorg - Ynoised) ** 2)), sqrt(mean((Yorg - Ydenoised) ** 2)) 
-print "mae=", mean(abs(Yorg - Ynoised)), mean(abs(Yorg - Ydenoised)) 
+print("mse=", sqrt(mean((Yorg - Ynoised) ** 2)), sqrt(mean((Yorg - Ydenoised) ** 2))) 
+print("mae=", mean(abs(Yorg - Ynoised)), mean(abs(Yorg - Ydenoised))) 
 
 
 show()
--- ./examples/dependent/linreg.py	(original)
+++ ./examples/dependent/linreg.py	(refactored)
@@ -22,9 +22,9 @@
 Xobs = UniformDistr().rand(n)
 a, b = 0.3, 0.7 
 Yobs = a * Xobs + b #+ E[0].rand(n)
-print '{0:{align}15}\t{0:{align}15}'.format("Xobs","Xobs", align = '>')
+print('{0:{align}15}\t{0:{align}15}'.format("Xobs","Xobs", align = '>'))
 for i in range(len(Xobs)):
-    print '{0:{align}20}\t{0:{align}14}'.format(Xobs[i], Yobs[i], align = '>')
+    print('{0:{align}20}\t{0:{align}14}'.format(Xobs[i], Yobs[i], align = '>'))
 #!
 #! Model
 #!
@@ -42,16 +42,16 @@
 
 M = Model(X + E + [A, B], Y)
 M.toGraphwiz(f=open('bn.dot', mode="w+"))
-print M
+print(M)
 #!
 #! Inference
 #!
 MAB = M.inference([A,B], X + Y,  concatenate((Xobs, Yobs)))
 MA = MAB.inference([A],[],[])
 MB = MAB.inference([B],[],[])
-print MAB
-print MA
-print MB
+print(MAB)
+print(MA)
+print(MB)
 figure(1)
 MAB.plot(have_3d=True)
 title("Joint distribution of A and B conditioned on sample")
@@ -71,10 +71,10 @@
 #!
 #! Estimation of coefficients
 #!
-print "original coefficients a=", a, "b=", b
-print "mean   est. A=", MA.as1DDistr().mean(),   "est. B=", MB.as1DDistr().mean()
-print "median est. A=", MA.as1DDistr().median(), "est. B=", MB.as1DDistr().median()
-print "mode   est. A=", MA.as1DDistr().mode(),   "est. B=", MB.as1DDistr().mode()
+print("original coefficients a=", a, "b=", b)
+print("mean   est. A=", MA.as1DDistr().mean(),   "est. B=", MB.as1DDistr().mean())
+print("median est. A=", MA.as1DDistr().median(), "est. B=", MB.as1DDistr().median())
+print("mode   est. A=", MA.as1DDistr().mode(),   "est. B=", MB.as1DDistr().mode())
 MAB.nddistr(1, 3)
 abopt = MAB.nddistr.mode()
 (ar,br)=polyfit(Xobs,Yobs,1)
@@ -82,7 +82,7 @@
 #! Least squares estimates are maximum log-likelihood estimates 
 #! (are equal to maximum a posteriori in this case, because of uniform a priori distribution of coefficients) 
 #!
-print "              MAP  a=", abopt[0], "b=", abopt[1]
-print "polyfit (LSE) est. a=", ar, "b=", br
-print "computation time=", time.time() - t0
+print("              MAP  a=", abopt[0], "b=", abopt[1])
+print("polyfit (LSE) est. a=", ar, "b=", br)
+print("computation time=", time.time() - t0)
 
--- ./examples/dependent/sums.py	(original)
+++ ./examples/dependent/sums.py	(refactored)
@@ -27,7 +27,7 @@
 #A = UniformDistr(0,1, sym = "A")
 #B = UniformDistr(0,1, sym = "B")
 for i in range(n):
-    print "X{}".format(i)
+    print("X{}".format(i))
     X[i] = BetaDistr(2, 2, sym = "X{}".format(i))
     if i==0:
         S[i] = X[0]        
@@ -36,39 +36,39 @@
         S[i].setSym("S{}".format(i))
 
 M = Model(X, S[1:])
-print M
+print(M)
 M.toGraphwiz()
 #M = M.inference([S[-1], S[-4]], [S[-3]], [1])
 #M = M.inference([X[0], X[1]], [S[-1]], [3.5])
-print "===================="
+print("====================")
 M1 = M.inference(wanted_rvs =[X[0], X[1]], cond_rvs=[S[-1]], cond_X=[1])
-print "====================",M1
+print("====================",M1)
 M2 = M.inference(wanted_rvs =[S[1], S[4]])
-print "====================",M2
+print("====================",M2)
 M3 = M.inference(wanted_rvs =[S[1], S[4]], cond_rvs=[S[3]], cond_X=[2])
-print "====================",M3
+print("====================",M3)
 MC_X0 = M.inference(wanted_rvs =[X[0]], cond_rvs=[S[-1]], cond_X=[1])
-print "===================="
+print("====================")
 
-print M1
+print(M1)
 figure()
 M1.plot(cont_levels=10)
 figure()
 M1.plot(have_3d=True)
 
-print M2
+print(M2)
 figure()
 M2.plot(cont_levels=10)
 figure()
 M2.plot(have_3d=True)
 
-print M3
+print(M3)
 figure()
 M3.plot(cont_levels=10)
 figure()
 M3.plot(have_3d=True)
 
-print MC_X0
+print(MC_X0)
 figure()
 MC_X0.plot()
 
--- ./examples/dependent/two_variables/order_stats.py	(original)
+++ ./examples/dependent/two_variables/order_stats.py	(refactored)
@@ -26,8 +26,8 @@
 title("Joint distribution of min and max of 5 normals")
 
 #! Compare it with SAS/QC manual, functions: d2, d3
-print repr(R.mean())
-print repr(R.var()), repr(R.std())
+print(repr(R.mean()))
+print(repr(R.var()), repr(R.std()))
 R.summary()
 
 show()
--- ./examples/dependent/two_variables/regression.py	(original)
+++ ./examples/dependent/two_variables/regression.py	(refactored)
@@ -56,13 +56,13 @@
     legend()
 
 
-print "bivariate normal..."
+print("bivariate normal...")
 F = NDNormalDistr([0, 0], [[1, 0.5], [0.5, 1]])
 plot_regression(F, Ybreaks = [-Inf, -5, -1, 1, 5, Inf])
 title("bivariate normal, rho = 0.5")
 
 figure()
-print "Clayton copula..."
+print("Clayton copula...")
 X, Y = BetaDistr(2,3), UniformDistr() + UniformDistr()
 X.setSym("X"); Y.setSym("Y")
 F = ClaytonCopula(theta = 0.5, marginals=[X, Y])
@@ -70,7 +70,7 @@
 title("Clayton copula, theta = 0.5")
 
 figure()
-print "Frank copula..."
+print("Frank copula...")
 F = FrankCopula(theta = 8, marginals=[X, Y])
 plot_regression(F)
 title("Frank copula, theta = 8")
--- ./examples/dependent/two_variables/sum_dependent.py	(original)
+++ ./examples/dependent/two_variables/sum_dependent.py	(refactored)
@@ -12,7 +12,7 @@
 
 title("Bivariate normal")
 for i, theta in enumerate([-0.9, -0.5, 0.5, 0.9]):
-    print "theta=", theta
+    print("theta=", theta)
     ci = NDNormalDistr([0, 0], [[1, theta],[theta, 1]])
     Mi = TwoVarsModel(ci, ci.Vars[0] + ci.Vars[1])
     funi = Mi.eval()
@@ -23,7 +23,7 @@
 figure()
 title("GumbelCopula")
 for i, theta in enumerate([1, 5, 10, 15]):
-    print "theta=", theta
+    print("theta=", theta)
     ci = GumbelCopula(marginals=[X, Y], theta=theta)
     Mi = TwoVarsModel(ci, U)
     funi = Mi.eval()
@@ -34,7 +34,7 @@
 figure()
 title("FrankCopula")
 for i, theta in enumerate([-15, -5, 5, 15]):
-    print "theta=", theta
+    print("theta=", theta)
     ci = FrankCopula(marginals=[X, Y], theta=theta)
     Mi = TwoVarsModel(ci, U)
     funi = Mi.eval()
@@ -45,7 +45,7 @@
 figure()
 title("ClaytonCopula")
 for i, theta in enumerate([1, 5, 10, 15]):
-    print "theta=", theta
+    print("theta=", theta)
     ci = ClaytonCopula(marginals=[X, Y], theta=theta)
     Mi = TwoVarsModel(ci, U)
     funi = Mi.eval()
@@ -59,7 +59,7 @@
 U2.setSym("U2")
 title("FrankCopula - infinite domain")
 for i, theta in enumerate([1, 5, 10, 15]):
-    print "theta=", theta
+    print("theta=", theta)
     ci = FrankCopula(marginals=[X, Y2], theta=theta)
     Mi = TwoVarsModel(ci, U2)
     funi = Mi.eval()
--- ./examples/springer_book/Chapter3_sums.py	(original)
+++ ./examples/springer_book/Chapter3_sums.py	(refactored)
@@ -54,7 +54,7 @@
     demo_distr(ChiSquareDistr(10) + ChiSquareDistr(11),
                theoretical = ChiSquareDistr(21))
     cd = ChiSquareDistr(4)
-    for i in xrange(17):
+    for i in range(17):
         cd = cd + ChiSquareDistr(1)
         #print i, cd.pdf(1)
     figure()
@@ -84,7 +84,7 @@
     demo_distr(CauchyDistr(gamma = 10) + CauchyDistr(gamma = 50), theoretical = CauchyDistr(gamma = 60))
     figure()
     c = CauchyDistr(center = 1)
-    for i in xrange(9):
+    for i in range(9):
         c += CauchyDistr()
     demo_distr(c, theoretical = CauchyDistr(gamma = 10, center = 1))
        
@@ -105,11 +105,11 @@
             else:
                 nck = 1
                 pdf = 0.0
-                for k in xrange(r):
+                for k in range(r):
                     pdf += (-1)**k * nck * (x-k)**(n-1)
                     nck *= n - kRefactoringTool: Refactored ./examples/springer_book/Chapter4_products.py
RefactoringTool: Refactored ./examples/springer_book/Chapter5_functions.py
RefactoringTool: Refactored ./examples/springer_book/Chapter9_applications.py

                     nck /= k + 1
-                for i in xrange(2, n):
+                for i in range(2, n):
                     pdf /= i
                 y[j] = pdf
         return y
@@ -118,13 +118,13 @@
     u = UniformDistr(0,1) + UniformDistr(0,1)
     figure()
     demo_distr(u, theoretical = partial(uniform_sum_pdf, 2))
-    for i in xrange(2):
+    for i in range(2):
         u += UniformDistr(0,1)
     figure()
     demo_distr(u, theoretical = partial(uniform_sum_pdf, 3+i))
     
     u = UniformDistr(0,1)
-    for i in xrange(49):
+    for i in range(49):
         u += UniformDistr(0,1)
     figure()
     demo_distr(u, theoretical = partial(uniform_sum_pdf, i+2))
@@ -144,5 +144,5 @@
     #! Exercise 3.19
     figure()
     demo_distr(UniformDistr(-1,0) + ExponentialDistr() + NormalDistr(0, 1.0/numpy.sqrt(2)))
-    print "time=", time.time() - tic
+    print("time=", time.time() - tic)
     show()
--- ./examples/springer_book/Chapter4_products.py	(original)
+++ ./examples/springer_book/Chapter4_products.py	(refactored)
@@ -29,22 +29,22 @@
     #! Section 4.4.1
     def prod_uni_pdf(n, x):
         pdf = (-log(x)) ** (n-1)
-        for i in xrange(2, n):
+        for i in range(2, n):
             pdf /= i
         return pdf
     figure()
     demo_distr(UniformDistr(0,1) * UniformDistr(0,1) * UniformDistr(0,1), theoretical = partial(prod_uni_pdf, 3))
     
     pu = UniformDistr(0,1)
-    for i in xrange(4):
+    for i in range(4):
         pu *= UniformDistr(0,1)
     figure()
     demo_distr(pu, theoretical = partial(prod_uni_pdf, 5))
-    for i in xrange(6):
+    for i in range(6):
         pu *= UniformDistr(0,1)
     figure()
     demo_distr(pu, theoretical = partial(prod_uni_pdf, 11))
-    for i in xrange(10):
+    for i in range(10):
         pu *= UniformDistr(0,1)
     figure()
     demo_distr(pu, theoretical = partial(prod_uni_pdf, 21))
@@ -61,12 +61,12 @@
     figure()
     demo_distr(NormalDistr(0,1) * NormalDistr(0,1))
     np = NormalDistr(0,1)
-    for i in xrange(5):
+    for i in range(5):
         np *= NormalDistr(0,1)
     figure()
     demo_distr(np, xmin = -0.3, xmax = 0.3)
     
-    for i in xrange(10):
+    for i in range(10):
         np *= NormalDistr(0,1)
     figure()
     demo_distr(np, xmin = -0.3, xmax = 0.3, ymax = 5)
@@ -81,7 +81,7 @@
     #! Exercise 4.1
     def prod_uni_pdf_a(a, n, x):
         pdf = 0.5 * (n*log(a)-log(abs(x))) ** (n-1)
-        for i in xrange(2, n):
+        for i in range(2, n):
             pdf /= i
         pdf *= a**(-n)
         return pdf
@@ -92,7 +92,7 @@
     demo_distr(UniformDistr(-2,2) * UniformDistr(-2,2) * UniformDistr(-2,2), theoretical = partial(prod_uni_pdf_a, 2, 3))
     
     pu = UniformDistr(-1.5,1.5)
-    for i in xrange(4):
+    for i in range(4):
         pu *= UniformDistr(-1.5,1.5)
     figure()
     demo_distr(pu, theoretical = partial(prod_uni_pdf_a, 1.5, 5))
@@ -185,7 +185,7 @@
                                                                  + 52480*pi**6*log(x**2 / gamma**20)**3
                                                                  + 147456*pi**8*log(x**2 / gamma**20))
     c = CauchyDistr()
-    for i in xrange(9):
+    for i in range(9):
         c *= CauchyDistr()
     figure()
     demo_distr(c, xmin = -20, xmax = 20, ymax = 1.5,
@@ -199,7 +199,7 @@
     #! Exercise 4.12
     def log_prod_uni(n):
         u = UniformDistr(0,1)
-        for i in xrange(n-1):
+        for i in range(n-1):
             u *= UniformDistr(0,1)
         return -2 * log(u)
     figure()
@@ -223,10 +223,10 @@
         #for i in xrange(df2):
         #    den += NormalDistr(0,1) ** 2
         num = NormalDistr(0, 1) ** 2
-        for i in xrange(df1 - 1):
+        for i in range(df1 - 1):
             num += NormalDistr(0,1) ** 2
         den = NormalDistr() ** 2
-        for i in xrange(df2 - 1):
+        for i in range(df2 - 1):
             den += NormalDistr(0,1) ** 2
         if mode == 1:
             num /= df1
@@ -264,7 +264,7 @@
     #! Exercise 4.15
     def student_t(df):
         den = NormalDistr() ** 2
-        for i in xrange(df - 1):
+        for i in range(df - 1):
             den += NormalDistr() ** 2
         return NormalDistr() / sqrt(den / df)
     for df in [1, 2, 3, 5]:
@@ -289,13 +289,13 @@
     #! Exercise 4.18
     def theor_beta_prod(alpha, n, x):
         norm = float((alpha + 1) ** n)
-        for i in xrange(1, n):
+        for i in range(1, n):
             norm /= i
         return norm * x ** alpha * log(1.0 / x) ** (n - 1)
     for alpha in [0.2, 1, 2, 4]:
         for n in [2, 3, 5]:
             d = BetaDistr(alpha + 1, 1)
-            for i in xrange(n - 1):
+            for i in range(n - 1):
                 d *= BetaDistr(alpha + 1, 1)
             figure()
             demo_distr(d, theoretical = partial(theor_beta_prod, alpha, n))
@@ -429,10 +429,10 @@
     from pacal.utils import binomial_coeff
     for n, m in [(2,2), (5,7)]:
         N = UniformDistr(0,1)
-        for i in xrange(n-1):
+        for i in range(n-1):
             N += UniformDistr(0,1)
         D = UniformDistr(0,1)
-        for i in xrange(m-1):
+        for i in range(m-1):
             D += UniformDistr(0,1)
         d = N/D
         figure()
@@ -440,16 +440,16 @@
     
         a = 0.9
         nmfact = 1
-        for i in xrange(2, n+m+1):
+        for i in range(2, n+m+1):
             nmfact *= i
         nrm = a**m * nmfact
         s = 0
-        for i in xrange(int(numpy.floor(m*a)+1)):
-            for j in xrange(int(numpy.floor((m*a-i)/a)+1)):
+        for i in range(int(numpy.floor(m*a)+1)):
+            for j in range(int(numpy.floor((m*a-i)/a)+1)):
                 s += (-1)**(i+j) * binomial_coeff(n, i) * binomial_coeff(m, j) * ((m-j)*a-i)**(n+m)
         cdf_formula = s / nrm
         cdf_pacal = d.cdf(a)
-        print "n={0},m={1}  cdf({2})={3}, err = {4}".format(n, m, a, cdf_pacal, abs(cdf_pacal - cdf_formula))
+        print("n={0},m={1}  cdf({2})={3}, err = {4}".format(n, m, a, cdf_pacal, abs(cdf_pacal - cdf_formula)))
     
     #! Exercise 4.32
     for l1, l2 in [(1,1), (10,1), (1,10)]:
@@ -457,5 +457,5 @@
         figure()
         alpha = float(l2) / l1
         demo_distr(d, xmax = 10, theoretical = lambda x: alpha / (x+alpha)**2)
-    print "time=", time.time() - tic
+    print("time=", time.time() - tic)
     show()
--- ./examples/springer_book/Chapter5_functions.py	(original)
+++ ./examples/springer_book/Chapter5_functions.py	(refactored)
@@ -46,5 +46,5 @@
     figure()
     #demo_distr(d, theoretical = theor_ampl_uni, histogram=True)
     demo_distr(d)
-    print "time=", time.time() - tic
+    print("time=", time.time() - tic)
     show()
--- ./examples/springer_book/Chapter9_applications.py	(original)
+++ ./examples/springer_book/Chapter9_applications.py	(refactored)
@@ -71,7 +71,7 @@
     for ns in [[3, 5, 2], # sample sizes
                [4, 5, 10, 7, 3]
                ]:
-        print "sample sizes:", ns
+        print("sample sizes:", ns)
         N = sum(ns)
         num = ChiSquareDistr(ns[0] - 1)
         for n in ns[1:]:
@@ -87,16 +87,16 @@
     #! Geometric mean of uniforms
     def theor_geom_unif(n, x):
         nf = 1
-        for i in xrange(2, n):
+        for i in range(2, n):
             nf *= i
         return float(n) / nf * x**(n-1) * log(x**(-n))**(n-1)
     for n in [3, 7]:
         d = UniformDistr(0, 1)
-        for i in xrange(n-1):
+        for i in range(n-1):
             d *= UniformDistr(0, 1)
         d **= (1.0 / n)
         d2 = log(UniformDistr(0, 1))
-        for i in xrange(n-1):
+        for i in range(n-1):
             d2 += log(UniformDistr(0, 1))
         d2 /= n
         d2 = exp(d2)
@@ -111,7 +111,7 @@
     #! Harmonic mean of uniforms
     for n in [2, 3, 7]:
         d = 1 / UniformDistr(0, 1)
-        for i in xrange(n-1):
+        for i in range(n-1):
             d += 1 / UniformDistr(0, 1)
         d = n / d
         figure()
@@ -146,7 +146,7 @@
     #! Corollary 9.9.1b
     for n in [2, 3, 6]:
         s = GammaDistr()
-        for i in xrange(n-1):
+        for i in range(n-1):
             s += GammaDistr()
         s /= n
         figure() 
@@ -285,7 +285,7 @@RefactoringTool: Refactored ./examples/springer_book/Chapters678.py
RefactoringTool: Refactored ./stats/distr_est.py
RefactoringTool: Refactored ./stats/iid_ops.py
RefactoringTool: No changes to ./stats/noncentral_distr.py
RefactoringTool: Refactored ./test/nosetester.py
RefactoringTool: Refactored ./test/testArith.py

     
     for ps in [[1,2,3],
                [6,8,10,12]]:
-        pqs = zip(ps[:-1], ps[1:])
+        pqs = list(zip(ps[:-1], ps[1:]))
         pr = OneDistr()
         for p, q in pqs:
             pr *= BetaDistr(p, q-p)
@@ -297,7 +297,7 @@
     m = 3        
     
     pr = OneDistr()
-    for i in xrange(m):
+    for i in range(m):
         f = FunDistr(partial(gr, m, p, p0, i), [0,1])
         pr *= f
     figure()
@@ -325,7 +325,7 @@
                  ]:
         e = ExponentialDistr(l)
         s = ZeroDistr()
-        for i in xrange(n):
+        for i in range(n):
             s += e
         s /= n
         figure()
@@ -346,7 +346,7 @@
     #! Exercise 9.4
     for k, n in [[2,2]]:
         s = ZeroDistr()
-        for i in xrange(n):
+        for i in range(n):
             s += GammaDistr(k)
         figure()
         demo_distr(s, theoretical = GammaDistr(k*n))
@@ -372,7 +372,7 @@
     #! Exercise 9.11
     for n, p in [[2, 5]]:
         pr = OneDistr()
-        for i in xrange(n):
+        for i in range(n):
             pr *= GammaDistr(p+float(i)/n, 1)
         gm = pr ** (1.0/n)
         figure()
@@ -406,10 +406,10 @@
     bs = [2,3]
     p = len(bs)
     As = [a1]
-    for i in xrange(p-1):
+    for i in range(p-1):
         As.append(As[i] + bs[i])
     pr = OneDistr()
-    for i in xrange(p):
+    for i in range(p):
         pr *= 1/(1+GammaDistr(bs[i], 1) / GammaDistr(As[i], 1))
     figure()
     demo_distr(pr, theoretical = BetaDistr(a1, sum(bs)))
@@ -459,5 +459,5 @@
     for p in [1, 3, 5, 100]:
         figure()
         demo_distr(GammaDistr(p, 1) - GammaDistr(p, 1))
-    print time.time() - t0
+    print(time.time() - t0)
     show()
--- ./examples/springer_book/Chapters678.py	(original)
+++ ./examples/springer_book/Chapters678.py	(refactored)
@@ -39,7 +39,7 @@
 figure()
 demo_distr(d, xmax=20)
 exm = -6.7020187668243558
-print "exact mean =", exm, "err =", d.mean() - exm
+print("exact mean =", exm, "err =", d.mean() - exm)
 
 #! Example 8.7.1
 #!
--- ./stats/distr_est.py	(original)
+++ ./stats/distr_est.py	(refactored)
@@ -25,7 +25,7 @@
         i = 0
         for i in range(len(self.params)):            
             self.parkvargs[self.params[i]] = self.defvals[i]
-        if self.debug_info:  print "parkvargs=", self.parkvargs
+        if self.debug_info:  print("parkvargs=", self.parkvargs)
     def make_kwargs(self, params, vals):
         i = 0
         parkvargs = {}
@@ -36,7 +36,7 @@
         kwargs = self.make_kwargs(self.params, parvals)
         #self.distr(**kwargs).summary()   
         ll=-sum(log(self.distr(**kwargs).get_piecewise_pdf()(self.xi)+1e-300))
-        if self.debug_info: print parvals, ll, self.distr(**kwargs).get_piecewise_pdf()(self.xi)
+        if self.debug_info: print(parvals, ll, self.distr(**kwargs).get_piecewise_pdf()(self.xi))
         return ll
     def find_params(self):
         paropt=fmin(self.logli, self.defvals)
@@ -57,8 +57,8 @@
     c = LoglikelihoodEstimator(distr=CauchyDistr, xi=CauchyDistr(1,1).rand(1000))
     d = LoglikelihoodEstimator(distr=ParetoDistr, xi=ParetoDistr(1.4).rand(1000))
     
-    print a.find_params()
-    print b.find_params()
-    print c.find_params()
-    print d.find_params()
+    print(a.find_params())
+    print(b.find_params())
+    print(c.find_params())
+    print(d.find_params())
     show()
--- ./stats/iid_ops.py	(original)
+++ ./stats/iid_ops.py	(refactored)
@@ -25,7 +25,7 @@
     """Exponentiation by squaring returning all powers."""
     res = [None] * (n+1)
     res[1] = x
-    for i in xrange(2, n+1):
+    for i in range(2, n+1):
         res[i] = op(res[i // 2], res[i - i // 2])
     return res[1:]
 
@@ -58,7 +58,7 @@
 def iid_unknown(X, n, k, **kwargs):
     """It gives distribution of sample _unknown on level k based on sample size of n."""
     fun = PiecewiseFunction([])
-    for i in xrange(k, n+1):
+    for i in range(k, n+1):
         fun += iid_order_stat(X, n, i).get_piecewise_pdf()
     fun2 = (1.0 / (1+n-k)) * fun
     return FunDistr(fun = fun2.toInterpolated(), breakPoints = X.get_piecewise_pdf().getBreaks(), **kwargs)
@@ -91,7 +91,7 @@
     Extended operator arguments."""
     res = [None] * (n+1)
     res[1] = x
-    for i in xrange(2, n+1):
+    for i in range(2, n+1):
         i1 = i // 2
         i2 = i - i // 2
         res[i] = op(i1, res[i1], i2, res[i2])
@@ -143,9 +143,9 @@
     T = UniformDistr()+UniformDistr()
     T.plot(linewidth=2.0)
     n = 11
-    for k in xrange(0, n):
+    for k in range(0, n):
         T = UniformDistr()+UniformDistr()
-        print "k=", k+1, "n=", n
+        print("k=", k+1, "n=", n)
         fun2 = iid_order_stat(T, n, k+1)
         fun = iid_quantile(T, n, k+1)
         fun2.plot(xmin=0,xmax=2,color="c", linewidth=4.0)
--- ./test/nosetester.py	(original)
+++ ./test/nosetester.py	(refactored)
@@ -11,5 +11,5 @@
     #print nose.run(argv=[__file__, '-v', '-i=pacal/*', '--with-profile', '--profile-stats-file=out/pacal.proof']) # it works, but unknown output format (file abcd.txt) 
     #nose.run(argv=[__file__, '-v'])
     #nose.run()
-    print nose.run(argv=[__file__, '--verbosity=2', '--with-id', '--with-coverage', '--cover-tests'])
+    print(nose.run(argv=[__file__, '--verbosity=2', '--with-id', '--with-coverage', '--cover-tests']))
     plt.show();
--- ./test/testArith.py	(original)
+++ ./test/testArith.py	(refactored)
@@ -12,12 +12,12 @@
 
 class TestArith(unittest.TestCase):
     def setUp(self):
-        print """====Test starting============================="""        
+        print("""====Test starting=============================""")        
         self. ts = time.time()
         
     def tearDown(self):
         te = time.time()
-        print 'test done,   time=%7.5f s' % (te - self.ts)        
+        print('test done,   time=%7.5f s' % (te - self.ts))        
     
     def testCentralLimit(self):
         fig = plt.figure()
@@ -25,7 +25,7 @@
         mu = 2
         sigma = 1
         S = NormalDistr(mu, sigma)
-        for i in xrange(n-1):
+        for i in range(n-1):
             S.hist()
             S = S + NormalDistr(mu,sigma)
         S.plot()
@@ -34,7 +34,7 @@
         s = S.std()
         #print "error =", S.err, "interp. nodes used =", S.n_nodes, "#breakpoints =", len(S.breaks)        
         te = time.time()
-        self.assert_(abs(s-sqrt(n))<1e-15 and (te-self.ts)<10, 'difference in comparison with theoretical std: mean(X)={0}, std={1}, sqrt({2})={3}, OR it should be faster time={4} s'.format(m,s,n,sqrt(n), (te - self.ts)))
+        self.assertTrue(abs(s-sqrt(n))<1e-15 and (te-self.ts)<10, 'difference in comparison with theoretical std: mean(X)={0}, std={1}, sqrt({2})={3}, OR it should be faster time={4} s'.format(m,s,n,sqrt(n), (te - self.ts)))
 
     def testCentralLimitUniform(self):
         fig = plt.figure()
@@ -44,7 +44,7 @@
         sigma = 1
         S = UniformDistr(a, b)
         S.plot()
-        for i in xrange(n-1):
+        for i in range(n-1):
             S.hist()
             S = S + UniformDistr(a,b)
             S.plot()
@@ -54,10 +54,10 @@
         #Y = InterpolatedDistr(S)
         #print "error =", S.err, "interp. nodes used =", S.n_nodes, "#breakpoints =", len(S.breaks)        
         te = time.time()
-        print te-self.ts
-        print s - sqrt(n/12.0)
+        print(te-self.ts)
+        print(s - sqrt(n/12.0))
         #self.assert_(abs(s-sqrt(n))<1e-14 and (te-self.ts)<1, 'difference in comparison with theoretical std: mean(X)={0}, std={1}, sqrt({2})={3}, OR it should be faster time={4} s'.format(m,s,n,sqrt(n), (te - self.ts)))
-        self.assert_(abs(s-sqrt(n/12.0))<1e-14, 'difference in comparison with theoretical std: mean(X)={0}, std={1}, sqrt({2}/12.0)={3}'.format(m,s,n,sqrt(n/12.0)))
+        self.assertTrue(abs(s-sqrt(n/12.0))<1e-14, 'difference in comparison with theoretical std: mean(X)={0}, std={1}, sqrt({2}/12.0)={3}'.format(m,s,n,sqrt(n/12.0)))
 
     def testSumOfSquares(self):
         fig = plt.figure()
@@ -69,11 +69,11 @@
             X = NormalDistr(mu, sigma)
             S = S + X
             S.hist()        
-        print 'sum of {0} normal N({1}, {2}) variables:'.format(n, mu, sigma) RefactoringTool: Refactored ./test/testFunc.py
RefactoringTool: Refactored ./test/testNumeric.py

+        print('sum of {0} normal N({1}, {2}) variables:'.format(n, mu, sigma)) 
         
     def testSumDependent(self):
-        print """sum of two the same normal variables X+X=2X, 
-        not two i.i.d."""
+        print("""sum of two the same normal variables X+X=2X, 
+        not two i.i.d.""")
         fig = plt.figure()
         X = NormalDistr(1,1)
         Y = X+X
@@ -83,8 +83,8 @@
         Y.hist()
         m = Y.mean()
         s = Y.std()
-        print 'mean(X)={0}, std={1}, abs(std-sqrt(2))={2}'.format(m,s, abs(s-sqrt(2)))        
-        self.assert_(abs(s-2)<1e-10,'sum of dependent variables not working yet')
+        print('mean(X)={0}, std={1}, abs(std-sqrt(2))={2}'.format(m,s, abs(s-sqrt(2))))        
+        self.assertTrue(abs(s-2)<1e-10,'sum of dependent variables not working yet')
 
     def testCupOfTeaExample(self):
         """ The cup of tea example, take n times sip of tea 
@@ -96,7 +96,7 @@
         """
         n = 2
         Y_0=ConstDistr(100)
-        self.assert_(1<0, 'not work yet')
+        self.assertTrue(1<0, 'not work yet')
     
 def suite():
     suite = unittest.TestSuite()
--- ./test/testFunc.py	(original)
+++ ./test/testFunc.py	(refactored)
@@ -10,35 +10,35 @@
 
 class TestFunc(unittest.TestCase):
     def setUp(self):
-        print """====Test starting============================="""        
+        print("""====Test starting=============================""")        
         self.N1 = NormalDistr(0,1)
         self.N2 = NormalDistr(0,1)        
         self.ts = time.time()
         
     def tearDown(self):
         te = time.time()
-        print 'test done,   time=%7.5f s' % (te - self.ts)
+        print('test done,   time=%7.5f s' % (te - self.ts))
                
     def testChiSqr(self):
         """
             square of single normal variable
         """
         fig = plt.figure()
-        print "comparing \chi^2_1 with N(0,1)^2" 
+        print("comparing \chi^2_1 with N(0,1)^2") 
         orgChi2 =  ChiSquareDistr(1)             
         testChi2 = self.N1 ** 2
         orgChi2.plot()
         testChi2.plot()
         L1diff, err = quad(lambda x : abs(orgChi2.pdf(x)-testChi2.pdf(x)),0,Inf)
-        print 'L_1 difference = {0}'.format(L1diff)
-        self.assert_(L1diff < 1e-8);
+        print('L_1 difference = {0}'.format(L1diff))
+        self.assertTrue(L1diff < 1e-8);
     
     def testChiSqrWithInterpolation(self):
         """
             square of single normal variable
         """
         fig = plt.figure()
-        print "testing \chi^2_1 = N(0,1)^2, with interpolation" 
+        print("testing \chi^2_1 = N(0,1)^2, with interpolation") 
         N1 = NormalDistr(0,1)
         orgChi2 =  ChiSquareDistr(1)             
         squareN1 = N1**2
@@ -48,18 +48,18 @@
         testChi2.plot()
         squareN1.hist()
         L1diff, err = quad(lambda x : abs(orgChi2.pdf(x)-testChi2.pdf(x)),0,Inf)
-        print 'L_1 difference = {0}'.format(L1diff)
-        self.assert_(0< 1e-8);
+        print('L_1 difference = {0}'.format(L1diff))
+        self.assertTrue(0< 1e-8);
         
     def testChi2Sqr(self):
-        print "testing superposition real function with random variable"  
-        self.assert_(0< 1e-8);
+        print("testing superposition real function with random variable")  
+        self.assertTrue(0< 1e-8);
         
     def testChi3Sqr(self):
         """
             sum of squares of three independent normal variables
         """
-        self.assert_(0< 1e-8)
+        self.assertTrue(0< 1e-8)
 def suite():
     suite = unittest.TestSuite()
     suite.addTest(TestFunc("testChiSqr"))
--- ./test/testNumeric.py	(original)
+++ ./test/testNumeric.py	(refactored)
@@ -50,7 +50,7 @@
         self.v = self.X.var()
         self.EX = mu
         self.VX = sigma**2
-        self.assert_((abs(self.m-self.EX)+abs(self.v-self.VX)) < self.tol, self.errMsg);
+        self.assertTrue((abs(self.m-self.EX)+abs(self.v-self.VX)) < self.tol, self.errMsg);
         
     def testChi2(self):
         #print """basic stats of Chi2 distribution"""
@@ -60,7 +60,7 @@
         self.v = self.X.var()
         self.EX = df
         self.VX = df*2
-        self.assert_((abs(self.m-self.EX)+abs(self.v-self.VX)) < self.tol, self.errMsg);
+        self.assertTrue((abs(self.m-self.EX)+abs(self.v-self.VX)) < self.tol, self.errMsg);
         
     def testUniform(self):
         #print """basic stats of uniform distribution"""
@@ -71,7 +71,7 @@
         self.v = self.X.var()
         self.EX = (a+b)/2.0
         self.VX = (b-a)**2/12.0
-        self.assert_((abs(self.m-self.EX) + abs(self.v-self.VX)) < self.tol, self.errMsg);
+        self.assertTrue((abs(self.m-self.EX) + abs(self.v-self.VX)) < self.tol, self.errMsg);
 
 class TestIntegral(unittest.TestCase):
     def setUp(self):
@@ -79,7 +79,7 @@
         self.tol = 8 * eps
         self.ts = time.time()
     def _assert_integ(self, err, I):
-        self.assert_(err < self.tol, repr(I) + " +/- " + str(err))
+        self.assertTrue(err < self.tol, repr(I) + " +/- " + str(err))
     def tearDown(self):
         te = time.time()
         #print self.iClenshaw - self.exact, self.errClenshaw, self.tClenshaw - self.ts
@@ -172,7 +172,7 @@
         ci = ChebyshevInterpolator(cos, -2, 8)
         X = linspace(-2, 8, 1000)
         err = self.get_max_diff(X, cos, ci)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
     def testPMInfInterp(self):
         def f(x):
             return exp(-x*x)
@@ -180,13 +180,13 @@
         X = exp(linspace(-10, 10, 1000))
         X = hstack([-X,X])
         err = self.get_max_diff(X, f, ci)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
     def testCauchyPMInf(self):
         ci = ChebyshevInterpolator_PMInf(cauchy)
         X = exp(linspace(-10, 10, 1000))
         X = hstack([-X,X])
         err = self.get_max_diff(X, cauchy, ci)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
     def testInterpPInf(self):
         def f(x):
             return exp(-x)
@@ -194,21 +194,21 @@
         X = ci.vt.L + exp(linspace(-10, 10, 1000))
         #print X
         err = self.get_max_diff(X, f, ci)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
     def testInterpMInf(self):
         def f(x):
             return exp(x)
         ci = ChebyshevInterpolator_MInf(f, -2.0)
         X = ci.vt.U - exp(linspace(-10, 10, 1000))
         err = self.get_max_diff(X, f, ci)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
     def testNormalPMInf(self):
         ci = ChebyshevInterpolator_PMInf(normpdf)
         X = exp(linspace(-10, 10, 1000))
         X = hstack([-X,X])
         err = self.get_max_diff(X, normpdf, ci)
         #print err, len(ci.Xs)
-        self.assert_(err < self.tol, self._str_error(err, ci))
+        self.assertTrue(err < self.tol, self._str_error(err, ci))
 class TestVectorisation(unittest.TestCase):
     def setUp(self):
         #print """====Test starting============================="""        
@@ -223,73 +223,73 @@
     def testNormal(self):
         N1 = NormalDistr(0,1)
         y=N1.pdf(self.x)
-        self.assert_(0 < 1)
+        self.assertTrue(0 < 1)
     def testUniform(self):
         U1 = UniformDistr(0,1)
         y=U1.pdf(self.x)
         #print self.x,y
         #plot(self.x, y)
-        self.assert_(0 < 1)    
+        self.assertTrue(0 < 1)    
     def testChi2(self):
         Ch = ChiSquareDistr(4)
         y=Ch.pdf(self.x)
-        self.assert_(0 < 1)      
+        self.assertTrue(0 < 1)      
     def testUniformFor(self):
         U1 = UniformDistr(0,1)
         y1 = [U1.pdf(x) for x in self.x]
         #print self.x,y
         #plot(self.x, y)
-        self.assert_(0 < 1)    
+        self.assertTrue(0 < 1)    
     def testChebFor(self):
         c = ChebyshevInterpolator(cauchy, -2, 2)RefactoringTool: Refactored ./test/testPiecewise.py

         y = [c.interp_at(x) for x in self.x]
         #print self.x,y
         #plot(self.x, y)
-        self.assert_(0 < 1) 
+        self.assertTrue(0 < 1) 
     def testCheb(self):
         c = ChebyshevInterpolator(cauchy, -2, 2)
         y = c.interp_at(self.x)       
         #print self.x,y
         #plot(self.x, y)
-        self.assert_(0 < 1) 
+        self.assertTrue(0 < 1) 
     def testChebMat(self):
         c = ChebyshevInterpolator(cauchy, -2, 2)
         y = c.interp_at(self.x_mat)       
         #print self.x_mat
         #print y
-        self.assert_(0 < 1) 
+        self.assertTrue(0 < 1) 
 
 class TestVarTransform(unittest.TestCase):
     def setUp(self):
         self.vt = VarTransformAlgebraic_PMInf()
     def testVarChangeWMask1(self):
         x, mask = self.vt.inv_var_change_with_mask(array([-1.0,0.0,1.0]))
-        self.assert_(abs(x[1]) <= eps and all(mask == [False, True, False]))
+        self.assertTrue(abs(x[1]) <= eps and all(mask == [False, True, False]))
     def testVarChangeWMask2(self):
         # test integer arrays
         x, mask = self.vt.inv_var_change_with_mask(array([-1,0,1]))
-        self.assert_(abs(x[1]) <= eps and all(mask == [False, True, False]))
+        self.assertTrue(abs(x[1]) <= eps and all(mask == [False, True, False]))
     def testVarChangeWMask3(self):
         # test scalars
         x, mask = self.vt.inv_var_change_with_mask(-1.0)
-        self.assert_(mask == False)
+        self.assertTrue(mask == False)
     def testVarChangeWMask4(self):
         # test scalars
         x, mask = self.vt.inv_var_change_with_mask(1.0)
-        self.assert_(mask == False)
+        self.assertTrue(mask == False)
     def testVarChangeWMask5(self):
         # test scalars
         x, mask = self.vt.inv_var_change_with_mask(0)
-        self.assert_(abs(x) <= eps and mask == True)
+        self.assertTrue(abs(x) <= eps and mask == True)
     def testApplyWithTransform1(self):
         y = self.vt.apply_with_inv_transform(lambda x: x+1, array([-1,0,1]))
-        self.assert_(all(abs(y - [0, 1, 0]) <= eps))
+        self.assertTrue(all(abs(y - [0, 1, 0]) <= eps))
     def testApplyWithTransform2(self):
         y = self.vt.apply_with_inv_transform(lambda x: x+1, 0)
-        self.assert_(abs(y - 1) <= eps)
+        self.assertTrue(abs(y - 1) <= eps)
     def testApplyWithTransform3(self):
         y = self.vt.apply_with_inv_transform(lambda x: x+1, 1, def_val = 3)
-        self.assert_(abs(y - 3) <= eps)
+        self.assertTrue(abs(y - 3) <= eps)
 
 class TestInterpolators(unittest.TestCase):
     def setUp(self):
@@ -297,21 +297,21 @@
         self. ts = time.time()     
     def tearDown(self):
         te = time.time()
-        print 'test done,   time=%7.5f s' % (te - self.ts) 
+        print('test done,   time=%7.5f s' % (te - self.ts)) 
     def testChebcoef(self):
         S = PiecewiseFunction(fun=lambda x: sin(4*(x-0.5)), breakPoints=[-1, 1]).toInterpolated()
         seg = S.segments[0]
         Xs, Ys = seg.f.Xs, seg.f.Ys
-        print "Xs=", Xs
-        print "Ys=", Ys
-        print "Cs=", chebt2(Ys)
-        print "Xs=", ichebt2(chebt2(Ys))
+        print("Xs=", Xs)
+        print("Ys=", Ys)
+        print("Cs=", chebt2(Ys))
+        print("Xs=", ichebt2(chebt2(Ys)))
         figure()
         S.plot(color="r")
         D = S.diff()
         D.plot(color="k")
         #show()
-        self.assert_(0 < 1)
+        self.assertTrue(0 < 1)
     def testTrim(self):
         S = PiecewiseFunction(fun=lambda x: sin(4*(x-0.5)), breakPoints=[-1, 1]).toInterpolated()
         I = S.trimInterpolators(abstol=1e-15)
@@ -323,7 +323,7 @@
         subplot(212)
         r.plot()
         #show()
-        self.assert_(0 < 1)
+        self.assertTrue(0 < 1)
     def testDiff(self):
         n=8
         S = UniformDistr(0,2)
@@ -351,7 +351,7 @@
         D.diff().plot()
         plot(xi,mi, 'bo')
         plot(r,D(r), 'ro')
-        self.assert_(0 < 1)
+        self.assertTrue(0 < 1)
     def testMinmax(self):
         n=8
         S = UniformDistr(0,2)
@@ -366,13 +366,13 @@
             D.plot()
             plot(xmaxi,maxi,  'ko')
             plot(xmini,mini,  'ro')
-        self.assert_(0 < 1)
+        self.assertTrue(0 < 1)
     def testDiffInf(self):
         S = BetaDistr(3,4)* BetaDistr(3,4)
         S.summary()
         figure()
         S.plot()
-        print S.get_piecewise_pdf()
+        print(S.get_piecewise_pdf())
         D = S.get_piecewise_pdf().diff()
         D.plot(color="k")
         show()
--- ./test/testPiecewise.py	(original)
+++ ./test/testPiecewise.py	(refactored)
@@ -101,7 +101,7 @@
             plot(X, Y, color='k')            
             subplot(n,2,2*i+2)
             plot(X, abs(h(X) - Y)/Y)
-            print "iii====", i, h
+            print("iii====", i, h)
             #for seg in h.segments:
             #    figure()
             #    loglog(seg.f.getNodes()[0], seg.f.getNodes()[1], "o")
@@ -113,16 +113,16 @@
             subplot(n,1,i+1)
             h.plot(color = 'g', linewidth = 3)        
             plot(X, h(X), color='r',linewidth=2)            
-            print "iii====", i, h
+            print("iii====", i, h)
             LInferr[i] = 0
             LInferr2[i] = 0
             
         
         ints[i] = h.integrate()
-        print "int error=", 1.0-ints[i]
+        print("int error=", 1.0-ints[i])
         if i==n-1:
             break
-        print h,g
+        print(h,g)
         h=op(h, g)
     if plot_tails:
         plt.figure()
@@ -130,10 +130,10 @@
             h.plot_tails(asympf = asympf)
         else:
             h.plot_tails()
-    print ints
-    print "interr = ", 1-ints
-    print "LInfAbs = ", LInferr
-    print "LInfRel = ", LInferr2
+    print(ints)
+    print("interr = ", 1-ints)
+    print("LInfAbs = ", LInferr)
+    print("LInfRel = ", LInferr2)
     return ints
 
 def ratioTester(f, Lexp = -10, Uexp=1):
@@ -145,16 +145,16 @@
     
     subplot(3,1,1)
     f.plot(color='k')
-    print "f=", f, f(array([1.0]))
+    print("f=", f, f(array([1.0])))
     r=convdiv(f,f)
-    print "r=", r
+    print("r=", r)
     
     r.plot(color='k', linewidth=2)
     subplot(3,1,2)
     p = convprod(r,r)
-    print "p=", p
+    print("p=", p)
     d = convdiv(r,r)
-    print "d=", d
+    print("d=", d)
     p.plot(color='k', linewidth=1, linestyle='-')
     d.plot(color='r', linewidth=1, linestyle='-')
     subplot(3,1,3)
@@ -167,11 +167,11 @@
     intd = d.integrate()
     interr = err.integrate()
     
-    print "intf = ", intf, 1-intf
-    print "intr = ", intr, 1-intr
-    print "intp = ", intp, 1-intp
-    print "intd = ", intd, 1-intd
-    print "interr = ", interr
+    print("intf = ", intf, 1-intf)
+    print("intr = ", intr, 1-intr)
+    print("intp = ", intp, 1-intp)
+    print("intd = ", intd, 1-intd)
+    print("interr = ", interr)
     return max(1-intp, 1-intd)
 
 def inversionTester(f, Lexp = -10, Uexp=1):
@@ -187,13 +187,13 @@
     p=convprod(f,r);
     d=convdiv(f,f);
     
-    print "f=", f
-    print "r=", r
+    print("f=", f)
+    print("r=", r)
     r.plot(color='k', linewidth=2)
     
     subplot(3,1,2)
-    print "p=", p
-    print "d=", d
+    print("p=", p)
+    print("d=", d)
     p.plot(color='k', linewidth=1, linestyle='-')
     d.plot(color='r', linewidth=1, linestyle='-')
     subplot(3,1,3)
@@ -206,19 +206,19 @@
     intd = d.integrate()
     interr = err.integrate()
     
-    print "intf = ", intf, 1-intf
-    print "intr = ", intr, 1-intr
-    print "intp = ", intp, 1-intp
-    print "intd = ", intd, 1-intd
-    print "interr = ", interr
+    print("intf = ", intf, 1-intf)
+    print("intr = ", intr, 1-intr)
+    print("intp = ", intp, 1-intp)
+    print("intd = ", intd, 1-intd)
+    print("interr = ", interr)
     return max(1-intp, 1-intd)
 
 def integrationTester(fun):
     ifun1 = fun.cumint()
     ifun = ifun1.toInterpolated()
-    print fun
-    print ifun1
-    print ifun
+    print(fun)
+    print(ifun1)
+    print(ifun)
     subplot(2,1,1)
     fun.plot()
     subplot(2,1,2)
@@ -227,8 +227,8 @@
     ifun.hist()
     levels =  array([0.05, 0.1, 0.5, 0.9, 0.95])
     for level in levels:
-        print "level={0} cv={1}".format(level, ifun.inverse(level))
-    print "levels=",levels, "cv=", ifun.inverse(levels)
+        print("level={0} cv={1}".format(level, ifun.inverse(level)))
+    print("levels=",levels, "cv=", ifun.inverse(levels))
 class TestPicewiseConvs(unittest.TestCase):
     def setUp(self):
         #print """====Test starting============================="""        
@@ -238,7 +238,7 @@
         self.ts = time.time()        
     def tearDown(self):
         te = time.time()
-        print 'test done,   time=%7.5f s' % (te - self.ts) 
+        print('test done,   time=%7.5f s' % (te - self.ts)) 
     def testPiecewiseFunction(self):
         """Fragment of Cauchy distribution as piecewise function"""
         fig = plt.figure()
@@ -275,10 +275,10 @@
         #finterp.plot(linewidth=1, color = 'k', linestyle='-')
         gint = g.integrate()        
         fint = f.integrate()
-        print "f=",f
-        print "g=",g        
-        print fint + fint, gint, fint * fint - gint        
-        self.assert_(0 < 1) 
+        print("f=",f)
+        print("g=",g)        
+        print(fint + fint, gint, fint * fint - gint)        
+        self.assertTrue(0 < 1) 
  
     def testConvUniformMix(self):
         """Sum of N mixtures of uniform random variables"""
@@ -295,10 +295,10 @@
         for i in range(self.n):
             h = conv(h,f)
             h.plot(linewidth=1, color = 'k', linestyle='-')
-            print i, h
+            print(i, h)
         self.f = h
         int = h.integrate()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvUniform(self):
         """Sum of N U[0,1] random variables"""
         plt.figure()
@@ -310,9 +310,9 @@
         for i in range(self.n) :
             h = conv(h,f)
             h.plot(linewidth=1, color = 'k', linestyle='-')
-            print i, h
+            print(i, h)
         int = h.integrate()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvCauchy(self):
         """Mean of the N Cauchy random variables, on figure difference between original single cauchy and mean of N ..."""
         segf1 = Segment(-1.0, 0.0, lambda x:cauchy(x))
@@ -328,10 +328,10 @@
         #fig = plt.figure()
         #h.plot(linewidth=3, color = 'b', linestyle='-')
         int = h.integrate()
-        print int
-        fig = plt.figure()
-        print h
-        print h.integrate()
+        print(int)
+        fig = plt.figure()
+        print(h)
+        print(h.integrate())
         for i in range(self.n):
             h = conv(h,f)
             #h.plot(color = 'r', linewidth=i+1)
@@ -346,11 +346,11 @@
             X = linspace(-10,10,10000)
             E = k(X) - cauchy(X,c=i+2)#f(X)
             plot(X, E, linewidth=0.5, color = 'k', linestyle='-')
-            print i, h
+            print(i, h)
         I = h.integrate()
         figure()
         h.plot_tails(asympf = lambda x: -2*x)
-        self.assert_(abs(I-1)<self.tol, 'integral = {0}'.format(abs(I-1)))
+        self.assertTrue(abs(I-1)<self.tol, 'integral = {0}'.format(abs(I-1)))
         
     def testConvXalpha(self):
         """Mean of the N Cauchy random variables, on figure difference between original single cauchy and mean of N ..."""
@@ -378,12 +378,12 @@
             fig = plt.figure()
             estimateDegreeOfPole(f, Inf)
             estimateDegreeOfPole(h, Inf)
-        print f
-        print h
+        print(f)
+        print(h)
         it = h.integrate()
         intf = f.integrate()
-        print "intf=", intf * intf, "int=", it, ", tol=", intf*intf-it
-        self.assert_(abs(it-1)<self.tol, 'integral = {0}'.format(abs(it)))
+        print("intf=", intf * intf, "int=", it, ", tol=", intf*intf-it)
+        self.assertTrue(abs(it-1)<self.tol, 'integral = {0}'.format(abs(it)))
         
     def testConvNormalScaled(self):
         """Mean of the N normal random variables, on figure difference between original single cauchy and mean of N ..."""
@@ -404,7 +404,7 @@
             #h= convmean(h,f, p=0.5, q=0.5)
             subplot(3,1,1)
             h.plot(linewidth=1, linestyle='-')
-            print i, h
+            print(i, h)
             #int = h.integrate()
             #print 'initegral=', int
         #subplot(3,1,2)
@@ -443,7 +443,7 @@
         int = h.integrate()
         #figure()
         #h.plot_tails()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
     def testConvStable0_5(self):
         """Sum of stable distributions with alpha=0.5."""
@@ -471,14 +471,14 @@
             me[i+1] = h.mean()
             va[i+1] = h.var()
             h.plot(linewidth=1, linestyle='-')
-            print i, h
+            print(i, h)
             int = h.integrate()
-            print 'initegral=', int, repr(int), abs(int-1)
-        print "mean=", me
-        print "var=", va
+            print('initegral=', int, repr(int), abs(int-1))
+        print("mean=", me)
+        print("var=", va)
         figure()
         h.plot_tails()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
         
     def testConvprodUniform(self):
@@ -492,10 +492,10 @@
         for i in range(self.n) :
             h = convprod(h,f)
             h.plot(linewidth=1, color = 'k', linestyle='-')
-            print i, h
+            print(i, h)
             int = h.integrate()
-            print 'initegral=', int
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))    
+            print('initegral=', int)
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))    
     def testConvprodUniform01(self):
         """Product of the N U[0.0, 1.0] random variables"""
         fig = plt.figure()
@@ -518,12 +518,12 @@
             plot(X,Y,linewidth=1, color = 'r', linestyle='--')
             plt.subplot(2,1,2)
             plot(X, abs(Y-h(X))/Y, linewidth=1, color = 'b', linestyle='-')
-            print i, h
+            print(i, h)
             int[i] = h.integrate()
             relerr[i] = max(abs(Y-h(X))/Y)
-            print 'initegral=', int
-            print 'initerr=', relerr
-        self.assert_(abs(max(int)-1)<self.tol, 'integrals = {0}'.format(abs(int-1)))    
+            print('initegral=', int)
+            print('initerr=', relerr)
+        self.assertTrue(abs(max(int)-1)<self.tol, 'integrals = {0}'.format(abs(int-1)))    
     
     def testConvprodUniform2(self):
         """Product of U[1, 2] and U[-1,1]"""
@@ -545,10 +545,10 @@
         for i in range(1) :
             h = convprod(g,h)
             h.plot(linewidth=1, color = 'k', linestyle='-')
-            print i, h
+            print(i, h)
             int = h.integrate()
-            print 'initegral=', int
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))    
+            print('initegral=', int)
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))    
     def testConvprodMix(self):
         """Product of N mixtures of uniform random variables"""
         plt.figure()
@@ -564,9 +564,9 @@
             h = convprod(h,f)
             h.plot(linewidth=1, color = 'k', linestyle='-')
             int = h.integrate()
-            print i, h
-            print 'initegral=', int
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+            print(i, h)
+            print('initegral=', int)
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvprodCauchy(self):
         """Product of two Cauchy random variables"""
         fig = plt.figure()
@@ -604,14 +604,14 @@
             k.plot(linewidth=1, color = 'k', linestyle='-')            
             inth = h.integrate()
             intk = h.integrate()
-            print inth, h
-            print intk, k
+            print(inth, h)
+            print(intk, k)
             X=linspace(-100,100, 100000 )
             Y=h(X)-k(X)
             plot(X,Y,'k')
             
             subplot(3,1,3)
-        self.assert_(abs(max(inth,intk)-1)<self.tol, 'integral = {0}'.format(max(inth,intk)-1))
+        self.assertTrue(abs(max(inth,intk)-1)<self.tol, 'integral = {0}'.format(max(inth,intk)-1))
     def testConvprodCauchyUni(self):
         """Product of Cauchy and uniform variables"""
         fig = plt.figure()
@@ -642,9 +642,9 @@
             subplot(3,1,3)
             k.plot(linewidth=1, color = 'k', linestyle='-')            
             int = h.integrate()
-            print i, h
-            print 'initegral=', int  
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+            print(i, h)
+            print('initegral=', int)  
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvprodMix2(self):
         """Another product of N mixtures of uniform random variables"""
         plt.figure()       
@@ -664,16 +664,16 @@
         #print "left_degree=", estimateDegreeOfPole(h,-Inf)
         #print "left_degree=", estimateDegreeOfPole(h,Inf)
         for i in range(1):
-            print i
+            print(i)
             h = convprod(g,h)
             h.plot(linewidth=1, color = 'k', linestyle='-')
             int = h.integrate()
-            print i, h
-            print 'initegral=', int
+            print(i, h)
+            print('initegral=', int)
             #fig = plt.figure()
             #print "left_degree=", estimateDegreeOfPole(h,-Inf)
             #print "left_degree=", estimateDegreeOfPole(h,Inf)    
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
         
     def testConvProdNormal(self):
         """Product two normal random variables"""
@@ -693,9 +693,9 @@
             h = convprod(h,f)
             h.plot(linewidth=1, color = 'k', linestyle='-')            
             int = h.integrate()
-            print i, h
-            print 'initegral=', int  
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+            print(i, h)
+            print('initegral=', int)  
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
     def testConvProdSqrtUni(self):
         """Product two normal random variables"""
@@ -720,9 +720,9 @@
         fint = f.integrate()        
         gint = g.integrate()   
         axis((0,2,0,5))     
-        print ">>>>>>>>>>>>>>",fint, int, gint*fint-int
-        print h
-        self.assert_(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(gint*fint-int)))
+        print(">>>>>>>>>>>>>>",fint, int, gint*fint-int)
+        print(h)
+        self.assertTrue(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(gint*fint-int)))
 
     def testConvDivInf1(self):
         """Product two normal random variables"""
@@ -764,9 +764,9 @@
         #semilogx(X,Y)
         int = h.integrate()            
         fint = f.integrate()  
-        print ">>>>>>>>>>>>>>",fint, int, fint*fint-int
-        print i
-        print h
+        print(">>>>>>>>>>>>>>",fint, int, fint*fint-int)
+        print(i)
+        print(h)
         fig = plt.figure()
         h.semilogx(linewidth=1, color = 'b', linestyle='-')
         h2.semilogx(linewidth=1, color = 'k', linestyle='-')
@@ -820,7 +820,7 @@
         #h.plot(linewidth=1, color = 'k', linestyle='-')
         #fig = plt.figure()
         #f.semilogx(linewidth=2, color = 'k', linestyle='-')
-        self.assert_(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(fint*fint-int)))
+        self.assertTrue(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(fint*fint-int)))
     
     def testConvProdInf1(self):
         """Product two normal random variables"""
@@ -856,9 +856,9 @@
         #h.semilogx()
         int = h.integrate()            
         fint = f.integrate()                
-        print ">>>>>>>>>>>>>>",fint, int, fint*fint-int
-        print h
-        self.assert_(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(fint*fint-int)))
+        print(">>>>>>>>>>>>>>",fint, int, fint*fint-int)
+        print(h)
+        self.assertTrue(abs(fint-int)<self.tol, 'integral = {0}'.format(abs(fint*fint-int)))
 
     def testConvDivUni2(self):
         """Product two normal random variables"""
@@ -878,10 +878,10 @@
             plt.title('tails i={0}'.format(i))
             g.plot_tails()
             int = g.integrate()
-            print i, g
-            print 'initegral=', int  
+            print(i, g)
+            print('initegral=', int)  
         axis((-10,10,0,0.51))  
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
     def testConvDivNormal(self):
         """Quotient two normal random variables"""
@@ -915,15 +915,15 @@
         h.plot(linewidth=1, color = 'k', linestyle='-')            
         k = h - g
         int = h.integrate()
-        print h
-        print 'initegral=', int
+        print(h)
+        print('initegral=', int)
         fig = plt.figure()
         g.plot(color = 'b')
         h.plot(color = 'k')
         fig = plt.figure()
         k.plot(color = 'r')
         plt.title("Quotient two normal random variables - difference between theoretical Cauchy distribution")
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
     def testConvDivCauchy(self):
         """Quotient of two cauchy random variables"""
@@ -948,9 +948,9 @@
             
             h.plot(linewidth=1, color = 'k', linestyle='-')            
             int = h.integrate()
-            print i, h
-            print 'initegral=', int  
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+            print(i, h)
+            print('initegral=', int)  
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
 
     def testConvDivUni(self):
         """Quotient two normal random variables"""
@@ -972,10 +972,10 @@
             #k = convdiv(f,h)
             #k.plot(linewidth=1, color = 'b', linestyle='-')            
             int = h.integrate()
-            print i, h
-            print 'initegral=', int  
+            print(i, h)
+            print('initegral=', int)  
         axis((-10,10,0,0.51))
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvDivUniWide(self):
         """Quotient two random variables.
 
@@ -998,9 +998,9 @@
             figure()
             h.plot(linewidth=1, color = 'k', linestyle='-')            
             int = h.integrate()
-            print i, h
-            print 'initegral=', int  
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+            print(i, h)
+            print('initegral=', int)  
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     
     def testCauchy(self):
         """Quotient of two cauchy random variables"""
@@ -1037,12 +1037,12 @@
         fig = plt.figure()
         k.plot(linewidth=1, color = 'k', linestyle='-')
         plot(X, prodcauchy(X), color = 'g', linestyle='-', linewidth=2)
-        print "int(h)=", 1.0-h.integrate()
-        print "int(k)=", 1.0-k.integrate()
-        print "h=", h
-        print "k=", k
-        print 'difference=', max(Yh), max(Yk)  
-        self.assert_(abs(max(Yh))<self.tol, 'diff = {0}'.format(abs(max(max(Yh), max(Yh)))))
+        print("int(h)=", 1.0-h.integrate())
+        print("int(k)=", 1.0-k.integrate())
+        print("h=", h)
+        print("k=", k)
+        print('difference=', max(Yh), max(Yk))  
+        self.assertTrue(abs(max(Yh))<self.tol, 'diff = {0}'.format(abs(max(max(Yh), max(Yh)))))
    
     def testConvDivMix(self):
         """Quotient of N mixtures of uniform random variables"""
@@ -1083,11 +1083,11 @@
             figure()
             h.plot_tails()
             int = h.integrate()
-            print i, h
-            print 'initegral=', int
+            print(i, h)
+            print('initegral=', int)
         figure()
         h.plot_tails()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
     def testConvMin(self):
         """Max of N of uniform random variables"""
         fig = plt.figure()
@@ -1109,9 +1109,9 @@
             h = convmin(f,h)
             h.plot(linewidth=1, color = 'k', linestyle='-')
             int = h.integrate()
-            print i, h
-            print 'initegral - 1 =', int-1     
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
+            print(i, h)
+            print('initegral - 1 =', int-1)     
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
     def testConvmaxNormal(self):
         """Mean of the N normal random variables, on figure difference between original single cauchy and mean of N ..."""
         fig = plt.figure()
@@ -1134,8 +1134,8 @@
             #h= convmean(h,f, p=0.5, q=0.5)
             subplot(2,1,2)
             int = h.integrate()
-            print i, h
-            print 'initegral=', int
+            print(i, h)
+            print('initegral=', int)
         subplot(2,1,2)
         h.plot(linewidth=1, linestyle='-')
         #subplot(3,1,3)
@@ -1145,7 +1145,7 @@
         #y=abs(k(x)-normpdf(x))
         #plot(x,y,linewidth=0.5, linestyle='-')
         int = h.integrate()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
         
     def testConvMax(self):
         """Min of N of uniform random variables"""
@@ -1167,9 +1167,9 @@
             h = convmax(f,h)
             h.plot(linewidth=1, color = 'k', linestyle='-')
             int = h.integrate()
-            print i, h
-            print 'initegral - 1 =', int-1     
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
+            print(i, h)
+            print('initegral - 1 =', int-1)     
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
         
     def testConvDiscrete(self):
         """Sum of N of binomial random variables"""
@@ -1179,21 +1179,21 @@
         f = PiecewiseFunction([])
         f.addSegment(segf1)
         f.addSegment(segf2)
-        print f.getDiracs()
+        print(f.getDiracs())
         for i in range(3):
-            print i
+            print(i)
             f=convdiracs(f, f, fun = lambda x,y : x+y)
-            print "cumsum=", f.integrate()-1, f
+            print("cumsum=", f.integrate()-1, f)
         plt.figure()
         f.plot();
         for i in range(3):
             f=convdiracs(f, f, fun = lambda x,y : x-y)
-            print "cumsum=", f.integrate()-1, f
+            print("cumsum=", f.integrate()-1, f)
         plt.figure()
         f.plot();
     def testConvDiscreteMix1(self):
         """Sum of N of binomial random variables"""
-        print "==============="
+        print("===============")
         segf1 = DiracSegment(0.0, 0.3)
         segf2 = DiracSegment(0.5, 0.5)
         segf3 = ConstSegment(0.0, 0.5, 0.4)
@@ -1215,29 +1215,29 @@
         g.plot(linewidth=2, color = 'k');
         
         axis((-1,8,0,1.1))
-        print "===", f, f.integrate()
-        print "===", g, g.integrate()
+        print("===", f, f.integrate())
+        print("===", g, g.integrate())
 
         for i in range(n):
-            print i
+            print(i)
             g=conv(f, g)
             subplot(n+1,1,i+2)
             g.plot(linewidth=2, color = 'k')
-            print "cumsum=", g.integrate()-1, g
+            print("cumsum=", g.integrate()-1, g)
             int = g.integrate()
-            print i, g            
-            print 'initegral - 1 =', int-1  
+            print(i, g)            
+            print('initegral - 1 =', int-1)  
         plt.figure()
         c =g.cumint()
         c.plot()  
         plt.figure()
         g.plot()
         c.hist()       
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1))) 
 
     def testConvDiscreteMix2(self):
         """Sum of N of binomial random variables"""
-        print "==============="
+        print("===============")
         segf1 = DiracSegment(1.0, 0.3)
         segf2 = DiracSegment(0.0, 0.2)
         segf3 = ConstSegment(1.0, 2.0, 0.5)
@@ -1265,12 +1265,12 @@
         g.plot(linewidth=2, color = 'k');
         
         axis((-1,8,0,1.1))
-        print "===", f, f.integrate()
-        print "===", g, g.integrate()
+        print("===", f, f.integrate())
+        print("===", g, g.integrate())
         h=g
         p=g
         for i in range(n):
-            print i
+            print(i)
             subplot(n+3,2,2*i+3)
             h=convmin(h, f)
             h.plot(linewidth=2, color = 'k')
@@ -1280,9 +1280,9 @@
             
             inth = h.integrate()
             intp = p.integrate()
-            print i, " ========================="
-            print "cumsum=", inth-1, inth, h
-            print "cumsum=", intp-1, intp, p
+            print(i, " =========================")
+            print("cumsum=", inth-1, inth, h)
+            print("cumsum=", intp-1, intp, p)
         subplot(n+3,2,2*n+3)
         ch =h.cumint().toInterpolated()
         ch.plot()  
@@ -1298,7 +1298,7 @@
         p.plot()
             
         err = max(abs(inth-1),abs(inth-1))       
-        self.assert_( err < self.tol, 'integral = {0}'.format(err))        
+        self.assertTrue( err < self.tol, 'integral = {0}'.format(err))        
 
     def testRatio(self):
         """Product and quotient of ratios of identical distributions
@@ -1326,7 +1326,7 @@
         plot(X,Y,'k')
         pint = p.integrate()
         qint = q.integrate()
-        print pint, qint, pint-qint
+        print(pint, qint, pint-qint)
     
     def testSegmentsWithPoles(self):
         """Poles..."""
@@ -1342,7 +1342,7 @@
         g.addSegment(segf2)
         #f = conv(f, f)
         plt.figure()
-        print "est=", estimateDegreeOfPole(fun1, 0.0)
+        print("est=", estimateDegreeOfPole(fun1, 0.0))
         
         plt.figure()
         f.plot(linewidth=2)
@@ -1368,10 +1368,10 @@
         
         semilogx(X, (Yf - Y), 'b')
         semilogx(X, (Yf - Y)/Y, 'r')
-        print f.integrate();
-        print g.integrate();
-        print integrate_fejer2(fun1, 0.0, 1.0);
-        print integrate_fejer2(fun2, 0.0, 1.0);
+        print(f.integrate());
+        print(g.integrate());
+        print(integrate_fejer2(fun1, 0.0, 1.0));
+        print(integrate_fejer2(fun2, 0.0, 1.0));
         #X=-1 + logspace(0,-3,100)
         #Y = fun2(X)
         #plot(X, Y, 'r')
@@ -1390,7 +1390,7 @@
         f1.addSegment(segf1)
         f1.addSegment(segf3)
         f1.addSegment(segf4)
-        print f1
+        print(f1)
         g1 = f1.copySquareComposition()
         #g2 = f2.copySquareComposition()
         plt.figure(1)
@@ -1404,7 +1404,7 @@
         g1.plot()
         plt.figure(2)
         estimateDegreeOfPole(g1,0)
-        print "g1=", g1, g1(2)
+        print("g1=", g1, g1(2))
         plt.figure(1)
         h = g1.toInterpolated()
         #print h
@@ -1422,9 +1422,9 @@
             subplot(n,1,i+1)
             semilogx(xx, (abs(h(xx) - yy)))
             ylabel('abs. error')
-            print "iii====", i, h
+            print("iii====", i, h)
             int = h.integrate()
-            print "int error=", 1.0-int
+            print("int error=", 1.0-int)
             if i==n-1:
                 break
             h=conv(h,g1)
@@ -1434,19 +1434,19 @@
     def testLogNotOneOverX(self):
         "Distribution which is O(1/x) whose log is not O(1/x)."
         f1 = PiecewiseFunction([])
-        for i in xrange(1,148):
+        for i in range(1,148):
             seg = ConstSegment((i+1.0) - 1.0/(i), i+1.0, 1.0/(i+1))
             f1.addSegment(seg)
         fig = plt.figure()
         g = f1.copyComposition(lambda x: log(x), lambda x: exp(x), lambda x: exp(x) )
         f2 = PiecewiseFunction([])
-        for i in xrange(1,25):
+        for i in range(1,25):
             seg = ConstSegment((i+1.0) - 1.0/(i), i+1.0, 1.0/(i+1))
             f2.addSegment(seg)
             
         g2 = f2.copyComposition(lambda x: sqrt(x), lambda x: x*x, lambda x: 2*x )  # this is O(1/x)
         f3 = PiecewiseFunction([])
-        for i in xrange(1,125):
+        for i in range(1,125):
             seg = ConstSegment((i+1.0) - 1.0/(i), i+1.0, 1.0/(i+1))
             f3.addSegment(seg)
         g3 = f3.copyComposition(lambda x: x**(1.0/3), lambda x: x*x*x, lambda x: 3*x*x )  # this is O(1/x)
@@ -1522,11 +1522,11 @@
         plt.ylabel('$\sqrt{X}$', fontsize=16)
         subplot(4,1,3)
         plt.ylabel('$\sqrt[3]{X}$', fontsize=16)
-        print g2
-        print f1.integrate()
-        print g.integrate()
-        print g2.integrate()
-        print g3.integrate()
+        print(g2)
+        print(f1.integrate())
+        print(g.integrate())
+        print(g2.integrate())
+        print(g3.integrate())
     def testConvmeanUniform(self):
         """Weighted mean of two uniform random variables
          with different variance, optimal solution"""
@@ -1549,13 +1549,13 @@
         #int = h.integrate()
         #mh = h.mean()
         #vh = h.var()
-        print mf, vf, mg, vg 
+        print(mf, vf, mg, vg) 
         
         w0=[0.5, 0.5]
         fun1 = lambda w : convmean(f,g, p=w[0],q=w[1]).var();
         fun2 = lambda w : convmean(f,g, p=w[0],q=w[1]).iqrange(0.49);
         fun3 = lambda w : convmean(f,g, p=w[0],q=w[1]).medianad();
-        print fun1(w0), fun2(w0), fun3(w0)
+        print(fun1(w0), fun2(w0), fun3(w0))
         w = fmin(fun1, w0)
         w2 = fmin(fun2, w0)
         w3 = fmin(fun3, w0)
@@ -1567,12 +1567,12 @@
         h1 = convmean(f,g, p = w[0] , q = w[1] )
         h2 = convmean(f,g, p = w2[0], q = w2[1] )
         h3 = convmean(f,g, p = w3[0], q = w3[1] )
-        print "fun1:", fun1(w), fun1(w2), fun1(w3)
-        print "fun2:", fun2(w), fun2(w2), fun2(w3)
-        print "fun3:", fun3(w), fun3(w2), fun3(w3)
-        print "w1=", w, h1.var(), h1.iqrange(0.01), h1.medianad()
-        print "w2=", w2, h2.var(), h2.iqrange(0.01), h2.medianad()
-        print "w3=", w3, h3.var(), h3.iqrange(0.01), h3.medianad()
+        print("fun1:", fun1(w), fun1(w2), fun1(w3))
+        print("fun2:", fun2(w), fun2(w2), fun2(w3))
+        print("fun3:", fun3(w), fun3(w2), fun3(w3))
+        print("w1=", w, h1.var(), h1.iqrange(0.01), h1.medianad())
+        print("w2=", w2, h2.var(), h2.iqrange(0.01), h2.medianad())
+        print("w3=", w3, h3.var(), h3.iqrange(0.01), h3.medianad())
         h1.plot(linewidth=2, color = 'b', linestyle='-')
         h2.plot(linewidth=2, color = 'k', linestyle='-')
         h3.plot(linewidth=2, color = 'm', linestyle='-')
@@ -1580,21 +1580,21 @@
         c1 = h1.cumint();
         c2 = h2.cumint();
         c3 = h3.cumint();
-        print f
-        print f.summary()
-        print g
-        print g.summary()
-        print h1
-        print h1.summary()
-        print h2
-        print h2.summary()
-        print h3
-        print h3.summary()
+        print(f)
+        print(f.summary())
+        print(g)
+        print(g.summary())
+        print(h1)
+        print(h1.summary())
+        print(h2)
+        print(h2.summary())
+        print(h3)
+        print(h3.summary())
         c1.plot(linewidth=1, color = 'b', linestyle='-')
         c2.plot(linewidth=1, color = 'k', linestyle='-')
         c3.plot(linewidth=1, color = 'm', linestyle='-')
         int = h1.integrate()
-        self.assert_(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
+        self.assertTrue(abs(int-1)<self.tol, 'integral = {0}'.format(abs(int-1)))
         
     def testConvmeanBeta(self):
         """Weighted mean of two uniform random variables
@@ -1622,7 +1622,7 @@
         h = convmean(n,g, p=0.57142393, q= 0.42857607)
         h.plot(linewidth=1, color = 'k', linestyle='-')
         int = h.integrate()
-        print n.var(), g.var(), h.var()
+        print(n.var(), g.var(), h.var())
         #w0=[0.5, 0.5]
         #fun = lambda w : convmean(n,g, p=w[0],q=w[1]).var();
         #w = fmin(fun, w0)
@@ -1632,19 +1632,19 @@
     def testThChi2(self):
         plt.figure()
         ints = testWithTheoretical(n = 3, op = conv, theoretic = chisqr, a = 0, b=Inf, isPoleAtZero = True)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testThNormal(self):
         plt.figure()
         ints = testWithTheoretical(n = 3, op = conv, theoretic = lambda x,k: normpdf(x,0,sqrt(k)), a = -Inf, b=Inf, isPoleAtZero = False)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testThCauchy(self):
         plt.figure()
         ints = testWithTheoretical(n = 3, op = conv, theoretic = cauchy, a = -Inf, b=Inf, isPoleAtZero = False, plot_tails = True, asympf = lambda x: -2*x)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testThLevy05(self):
         plt.figure()
         ints = testWithTheoretical(n = 2, op = conv, theoretic = lambda x,k: stable05pdf(x,0,k**2), a = 0, b=Inf, isPoleAtZero = False, splitPoints = array([1.0/3]), plot_tails = True, asympf = lambda x: -1.5*x)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testOneOverSqrRoot(self):
         def sqrrrootdistr(x, _n = 1):
             if isscalar(x):
@@ -1661,7 +1661,7 @@
         f = PiecewiseFunction([])
         f.addSegment(SegmentWithPole(0, 1, sqrrrootdistr))
         ints = testWithTheoretical(n = 2, op = conv, f = f, theoretic = sqrrrootdistr, comp_w_theor = False, a = 0, b=1, isPoleAtZero = True)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testOneOverSqrRootAbs(self):
         def sqrrrootdistr(x, _n = 1):
             if isscalar(x):
@@ -1679,11 +1679,11 @@
         f.addSegment(SegmentWithPole(-1, 0, sqrrrootdistr, left_pole = False))
         f.addSegment(SegmentWithPole(0, 1, sqrrrootdistr))
         ints = testWithTheoretical(n = 2, op = conv, f = f, theoretic = sqrrrootdistr, comp_w_theor = False, a = -1, b=1, isPoleAtZero = True)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testThNegChi2(self):
         plt.figure()
         ints = testWithTheoretical(n = 2, op = conv, theoretic = lambda x, n: chisqr(-x, n), a = -Inf, b=0, isPoleAtZero = True)
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testNegLog(self):
         def _logdistr(x, _n = 1):
             if isscalar(x):
@@ -1704,7 +1704,7 @@
         f.addSegment(Segment(0.5, 1, _logdistr))
         plt.figure()
         ints = testWithTheoretical(n = 3, op = conv, f = f, theoretic = _logdistr, comp_w_theor = False, a = 0, b=1, isPoleAtZero = True, splitPoints = [0.5])
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))RefactoringTool: Refactored ./test/testPlot.py
RefactoringTool: Refactored ./test/examples/BehrensFisher.py
RefactoringTool: Refactored ./test/examples/diffeq.py
RefactoringTool: Refactored ./test/examples/how_to_use.py
RefactoringTool: Refactored ./test/examples/linreg_m.py

+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     def testNegLogAbs(self):
         def _logdistr(x, _n = 1):
             if isscalar(x):
@@ -1727,13 +1727,13 @@
         f.addSegment(Segment(0.5, 1, _logdistr2))
         plt.figure()
         ints = testWithTheoretical(n = 3, op = conv, f = f, theoretic = _logdistr, comp_w_theor = False, a = 0, b=1, isPoleAtZero = True, splitPoints = [0.5])
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
         
 
     def testThProdUni(self):
         plt.figure()
         ints = testWithTheoretical(n = 2, op = convprod, theoretic = prodNuniform01, a = 0, b = 1, isPoleAtZero = False, splitPoints = array([0.5]))
-        self.assert_(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
+        self.assertTrue(max(abs(ints-1.0))<self.tol, 'integral error = {0}'.format(max(abs(ints-1))))
     
     def testRatio2(self):
         plt.figure()
@@ -1743,14 +1743,14 @@
         fun.addSegment(segf1)
         fun.addSegment(segf2)
         err = ratioTester(fun)
-        self.assert_(err < self.tol, 'integral error = {0}'.format(err))
+        self.assertTrue(err < self.tol, 'integral error = {0}'.format(err))
     def testRatio3(self):
         plt.figure()
         fun = PiecewiseFunction([])        
         segf1 = Segment(0.0, 1.0, lambda x: 1.0/1.0 + 0*x)        
         fun.addSegment(segf1)
         err = ratioTester(fun)
-        self.assert_(err < self.tol, 'integral error = {0}'.format(err))
+        self.assertTrue(err < self.tol, 'integral error = {0}'.format(err))
     
     def testInversionUniform(self):
         plt.figure()
@@ -1760,7 +1760,7 @@
         #fun.addSegment(segf1)
         fun.addSegment(segf2)
         err = ratioTester(fun)
-        self.assert_(err < self.tol, 'integral error = {0}'.format(err))
+        self.assertTrue(err < self.tol, 'integral error = {0}'.format(err))
     def testInversionNormal(self):
         plt.figure()
         fun = PiecewiseFunction([])        
@@ -1773,7 +1773,7 @@
         fun.addSegment(segf3)
         fun.addSegment(segf4)
         err = ratioTester(fun)
-        self.assert_(err < self.tol, 'integral error = {0}'.format(err))
+        self.assertTrue(err < self.tol, 'integral error = {0}'.format(err))
     def testIntegration(self):
         segf1 = Segment(1.0, 2.0, lambda x: 2772.0*betapdf(x-1,alpha = 6, beta=6))
         segf2 = ConstSegment(0.0, 1.0, 0.5/5.0)        
@@ -1824,8 +1824,8 @@
         g5.addSegment(segk4);
         for fi in [f1, f2, g3, g4, g5]:
             plt.figure()
-            print "=========================================================="
-            print fi.summary();
+            print("==========================================================")
+            print(fi.summary());
             integrationTester(fi)
             
 def suite():
--- ./test/testPlot.py	(original)
+++ ./test/testPlot.py	(refactored)
@@ -9,7 +9,7 @@
 # sass  sa sa sas ala all jest to 
 class TestPlot(unittest.TestCase):
     def setUp(self):
-        print """====Test starting============================="""        
+        print("""====Test starting=============================""")        
         self.N1 = NormalDistr(1, 1)
         self.N2 = NormalDistr(2, 1)
         self.SumN1N2 = self.N1 + self.N2
@@ -20,11 +20,11 @@
         
     def tearDown(self):
         te = time.time()
-        print 'test done,   time=%7.5f s' % (te - self.ts)        
+        print('test done,   time=%7.5f s' % (te - self.ts))        
         
         
     def testPlotPdf(self):
-        print """pdfs and histograms ..."""
+        print("""pdfs and histograms ...""")
         fig = plt.figure()
         self.Chi4.plot()
         self.SumN1N2.plot()
@@ -32,15 +32,15 @@
         self.Chi4.hist()
         self.SumN1N2.hist()
         self.U1.hist()
-        self.assert_(True);
+        self.assertTrue(True);
     
     def testHistdistr(self):
-        print """histograms ..."""
+        print("""histograms ...""")
         fig = plt.figure()
         self.Chi4.hist()
         self.SumN1N2.hist()
         self.U1.hist()
-        self.assert_(True);
+        self.assertTrue(True);
     
        
 
@@ -54,7 +54,7 @@
           F.boxplot(pos, color=col[pos], useci=0.01, label=F.__class__.__name__)
           pos += 1        
         legend()
-        self.assert_(True);
+        self.assertTrue(True);
         
 def suite():
     suite = unittest.TestSuite()
--- ./test/examples/BehrensFisher.py	(original)
+++ ./test/examples/BehrensFisher.py	(refactored)
@@ -38,11 +38,11 @@
         v1  = var(x1, ddof = 1)
     if v2 is None:
         v2  = var(x2, ddof = 1)
-    print "x1: mean={0}, var={1}, n={2}".format(mu1, v1, n1)
-    print "x2: mean={0}, var={1}, n={2}".format(mu2, v2, n2)
+    print("x1: mean={0}, var={1}, n={2}".format(mu1, v1, n1))
+    print("x2: mean={0}, var={1}, n={2}".format(mu2, v2, n2))
 
     T = (mu1 - mu2) / sqrt(v1 / n1 + v2 / n2)
-    print "test statistic T={0}".format(T)
+    print("test statistic T={0}".format(T))
 
     # distribution of the statistic under null hypothesis
     t = BF_distr(n1, n2, v1, v2)
@@ -61,7 +61,7 @@
     rejections of correct H0."""
     nrej_BF = 0
     nrej_W = 0
-    for i in xrange(nsamp):
+    for i in range(nsamp):
         x1 = normal(2, 1, n1)
         x2 = normal(2, 1, n2)
         pv, t, pvw, wd = BF_pvalue(x1, x2)
@@ -69,7 +69,7 @@
             nrej_BF += 1
         if pvw < alpha:
             nrej_W += 1
-        print "pv, pvw=", pv, pvw
+        print("pv, pvw=", pv, pvw)
     return float(nrej_BF) / nsamp, float(nrej_W) / nsamp
 
 if __name__ == "__main__":
@@ -90,10 +90,10 @@
     #x1 = normal(2, 1, 4)
     #x2 = normal(3, 15, 6)
 
-    print "x1 =", x1
-    print "x2 =", x2
+    print("x1 =", x1)
+    print("x2 =", x2)
     pv, t, pvw, wd = BF_pvalue(x1, x2)
-    print pv, pvw
+    print(pv, pvw)
     t.plot()
     t.summary()
     wd.plot()
--- ./test/examples/diffeq.py	(original)
+++ ./test/examples/diffeq.py	(refactored)
@@ -38,7 +38,7 @@
 K = (1 + h*A)
 K.setSym("K") 
 Y = [Y0]*(n+1)
-for i in xrange(n+1):
+for i in range(n+1):
     if i==0:
         pass
     else:
@@ -57,7 +57,7 @@
 Y[-1].plot(color='r',linewidth=5)
 M3 = M.inference([Y[-1]], [], [])
 
-M3.plot(); print M3; 
+M3.plot(); print(M3); 
 
 X0 = BetaDistr(2, 2)
 y = X0 * exp(A) 
@@ -71,27 +71,27 @@
 
 stop
 
-print "---", [K] + Y
-print M
+print("---", [K] + Y)
+print(M)
 M.varschange(A, K)
-print M
-for i in xrange(n):
+print(M)
+for i in range(n):
     M.varschange(Y[i], Y[i+1])
-print M
+print(M)
 M.varschange(K, A)
 M.plot()
 #M.condition(Y[n], 2)
-print M
+print(M)
 M.eliminate(K)
-print M
-for i in xrange(n-1,-1,-1):
+print(M)
+for i in range(n-1,-1,-1):
     M.eliminate(Y[i])
-print M
+print(M)
 M.eliminate(A)
-print M
+print(M)
 figure()
 M.plot()
-print M.nddistr.pdf(linspace(0,2.5,100))
+print(M.nddistr.pdf(linspace(0,2.5,100)))
 X0 = BetaDistr(1, 1)
 y = X0 * exp(A)
 y.summary()
--- ./test/examples/how_to_use.py	(original)
+++ ./test/examples/how_to_use.py	(refactored)
@@ -130,13 +130,13 @@
     X = PDistr(fun)
     X.summary()
     r = X.rand_invcdf(10)
-    print r
+    print(r)
     figure()
     X.hist(n=10000, bins=10)
     X.plot(linewidth=2.0)
     X.get_piecewise_cdf().plot(linewidth=2.0)
     show()
-    print "1-st quartile: ", X.quantile(0.25)
-    print "median: ", X.quantile(0.5)
-    print "3-rd quartile", X.quantile(0.75)
+    print("1-st quartile: ", X.quantile(0.25))
+    print("median: ", X.quantile(0.5))
+    print("3-rd quartile", X.quantile(0.75))
     
--- ./test/examples/linreg_m.py	(original)
+++ ./test/examples/linreg_m.py	(refactored)
@@ -31,12 +31,12 @@
 
 #A = UniformDistr(0,1, sym = "A")
 #B = UniformDistr(0,1, sym = "B")
-W = [BetaDistr(3,3, sym = "W" + str(i)) for i in xrange(m + 1)]
+W = [BetaDistr(3,3, sym = "W" + str(i)) for i in range(m + 1)]
 for i in range(n):
     #X.append(UniformDistr(0, 1, sym = "X{}".format(i)))
     xind = len(X)RefactoringTool: Refactored ./test/examples/lotka_volterra.py
RefactoringTool: No changes to ./test/examples/makerep.py
RefactoringTool: Refactored ./test/examples/noncentral_t_distr.py
RefactoringTool: Refactored ./test/examples/problems.py
RefactoringTool: Refactored ./test/examples/testmp.py
RefactoringTool: Refactored ./test/examples/vec_sum.py
RefactoringTool: Files that need to be modified:
RefactoringTool: ./__init__.py
RefactoringTool: ./distr.py
RefactoringTool: ./gamma.py
RefactoringTool: ./indeparith.py
RefactoringTool: ./integration.py
RefactoringTool: ./interpolation.py
RefactoringTool: ./params.py
RefactoringTool: ./rv.py
RefactoringTool: ./segments.py
RefactoringTool: ./standard_distr.py
RefactoringTool: ./sympy_utils.py
RefactoringTool: ./utils.py
RefactoringTool: ./vartransforms.py
RefactoringTool: ./bindings/PacalServer.py
RefactoringTool: ./depvars/copulas.py
RefactoringTool: ./depvars/models.py
RefactoringTool: ./depvars/nddistr.py
RefactoringTool: ./depvars/sparse_grids.py
RefactoringTool: ./examples/Hill_estimator.py
RefactoringTool: ./examples/central_limit_demo.py
RefactoringTool: ./examples/discrete.py
RefactoringTool: ./examples/extreme_value_demo.py
RefactoringTool: ./examples/functions.py
RefactoringTool: ./examples/measurements.py
RefactoringTool: ./examples/noncentral.py
RefactoringTool: ./examples/order_stats.py
RefactoringTool: ./examples/singularities.py
RefactoringTool: ./examples/dependent/depvars_demo.py
RefactoringTool: ./examples/dependent/diffeq_noise.py
RefactoringTool: ./examples/dependent/kalman.py
RefactoringTool: ./examples/dependent/linreg.py
RefactoringTool: ./examples/dependent/sums.py
RefactoringTool: ./examples/dependent/two_variables/order_stats.py
RefactoringTool: ./examples/dependent/two_variables/regression.py
RefactoringTool: ./examples/dependent/two_variables/resistors.py
RefactoringTool: ./examples/dependent/two_variables/sum_dependent.py
RefactoringTool: ./examples/springer_book/Chapter3_sums.py
RefactoringTool: ./examples/springer_book/Chapter4_products.py
RefactoringTool: ./examples/springer_book/Chapter5_functions.py
RefactoringTool: ./examples/springer_book/Chapter9_applications.py
RefactoringTool: ./examples/springer_book/Chapters678.py
RefactoringTool: ./stats/distr_est.py
RefactoringTool: ./stats/iid_ops.py
RefactoringTool: ./stats/noncentral_distr.py
RefactoringTool: ./test/nosetester.py
RefactoringTool: ./test/testArith.py
RefactoringTool: ./test/testFunc.py
RefactoringTool: ./test/testNumeric.py
RefactoringTool: ./test/testPiecewise.py
RefactoringTool: ./test/testPlot.py
RefactoringTool: ./test/examples/BehrensFisher.py
RefactoringTool: ./test/examples/diffeq.py
RefactoringTool: ./test/examples/how_to_use.py
RefactoringTool: ./test/examples/linreg_m.py
RefactoringTool: ./test/examples/lotka_volterra.py
RefactoringTool: ./test/examples/makerep.py
RefactoringTool: ./test/examples/noncentral_t_distr.py
RefactoringTool: ./test/examples/problems.py
RefactoringTool: ./test/examples/testmp.py
RefactoringTool: ./test/examples/vec_sum.py

     Yi = W[0]
-    for j in xrange(m):
+    for j in range(m):
         X.append(BetaDistr(3, 3, sym = "X{}{}".format(i,j)))
         Yi += W[j+1] * X[-1]
     E.append(MollifierDistr(0.4, sym = "E{}".format(i)))
@@ -52,9 +52,9 @@
 Yobs = []
 trueW = [0.3, 0.9, 0.5, 0.6]
 k = 0
-for i in xrange(n):
+for i in range(n):
     yi = trueW[0]
-    for j in xrange(m):
+    for j in range(m):
         Xobs.append(X[k].rand())
         k += 1
         yi += trueW[j+1] * Xobs[-1]
@@ -72,23 +72,23 @@
 # show()
 
 #print ar, br
-print Xobs, Yobs
-print X + Y
-print concatenate((Xobs, Yobs))
+print(Xobs, Yobs)
+print(X + Y)
+print(concatenate((Xobs, Yobs)))
 
 #print M
 #MAB = M.inference([A,B]+E, X + Y,  concatenate((Xobs, Yobs)))
 #print MAB
 #MAB = MAB.inference([A,B], X + Y,  concatenate((Xobs, Yobs)))
 MW = M.inference(W, X + Y,  concatenate((Xobs, Yobs)))
-print "-------------------"
+print("-------------------")
 MW0 = MW.inference([W[0]],[],[])
 #MB = MW.inference([B],[],[])
 
 #M = M.inference([A,B], [X[0], Y[0]], [0.2, 0.4])
-print MW
+print(MW)
         
-print MW0
+print(MW0)
 figure()
 subplot(211)
 MW0.plot()
@@ -104,5 +104,5 @@
 #print paropt
 #print MAB.nddistr(paropt)
 
-print time.time() - t0
+print(time.time() - t0)
 show()
--- ./test/examples/lotka_volterra.py	(original)
+++ ./test/examples/lotka_volterra.py	(refactored)
@@ -20,7 +20,7 @@
 #D = 0.9
 h=0.1
 for i in range(n):
-    print i
+    print(i)
     if i==0:
         X[i] = BetaDistr(3, 3, sym = "X0")
         Y[i] = BetaDistr(3, 3, sym = "Y0")
@@ -34,17 +34,17 @@
 
 
 M = Model([X[0], Y[0], A, B, C, D], X[1:] + Y[1:] )
-print M
+print(M)
 M.eliminate_other([X[0], Y[0], A, B, C, D] + X[1:] + Y[1:])
-print M
-print Y[1].range()
+print(M)
+print(Y[1].range())
 
 #M1 = M.inference([X[2], Y[2]], [X[0], Y[0]], [0.5, 0.2])\
 figure()
     
 for i in range(n):
     M1 = M.inference([X[i], Y[i]], [A, B, C, D], [0.9, 0.2, 0.3, 0.6])
-    print M1
+    print(M1)
     M1.plot(cont_levels=1)
     #figure()
     #M1.plot(have_3d=True)
--- ./test/examples/noncentral_t_distr.py	(original)
+++ ./test/examples/noncentral_t_distr.py	(refactored)
@@ -30,13 +30,13 @@
                       ):
     if exact_pdf is None:
         exact_pdf = float(multiprec_pdf(df, mu, x))
-        print "exact_pdf", repr(exact_pdf)
+        print("exact_pdf", repr(exact_pdf))
     if exact_cdf is None:
         exact_cdf = float(multiprec_cdf(df, mu, x))
-        print "exact_cdf", repr(exact_cdf)
+        print("exact_cdf", repr(exact_cdf))
     d_, f, P = noncentral_t(df, mu, x)
-    print "pacal_pdf", f
-    print "pacal_cdf", P
+    print("pacal_pdf", f)
+    print("pacal_cdf", P)
     # print f, P
     pdf_err = abs(f - exact_pdf)
     cdf_err = abs(P - exact_cdf)
@@ -49,12 +49,12 @@
         if cdf is not None:
             r_err += " cdf_err={0}".format(abs(exact_cdf - cdf))
         return r_err + "\n"
-    print str_errors("PaCal:      ", df, mu, x, f, P, exact_pdf, exact_cdf),
-    print str_errors("R:          ", df, mu, x, R_pdf, R_cdf, exact_pdf, exact_cdf),
-    print str_errors("Mathematica:", df, mu, x, Mathematica_pdf, Mathematica_cdf, exact_pdf, exact_cdf),
-    print str_errors("Mathematic8:", df, mu, x, Mathematic8_pdf, Mathematic8_cdf, exact_pdf, exact_cdf),
-    print str_errors("SAS:        ", df, mu, x, SAS_pdf, SAS_cdf, exact_pdf, exact_cdf),
-    print str_errors("Matlab:     ", df, mu, x, Matlab_pdf, Matlab_cdf, exact_pdf, exact_cdf),
+    print(str_errors("PaCal:      ", df, mu, x, f, P, exact_pdf, exact_cdf), end=' ')
+    print(str_errors("R:          ", df, mu, x, R_pdf, R_cdf, exact_pdf, exact_cdf), end=' ')
+    print(str_errors("Mathematica:", df, mu, x, Mathematica_pdf, Mathematica_cdf, exact_pdf, exact_cdf), end=' ')
+    print(str_errors("Mathematic8:", df, mu, x, Mathematic8_pdf, Mathematic8_cdf, exact_pdf, exact_cdf), end=' ')
+    print(str_errors("SAS:        ", df, mu, x, SAS_pdf, SAS_cdf, exact_pdf, exact_cdf), end=' ')
+    print(str_errors("Matlab:     ", df, mu, x, Matlab_pdf, Matlab_cdf, exact_pdf, exact_cdf), end=' ')
 
 
 #SAS code:
--- ./test/examples/problems.py	(original)
+++ ./test/examples/problems.py	(refactored)
@@ -97,7 +97,7 @@
     #$ by our interpolator (absolute accuracy 1e-3, integral accuracy 1e-8).
     #$ Here we try to interpolate function with unboded 1-st derivative.
     #$ Otherwise it seems to be evaluated correctly, e.g.:
-    print s(array(linspace(0,1,11))) - pi/4
+    print(s(array(linspace(0,1,11))) - pi/4)
     
     #! To improve accuracy one can try to change interpolation parameters
     #(params.segments.maxn).
--- ./test/examples/testmp.py	(original)
+++ ./test/examples/testmp.py	(refactored)
@@ -21,10 +21,10 @@
 #    s=op(s,u)
 #    s=op(s,u)
 #    s=op(s,s)
-    print s.pdf(1.0) 
+    print(s.pdf(1.0)) 
     
     #s.summary(show_moments=True)
-    print time.time()-tic
+    print(time.time()-tic)
     B.plot(color="b")
     s.plot()
     s.summary()
--- ./test/examples/vec_sum.py	(original)
+++ ./test/examples/vec_sum.py	(refactored)
@@ -37,9 +37,9 @@
 M = Model([C1,C2], [Z1, Z2])
 #M = Model([C1,Y1,Y2], [Z1, Z2])
 #M = Model([X1,X2,Y1,Y2], [Z1, Z2])
-print M
+print(M)
 
 M2 = M.inference([Z1, Z2])
-print M2
+print(M2)
 M2.plot()
 show()

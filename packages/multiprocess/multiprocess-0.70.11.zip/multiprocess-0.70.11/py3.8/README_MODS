cp -rf py3.7/examples .
cp -rf py3.7/doc .
cp -f py3.7/index.html .
cp -rf py3.7/Modules/_multiprocess/* Modules/_multiprocess
cp -f Python-3.8.0b1/Modules/multiprocessing/posixshmem.c Modules/_multiprocess
cp -rf Python-3.8.0b1/Modules/multiprocessing/clinic Modules/_multiprocess
cp -f Python-3.8.0b1/Lib/multiprocessing/* multiprocess
cp -rf py3.7/multiprocess/dummy multiprocess
cp -f Python-3.8.0b1/Lib/test/*test_multiprocessing*.py multiprocess/tests

# ----------------------------------------------------------------------
diff Python-3.7.3/Modules/_multiprocessing/semaphore.c Python-3.8.0b1/Modules/_multiprocessing/semaphore.c
144c144
<                      "value %d", res);
---
>                      "value %u", res);
524c524
< semlock_count(SemLockObject *self)
---
> semlock_count(SemLockObject *self, PyObject *Py_UNUSED(ignored))
530c530
< semlock_ismine(SemLockObject *self)
---
> semlock_ismine(SemLockObject *self, PyObject *Py_UNUSED(ignored))
537c537
< semlock_getvalue(SemLockObject *self)
---
> semlock_getvalue(SemLockObject *self, PyObject *Py_UNUSED(ignored))
555c555
< semlock_iszero(SemLockObject *self)
---
> semlock_iszero(SemLockObject *self, PyObject *Py_UNUSED(ignored))
576c576
< semlock_afterfork(SemLockObject *self)
---
> semlock_afterfork(SemLockObject *self, PyObject *Py_UNUSED(ignored))
587c587
<     {"acquire", (PyCFunction)semlock_acquire, METH_VARARGS | METH_KEYWORDS,
---
>     {"acquire", (PyCFunction)(void(*)(void))semlock_acquire, METH_VARARGS | METH_KEYWORDS,
591c591
<     {"__enter__", (PyCFunction)semlock_acquire, METH_VARARGS | METH_KEYWORDS,
---
>     {"__enter__", (PyCFunction)(void(*)(void))semlock_acquire, METH_VARARGS | METH_KEYWORDS,
636c636
<     /* tp_print          */ 0,
---
>     /* tp_vectorcall_offset */ 0,
639c639
<     /* tp_reserved       */ 0,
---
>     /* tp_as_async       */ 0,
diff Python-3.7.3/Lib/multiprocessing/dummy/__init__.py Python-3.8.0b1/Lib/multiprocessing/dummy/__init__.py
83c83
<     def __init__(self, **kwds):
---
>     def __init__(self, /, **kwds):
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/__init__.py py3.8/multiprocess/__init__.py
17a18,19
> __version__ = '0.70.8.dev0'
> 
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/connection.py py3.8/multiprocess/connection.py
21c21,24
< import _multiprocessing
---
> try:
>     import _multiprocess as _multiprocessing
> except ImportError:
>     import _multiprocessing
60c63
<     return time.monotonic() + timeout
---
>     return getattr(time,'monotonic',time.time)() + timeout
63c66
<     return time.monotonic() > t
---
>     return getattr(time,'monotonic',time.time)() > t
927c930
<                 deadline = time.monotonic() + timeout
---
>                 deadline = getattr(time,'monotonic',time.time)() + timeout
935c938
<                         timeout = deadline - time.monotonic()
---
>                         timeout = deadline - getattr(time,'monotonic',time.time)()
Common subdirectories: /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/dummy and py3.8/multiprocess/dummy
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/forkserver.py py3.8/multiprocess/forkserver.py
106c106
<             cmd = ('from multiprocessing.forkserver import main; ' +
---
>             cmd = ('from multiprocess.forkserver import main; ' +
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/managers.py py3.8/multiprocess/managers.py
500c500
< listener_client = {
---
> listener_client = { #XXX: register dill?
1087c1087
<             endtime = time.monotonic() + timeout
---
>             endtime = getattr(time,'monotonic',time.time)() + timeout
1093c1093
<                 waittime = endtime - time.monotonic()
---
>                 waittime = endtime - getattr(time,'monotonic',time.time)()
1177c1177
<     '__setitem__', 'clear', 'copy', 'get', 'items',
---
>     '__setitem__', 'clear', 'copy', 'get', 'has_key', 'items',
1218c1218
<     The `multiprocessing.Manager()` function creates started instances of
---
>     The `multiprocess.Manager()` function creates started instances of
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/popen_fork.py py3.8/multiprocess/popen_fork.py
43c43
<                 from multiprocessing.connection import wait
---
>                 from multiprocess.connection import wait
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/popen_forkserver.py py3.8/multiprocess/popen_forkserver.py
63c63
<             from multiprocessing.connection import wait
---
>             from multiprocess.connection import wait
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/queues.py py3.8/multiprocess/queues.py
22c22,25
< import _multiprocessing
---
> try:
>     import _multiprocess as _multiprocessing
> except ImportError:
>     import _multiprocessing
101c104
<                 deadline = time.monotonic() + timeout
---
>                 deadline = getattr(time,'monotonic',time.time)() + timeout
106c109
<                     timeout = deadline - time.monotonic()
---
>                     timeout = deadline - getattr(time,'monotonic',time.time)()
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/reduction.py py3.8/multiprocess/reduction.py
15c15,18
< import pickle
---
> try:
>     import dill as pickle
> except ImportError:
>     import pickle
34c37
<     '''Pickler subclass used by multiprocessing.'''
---
>     '''Pickler subclass used by multiprocess.'''
254c257
<     used in multiprocessing.'''
---
>     used in multiprocess.'''
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/resource_tracker.py py3.8/multiprocess/resource_tracker.py
37c37,40
<     import _multiprocessing
---
>     try: 
>         import _multiprocess as _multiprocessing
>     except ImportError:
>         import _multiprocessing
91c94
<             cmd = 'from multiprocessing.resource_tracker import main;main(%d)'
---
>             cmd = 'from multiprocess.resource_tracker import main;main(%d)'
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/spawn.py py3.8/multiprocess/spawn.py
86c86
<         prog = 'from multiprocessing.spawn import spawn_main; spawn_main(%s)'
---
>         prog = 'from multiprocess.spawn import spawn_main; spawn_main(%s)'
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/synchronize.py py3.8/multiprocess/synchronize.py
17c17,20
< import _multiprocessing
---
> try: 
>     import _multiprocess as _multiprocessing
> except ImportError:
>     import _multiprocessing
28,33c31,39
<     from _multiprocessing import SemLock, sem_unlink
< except (ImportError):
<     raise ImportError("This platform lacks a functioning sem_open" +
<                       " implementation, therefore, the required" +
<                       " synchronization primitives needed will not" +
<                       " function, see issue 3770.")
---
>     from _multiprocess import SemLock, sem_unlink
> except ImportError:
>     try:
>         from _multiprocessing import SemLock, sem_unlink
>     except (ImportError):
>         raise ImportError("This platform lacks a functioning sem_open" +
>                           " implementation, therefore, the required" +
>                           " synchronization primitives needed will not" +
>                           " function, see issue 3770.")
304c310
<             endtime = time.monotonic() + timeout
---
>             endtime = getattr(time,'monotonic',time.time)() + timeout
310c316
<                 waittime = endtime - time.monotonic()
---
>                 waittime = endtime - getattr(time,'monotonic',time.time)()
Only in py3.8/multiprocess: tests
diff /Users/mmckerns/src/Python-3.8.0b1/Lib/multiprocessing/util.py py3.8/multiprocess/util.py
38c38
< LOGGER_NAME = 'multiprocessing'
---
> LOGGER_NAME = 'multiprocess'
62c62
<     Returns logger used by multiprocessing
---
>     Returns logger used by multiprocess
diff Python-3.8.0b1/Lib/test/_test_multiprocessing.py ~/dev/svn/pathos/multiprocess/py3.8/multiprocess/tests/__init__.py       
23c23
< import pickle
---
> import pickle #XXX: use dill?
32c32
< _multiprocessing = test.support.import_module('_multiprocessing')
---
> _multiprocessing = test.support.import_module('_multiprocess')
34c34
< test.support.import_module('multiprocessing.synchronize')
---
> test.support.import_module('multiprocess.synchronize')
37,42c37,43
< import multiprocessing.connection
< import multiprocessing.dummy
< import multiprocessing.heap
< import multiprocessing.managers
< import multiprocessing.pool
< import multiprocessing.queues
---
> import multiprocess as multiprocessing
> import multiprocess.connection
> import multiprocess.dummy
> import multiprocess.heap
> import multiprocess.managers
> import multiprocess.pool
> import multiprocess.queues
44c45
< from multiprocessing import util
---
> from multiprocess import util
47c48
<     from multiprocessing import reduction
---
>     from multiprocess import reduction
53c54
<     from multiprocessing.sharedctypes import Value, copy
---
>     from multiprocess.sharedctypes import Value, copy
59c60
<     from multiprocessing import shared_memory
---
>     from multiprocess import shared_memory
93c94
<     from multiprocessing import resource_tracker
---
>     from multiprocess import resource_tracker
121c122
< from multiprocessing.connection import wait
---
> from multiprocess.connection import wait
134c135
< PRELOAD = ['__main__', 'test.test_multiprocessing_forkserver']
---
> PRELOAD = ['__main__', 'test_multiprocessing_forkserver']
173c174
<         t = time.monotonic()
---
>         t = getattr(time,'monotonic',time.time)()
177c178
<             self.elapsed = time.monotonic() - t
---
>             self.elapsed = getattr(time,'monotonic',time.time)() - t
289c290
<         from multiprocessing.process import parent_process
---
>         from multiprocess.process import parent_process
325c326
<         from multiprocessing.process import parent_process
---
>         from multiprocess.process import parent_process
470a472
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
722c724
<         from multiprocessing.forkserver import _forkserver
---
>         from multiprocess.forkserver import _forkserver
811c813
<             self.assertIn("test_multiprocessing.py", err)
---
>             self.assertIn("__init__.py", err)
1092c1094
<                     import multiprocessing
---
>                     import multiprocess as multiprocessing
1110c1112
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
1112c1114
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
1516c1518
<             dt = time.monotonic()
---
>             dt = getattr(time,'monotonic',time.time)()
1518c1520
<             dt = time.monotonic() - dt
---
>             dt = getattr(time,'monotonic',time.time)() - dt
1987c1989
<             self.skipTest("requires multiprocessing.sharedctypes")
---
>             self.skipTest("requires multiprocess.sharedctypes")
2553a2556
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
2595a2599
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
2609c2613
<         t_start = time.monotonic()
---
>         t_start = getattr(time,'monotonic',time.time)()
2621c2625
<         self.assertGreater(time.monotonic() - t_start, 0.9)
---
>         self.assertGreater(getattr(time,'monotonic',time.time)() - t_start, 0.9)
2693,2694c2697,2698
<     def test_unpickleable_result(self):
<         from multiprocessing.pool import MaybeEncodingError
---
>     def _test_unpickleable_result(self):
>         from multiprocess.pool import MaybeEncodingError
2764c2768
< from multiprocessing.managers import BaseManager, BaseProxy, RemoteError
---
> from multiprocess.managers import BaseManager, BaseProxy, RemoteError
3390c3394
<         from multiprocessing import resource_sharer
---
>         from multiprocess import resource_sharer
3832c3836
<             from multiprocessing.managers import SharedMemoryManager
---
>             from multiprocess.managers import SharedMemoryManager
3989c3993
<             from multiprocessing import shared_memory
---
>             from multiprocess import shared_memory
4007c4011
<             deadline = time.monotonic() + 60
---
>             deadline = getattr(time,'monotonic',time.time)() + 60
4009c4013
<             while time.monotonic() < deadline:
---
>             while getattr(time,'monotonic',time.time)() < deadline:
4161,4163c4165,4167
<         modules = ['multiprocessing.' + m for m in modules]
<         modules.remove('multiprocessing.__init__')
<         modules.append('multiprocessing')
---
>         modules = ['multiprocess.' + m for m in modules]
>         modules.remove('multiprocess.__init__')
>         modules.append('multiprocess')
4169,4171c4173,4175
<             modules.remove('multiprocessing.popen_fork')
<             modules.remove('multiprocessing.popen_forkserver')
<             modules.remove('multiprocessing.popen_spawn_posix')
---
>             modules.remove('multiprocess.popen_fork')
>             modules.remove('multiprocess.popen_forkserver')
>             modules.remove('multiprocess.popen_spawn_posix')
4173c4177
<             modules.remove('multiprocessing.popen_spawn_win32')
---
>             modules.remove('multiprocess.popen_spawn_win32')
4175c4179
<                 modules.remove('multiprocessing.popen_forkserver')
---
>                 modules.remove('multiprocess.popen_forkserver')
4179c4183
<             modules.remove('multiprocessing.sharedctypes')
---
>             modules.remove('multiprocess.sharedctypes')
4459c4463
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
4499c4503
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
4540c4544
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
4545c4549
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
4547c4551
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
4555c4559
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
4557c4561
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
4568c4572
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
4581c4585
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
4583c4587
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
4591c4595
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
4593c4597
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
4600c4604
<         start = time.monotonic()
---
>         start = getattr(time,'monotonic',time.time)()
4602c4606
<         delta = time.monotonic() - start
---
>         delta = getattr(time,'monotonic',time.time)() - start
4611c4615
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
4613c4617
<         t = time.monotonic()
---
>         t = getattr(time,'monotonic',time.time)()
4615c4619
<         t = time.monotonic() - t
---
>         t = getattr(time,'monotonic',time.time)() - t
4662c4666
<         prog = ('from test._test_multiprocessing import TestFlags; ' +
---
>         prog = ('from __init__ import TestFlags; ' +
4708c4712
<     def test_noforkbomb(self):
---
>     def _test_noforkbomb(self):
4837c4841
<     def test_ignore(self):
---
>     def _test_ignore(self):
4945c4949
<     def test_preload_resources(self):
---
>     def _test_preload_resources(self):
4962c4966
<     def test_resource_tracker(self):
---
>     def _test_resource_tracker(self):
4968,4970c4972,4974
<             import multiprocessing as mp
<             from multiprocessing import resource_tracker
<             from multiprocessing.shared_memory import SharedMemory
---
>             import multiprocess as mp
>             from multiprocess import resource_tracker
>             from multiprocess.shared_memory import SharedMemory
5030c5034
<         from multiprocessing.resource_tracker import _resource_tracker
---
>         from multiprocess.resource_tracker import _resource_tracker
5078c5082
<         from multiprocessing.resource_tracker import _resource_tracker
---
>         from multiprocess.resource_tracker import _resource_tracker
5087c5091
<         from multiprocessing.resource_tracker import _resource_tracker
---
>         from multiprocess.resource_tracker import _resource_tracker
5231c5235
<         start_time = time.monotonic()
---
>         start_time = getattr(time,'monotonic',time.time)()
5236c5240
<             dt = time.monotonic() - start_time
---
>             dt = getattr(time,'monotonic',time.time)() - start_time
5239c5243
<                 print("Warning -- multiprocessing.Manager still has %s active "
---
>                 print("Warning -- multiprocess.Manager still has %s active "
5510c5514
<         start_time = time.monotonic()
---
>         start_time = getattr(time,'monotonic',time.time)()
5515c5519
<             dt = time.monotonic() - start_time
---
>             dt = getattr(time,'monotonic',time.time)() - start_time
5518c5522
<                 print("Warning -- multiprocessing.Manager still has %s active "
---
>                 print("Warning -- multiprocess.Manager still has %s active "
diff Python-3.8.0b1/Lib/multiprocessing/popen_spawn_win32.py Python-3.8.0b2/Lib/multiprocessing/popen_spawn_win32.py
25,26c25
< WINENV = (hasattr(sys, '_base_executable') and
<           not _path_eq(sys.executable, sys._base_executable))
---
> WINENV = not _path_eq(sys.executable, sys._base_executable)
diff Python-3.8.0b1/Modules/_multiprocessing/clinic/posixshmem.c.h Python-3.8.0b4/Modules/_multiprocessing/clinic/posixshmem.c.h
38c38
<         _PyArg_BadArgument("shm_open", 1, "str", args[0]);
---
>         _PyArg_BadArgument("shm_open", "argument 'path'", "str", args[0]);
111c111
<         _PyArg_BadArgument("shm_unlink", 1, "str", args[0]);
---
>         _PyArg_BadArgument("shm_unlink", "argument 'path'", "str", args[0]);
133c133
< /*[clinic end generated code: output=be42e23c18677c0f input=a9049054013a1b77]*/
---
> /*[clinic end generated code: output=9132861c61d8c2d8 input=a9049054013a1b77]*/
diff Python-3.8.0b1/Lib/multiprocessing/forkserver.py Python-3.8.0b4/Lib/multiprocessing/forkserver.py
41a42,60
>     def _stop(self):
>         # Method used by unit tests to stop the server
>         with self._lock:
>             self._stop_unlocked()
> 
>     def _stop_unlocked(self):
>         if self._forkserver_pid is None:
>             return
> 
>         # close the "alive" file descriptor asks the server to stop
>         os.close(self._forkserver_alive_fd)
>         self._forkserver_alive_fd = None
> 
>         os.waitpid(self._forkserver_pid, 0)
>         self._forkserver_pid = None
> 
>         os.unlink(self._forkserver_address)
>         self._forkserver_address = None
> 
diff Python-3.8.0b1/Lib/multiprocessing/util.py Python-3.8.0b4/Lib/multiprocessing/util.py
108a109,117
> def _remove_temp_dir(rmtree, tempdir):
>     rmtree(tempdir)
> 
>     current_process = process.current_process()
>     # current_process() can be None if the finalizer is called
>     # late during Python finalization
>     if current_process is not None:
>         current_process._config['tempdir'] = None
> 
116c125,128
<         Finalize(None, shutil.rmtree, args=[tempdir], exitpriority=-100)
---
>         # keep a strong reference to shutil.rmtree(), since the finalizer
>         # can be called late during Python shutdown
>         Finalize(None, _remove_temp_dir, args=(shutil.rmtree, tempdir),
>                  exitpriority=-100)
# ----------------------------------------------------------------------
ADDED *args, **kwds for ForkingPickler in __init__, dump, and dumps
# ----------------------------------------------------------------------
diff Python-3.8.0b4/Lib/multiprocessing/context.py py3.8/multiprocessing/context.py
312c312
<        _default_context = DefaultContext(_concrete_contexts['spawn'])
---
>        _default_context = DefaultContext(_concrete_contexts['fork']) #FIXME: spawn
# ----------------------------------------------------------------------
diff Python-3.8.0b4/Lib/multiprocessing/popen_spawn_win32.py Python-3.8.1/Lib/multiprocessing/popen_spawn_win32.py
75c75
<                     env, None, False, 0, None, None, None)
---
>                     None, None, False, 0, env, None, None)
diff Python-3.8.0b4/Lib/multiprocessing/process.py Python-3.8.1/Lib/multiprocessing/process.py
303a304,305
>             if threading._HAVE_THREAD_NATIVE_ID:
>                 threading.main_thread()._set_native_id()
diff Python-3.8.0b4/Lib/multiprocessing/resource_tracker.py Python-3.8.1/Lib/multiprocessing/resource_tracker.py
52a53,65
>     def _stop(self):
>         with self._lock:
>             if self._fd is None:
>                 # not running
>                 return
> 
>             # closing the "alive" file descriptor stops main()
>             os.close(self._fd)
>             self._fd = None
> 
>             os.waitpid(self._pid, 0)
>             self._pid = None
> 
diff Python-3.8.0b4/Lib/multiprocessing/spawn.py Python-3.8.1/Lib/multiprocessing/spawn.py
39c39
<     _python_exe = sys.executable
---
>     _python_exe = sys._base_executable
diff Python-3.8.0b4/Lib/multiprocessing/util.py Python-3.8.1/Lib/multiprocessing/util.py
241c241
<             x += ', exitprority=' + str(self._key[0])
---
>             x += ', exitpriority=' + str(self._key[0])
441a442,466
> 
> 
> def _cleanup_tests():
>     """Cleanup multiprocessing resources when multiprocessing tests
>     completed."""
> 
>     from test import support
> 
>     # cleanup multiprocessing
>     process._cleanup()
> 
>     # Stop the ForkServer process if it's running
>     from multiprocessing import forkserver
>     forkserver._forkserver._stop()
> 
>     # Stop the ResourceTracker process if it's running
>     from multiprocessing import resource_tracker
>     resource_tracker._resource_tracker._stop()
> 
>     # bpo-37421: Explicitly call _run_finalizers() to remove immediately
>     # temporary directories created by multiprocessing.util.get_temp_dir().
>     _run_finalizers()
>     support.gc_collect()
> 
>     support.reap_children()
# ----------------------------------------------------------------------
diff Python-3.8.1/Lib/multiprocessing/connection.py Python-3.8.3/Lib/multiprocessing/connection.py
105c105
<     elif type(address) is str:
---
>     elif type(address) is str or util.is_abstract_socket_namespace(address):
600c600,601
<         if family == 'AF_UNIX':
---
>         if family == 'AF_UNIX' and not util.is_abstract_socket_namespace(address):
>             # Linux abstract socket namespaces do not need to be explicitly unlinked
diff Python-3.8.1/Lib/multiprocessing/forkserver.py Python-3.8.3/Lib/multiprocessing/forkserver.py
58c58,59
<         os.unlink(self._forkserver_address)
---
>         if not util.is_abstract_socket_namespace(self._forkserver_address):
>             os.unlink(self._forkserver_address)
138c139,140
<                 os.chmod(address, 0o600)
---
>                 if not util.is_abstract_socket_namespace(address):
>                     os.chmod(address, 0o600)
diff Python-3.8.1/Lib/multiprocessing/managers.py Python-3.8.3/Lib/multiprocessing/managers.py
62c62
<     Type to uniquely indentify a shared object
---
>     Type to uniquely identify a shared object
824c824
<         Try to call a method of the referrent and return a copy of the result
---
>         Try to call a method of the referent and return a copy of the result
1291a1292,1295
>             address = self.address
>             # The address of Linux abstract namespaces can be bytes
>             if isinstance(address, bytes):
>                 address = os.fsdecode(address)
1293c1297
<                 _SharedMemoryTracker(f"shmm_{self.address}_{getpid()}")
---
>                 _SharedMemoryTracker(f"shm_{address}_{getpid()}")
diff Python-3.8.1/Lib/multiprocessing/pool.py Python-3.8.3/Lib/multiprocessing/pool.py
654,655d653
<         self._worker_handler._state = TERMINATE
<         self._change_notifier.put(None)
684a683,685
>         # Notify that the worker_handler state has been changed so the
>         # _handle_workers loop can be unblocked (and exited) in order to
>         # send the finalization sentinel all the workers.
685a687,688
>         change_notifier.put(None)
> 
diff Python-3.8.1/Lib/multiprocessing/shared_memory.py Python-3.8.3/Lib/multiprocessing/shared_memory.py
435a436
>             encoded_value = value
437,438c438,441
<             if len(value) > self._allocated_bytes[position]:
<                 raise ValueError("exceeds available storage for existing str")
---
>             encoded_value = (value.encode(_encoding)
>                              if isinstance(value, str) else value)
>             if len(encoded_value) > self._allocated_bytes[position]:
>                 raise ValueError("bytes/str item exceeds available storage")
451,452c454
<         value = value.encode(_encoding) if isinstance(value, str) else value
<         struct.pack_into(new_format, self.shm.buf, offset, value)
---
>         struct.pack_into(new_format, self.shm.buf, offset, encoded_value)
diff Python-3.8.1/Lib/multiprocessing/spawn.py Python-3.8.3/Lib/multiprocessing/spawn.py
39c39
<     _python_exe = sys._base_executable
---
>     _python_exe = sys.executable
diff Python-3.8.1/Lib/multiprocessing/util.py Python-3.8.3/Lib/multiprocessing/util.py
104a105,127
> 
> # Abstract socket support
> 
> def _platform_supports_abstract_sockets():
>     if sys.platform == "linux":
>         return True
>     if hasattr(sys, 'getandroidapilevel'):
>         return True
>     return False
> 
> 
> def is_abstract_socket_namespace(address):
>     if not address:
>         return False
>     if isinstance(address, bytes):
>         return address[0] == 0
>     elif isinstance(address, str):
>         return address[0] == "\0"
>     raise TypeError('address type of {address!r} unrecognized')
> 
> 
> abstract_sockets_supported = _platform_supports_abstract_sockets()
# ----------------------------------------------------------------------
diff Python-3.8.3/Lib/multiprocessing/context.py Python-3.8.6/Lib/multiprocessing/context.py
259a260
>             methods = ['spawn', 'fork'] if sys.platform == 'darwin' else ['fork', 'spawn']
261,263c262,264
<                 return ['fork', 'spawn', 'forkserver']
<             else:
<                 return ['fork', 'spawn']
---
>                 methods.append('forkserver')
>             return methods
> 
diff Python-3.8.3/Lib/multiprocessing/shared_memory.py Python-3.8.6/Lib/multiprocessing/shared_memory.py
77a78,79
>             if size == 0:
>                 raise ValueError("'size' must be a positive number different from zero")
diff Python-3.8.3/Lib/multiprocessing/synchronize.py Python-3.8.6/Lib/multiprocessing/synchronize.py
273c273
<             False), ('notify: Should not have been able to acquire'
---
>             False), ('notify: Should not have been able to acquire '

